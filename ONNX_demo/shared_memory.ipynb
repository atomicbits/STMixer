{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7c94861",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/77834567/how-to-use-shared-memory-in-pycuda-logicerror-cumoduleloaddataex-failed-an-il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a779a08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector:\n",
      "[0 4 1 4 5 7 4 9 8 8 8 1 8 7 5 4 5 7 8 3]\n",
      "\n",
      "Output vector:\n",
      "[3 8 7 5 4 5 7 8 1 8 8 8 9 4 7 5 4 1 4 0]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as drv\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "n = 20\n",
    "\n",
    "input = np.random.randint(10, size=(n))\n",
    "output = np.zeros_like(input)\n",
    "\n",
    "input = input.astype(np.int32)\n",
    "output = output.astype(np.int32)\n",
    "\n",
    "mod = SourceModule(\n",
    "'''\n",
    "  __global__ void flipVectorSM(int* in, int* out, int n) {\n",
    "    extern __shared__ int sData[];\n",
    "    int inOffSet = blockDim.x * blockIdx.x;\n",
    "    int index = inOffSet + threadIdx.x;\n",
    "    if (index < n) {\n",
    "        sData[blockDim.x - 1 - threadIdx.x] = in[index];\n",
    "        __syncthreads();\n",
    "    }\n",
    "    int outOffSet = blockDim.x * (gridDim.x - 1 - blockIdx.x);\n",
    "    int outIndex = outOffSet + threadIdx.x;\n",
    "    out[outIndex] = sData[threadIdx.x];\n",
    "  }\n",
    "'''\n",
    ")\n",
    "\n",
    "flip = mod.get_function('flipVectorSM')\n",
    "flip(drv.In(input), drv.InOut(output), np.int32(n), block=(20, 1, 1), grid=(1, 1), shared=20)\n",
    "\n",
    "print(\"Input vector:\")\n",
    "print(input)\n",
    "print(\"\\nOutput vector:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fa6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc2cae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Reverse Result: [63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40\n",
      " 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16\n",
      " 15 14 13 12 11 10  9  8  7  6  5  4  3  2  1  0]\n",
      "Dynamic Reverse Result: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "# CUDA kernel for static memory version\n",
    "static_reverse_kernel = \"\"\"\n",
    "__global__ void staticReverse(int *d, int n)\n",
    "{\n",
    "  __shared__ int s[64];\n",
    "  int t = threadIdx.x;\n",
    "  int tr = n-t-1;\n",
    "  s[t] = d[t];\n",
    "  __syncthreads();\n",
    "  d[t] = s[tr];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# CUDA kernel for dynamic memory version\n",
    "dynamic_reverse_kernel = \"\"\"\n",
    "__global__ void dynamicReverse(int *d, int n)\n",
    "{\n",
    "  extern __shared__ int s[];\n",
    "  int t = threadIdx.x;\n",
    "  int tr = n-t-1;\n",
    "  s[t] = d[t];\n",
    "  __syncthreads();\n",
    "  d[t] = s[tr];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the CUDA kernels\n",
    "mod_static = SourceModule(static_reverse_kernel)\n",
    "mod_dynamic = SourceModule(dynamic_reverse_kernel)\n",
    "\n",
    "# Get the kernel functions\n",
    "static_reverse_func = mod_static.get_function(\"staticReverse\")\n",
    "dynamic_reverse_func = mod_dynamic.get_function(\"dynamicReverse\")\n",
    "\n",
    "# Host data\n",
    "n = 64\n",
    "a = np.arange(n).astype(np.int32)\n",
    "r = np.empty_like(a)\n",
    "d = cuda.mem_alloc(a.nbytes)\n",
    "\n",
    "# Copy data to device\n",
    "cuda.memcpy_htod(d, a)\n",
    "\n",
    "# Run static version kernel\n",
    "static_reverse_func(d, np.int32(n), block=(n, 1, 1))\n",
    "cuda.memcpy_dtoh(r, d)\n",
    "print(\"Static Reverse Result:\", r)\n",
    "\n",
    "# Run dynamic version kernel\n",
    "dynamic_reverse_func(d, np.int32(n), block=(n, 1, 1), shared=4*n)  # 4*n bytes of shared memory for int data\n",
    "cuda.memcpy_dtoh(r, d)\n",
    "print(\"Dynamic Reverse Result:\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4988f06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34fd60a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Reverse Result: [63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40\n",
      " 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16\n",
      " 15 14 13 12 11 10  9  8  7  6  5  4  3  2  1  0]\n"
     ]
    }
   ],
   "source": [
    "dynamic_reverse_kernel = \"\"\"\n",
    "__global__ void dynamicReverse(int *d, int n)\n",
    "{\n",
    "  extern __shared__ int s[];\n",
    "  int t = threadIdx.x;\n",
    "  int tr = n-t-1;\n",
    "  s[t] = d[t];\n",
    "  __syncthreads();\n",
    "  d[t] = s[tr];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the CUDA kernels\n",
    "mod_dynamic = SourceModule(dynamic_reverse_kernel)\n",
    "\n",
    "# Get the kernel functions\n",
    "dynamic_reverse_func = mod_dynamic.get_function(\"dynamicReverse\")\n",
    "\n",
    "# Host data\n",
    "n = 64\n",
    "a = np.arange(n).astype(np.int32)\n",
    "r = np.empty_like(a)\n",
    "d = cuda.mem_alloc(a.nbytes)\n",
    "\n",
    "# Copy data to device\n",
    "cuda.memcpy_htod(d, a)\n",
    "\n",
    "# Run dynamic version kernel\n",
    "dynamic_reverse_func(d, np.int32(n), block=(n, 1, 1), shared=n * 4)  # Allocate shared memory per thread\n",
    "cuda.memcpy_dtoh(r, d)\n",
    "print(\"Dynamic Reverse Result:\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed99fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148e3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784ae6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector addition successfully performed on GPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "# Kernel function for vector addition\n",
    "kernel_code = \"\"\"\n",
    "__global__ void vector_add(float *a, float *b, float *result, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n)\n",
    "        result[i] = a[i] + b[i];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the kernel code\n",
    "mod = SourceModule(kernel_code)\n",
    "\n",
    "# Get the kernel function\n",
    "vector_add = mod.get_function(\"vector_add\")\n",
    "\n",
    "# Define the size of the vectors\n",
    "n = 1000\n",
    "\n",
    "# Create random input data\n",
    "a = np.random.randn(n).astype(np.float32)\n",
    "b = np.random.randn(n).astype(np.float32)\n",
    "\n",
    "# Allocate memory on the GPU\n",
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "result_gpu = cuda.mem_alloc(a.nbytes)\n",
    "\n",
    "# Copy data to GPU\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "\n",
    "# Define block and grid size\n",
    "block_size = 256\n",
    "grid_size = (n + block_size - 1) // block_size\n",
    "\n",
    "# Call the kernel function\n",
    "vector_add(a_gpu, b_gpu, result_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "# Allocate memory for the result on the host\n",
    "result = np.empty_like(a)\n",
    "\n",
    "# Copy the result back to the host\n",
    "cuda.memcpy_dtoh(result, result_gpu)\n",
    "\n",
    "# Verify the result\n",
    "expected_result = a + b\n",
    "assert np.allclose(result, expected_result)\n",
    "\n",
    "print(\"Vector addition successfully performed on GPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad877a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Tensor shape: (32, 32)\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "# CUDA kernel for 2D convolution\n",
    "convolution_kernel = \"\"\"\n",
    "__global__ void convolution(float *input, float *output, float *kernel, int input_width, int input_height, int kernel_width, int kernel_height)\n",
    "{\n",
    "    int tx = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "    int ty = threadIdx.y + blockDim.y * blockIdx.y;\n",
    "\n",
    "    if (tx < input_width && ty < input_height)\n",
    "    {\n",
    "        int output_index = ty * input_width + tx;\n",
    "\n",
    "        output[output_index] = 0.0;\n",
    "        for (int i = 0; i < kernel_height; ++i)\n",
    "        {\n",
    "            for (int j = 0; j < kernel_width; ++j)\n",
    "            {\n",
    "                int input_index = (ty + i - kernel_height / 2) * input_width + (tx + j - kernel_width / 2);\n",
    "                int kernel_index = i * kernel_width + j;\n",
    "                if (input_index >= 0 && input_index < input_width * input_height)\n",
    "                {\n",
    "                    output[output_index] += input[input_index] * kernel[kernel_index];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def conv2d(input_tensor, kernel):\n",
    "    input_height, input_width = input_tensor.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    # Allocate device memory\n",
    "    input_gpu = cuda.mem_alloc(input_tensor.nbytes)\n",
    "    output_gpu = cuda.mem_alloc(input_tensor.nbytes)\n",
    "    kernel_gpu = cuda.mem_alloc(kernel.nbytes)\n",
    "\n",
    "    # Copy data to device\n",
    "    cuda.memcpy_htod(input_gpu, input_tensor)\n",
    "    cuda.memcpy_htod(kernel_gpu, kernel)\n",
    "\n",
    "    # Define block and grid dimensions\n",
    "    block_size = (16, 16, 1)\n",
    "    grid_size = ((input_width + block_size[0] - 1) // block_size[0],\n",
    "                 (input_height + block_size[1] - 1) // block_size[1])\n",
    "\n",
    "    # Compile CUDA kernel\n",
    "    mod = SourceModule(convolution_kernel)\n",
    "    convolution_func = mod.get_function(\"convolution\")\n",
    "\n",
    "    # Execute the kernel\n",
    "    convolution_func(input_gpu, output_gpu, kernel_gpu,\n",
    "                      np.int32(input_width), np.int32(input_height),\n",
    "                      np.int32(kernel_width), np.int32(kernel_height),\n",
    "                      block=block_size, grid=grid_size)\n",
    "\n",
    "    # Copy the result back to host\n",
    "    output_tensor = np.empty_like(input_tensor)\n",
    "    cuda.memcpy_dtoh(output_tensor, output_gpu)\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "# Example usage:\n",
    "input_tensor = np.random.rand(32, 32).astype(np.float32)\n",
    "kernel = np.random.rand(3, 3).astype(np.float32)\n",
    "\n",
    "output_tensor = conv2d(input_tensor, kernel)\n",
    "print(\"Output Tensor shape:\", output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ee3809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Indices after NMS: [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "# CUDA kernel for Non-Maximum Suppression\n",
    "nms_kernel = \"\"\"\n",
    "__global__ void nms(float *boxes, int *selected_indices, int num_boxes, float threshold)\n",
    "{\n",
    "    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "\n",
    "    if (idx < num_boxes)\n",
    "    {\n",
    "        float x1 = boxes[idx * 4];\n",
    "        float y1 = boxes[idx * 4 + 1];\n",
    "        float x2 = boxes[idx * 4 + 2];\n",
    "        float y2 = boxes[idx * 4 + 3];\n",
    "        float area = (x2 - x1 + 1) * (y2 - y1 + 1);\n",
    "\n",
    "        for (int i = 0; i < num_boxes; ++i)\n",
    "        {\n",
    "            if (i != idx)\n",
    "            {\n",
    "                float xx1 = fmaxf(x1, boxes[i * 4]);\n",
    "                float yy1 = fmaxf(y1, boxes[i * 4 + 1]);\n",
    "                float xx2 = fminf(x2, boxes[i * 4 + 2]);\n",
    "                float yy2 = fminf(y2, boxes[i * 4 + 3]);\n",
    "\n",
    "                float w = fmaxf(0.0f, xx2 - xx1 + 1);\n",
    "                float h = fmaxf(0.0f, yy2 - yy1 + 1);\n",
    "                float overlap = (w * h) / area;\n",
    "\n",
    "                if (overlap > threshold)\n",
    "                {\n",
    "                    return; // Suppress this box\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        selected_indices[idx] = 1; // Keep this box\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def nms_cuda(boxes, threshold):\n",
    "    num_boxes = boxes.shape[0]\n",
    "    selected_indices = np.zeros(num_boxes, dtype=np.int32)\n",
    "\n",
    "    # Allocate device memory\n",
    "    boxes_gpu = cuda.mem_alloc(boxes.nbytes)\n",
    "    selected_indices_gpu = cuda.mem_alloc(selected_indices.nbytes)\n",
    "\n",
    "    # Copy data to device\n",
    "    cuda.memcpy_htod(boxes_gpu, boxes)\n",
    "    cuda.memcpy_htod(selected_indices_gpu, selected_indices)\n",
    "\n",
    "    # Define block and grid dimensions\n",
    "    block_size = 256\n",
    "    grid_size = (num_boxes + block_size - 1) // block_size\n",
    "\n",
    "    # Compile CUDA kernel\n",
    "    mod = SourceModule(nms_kernel)\n",
    "    nms_func = mod.get_function(\"nms\")\n",
    "\n",
    "    # Execute the kernel\n",
    "    nms_func(boxes_gpu, selected_indices_gpu, np.int32(num_boxes), np.float32(threshold),\n",
    "             block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "    # Copy the result back to host\n",
    "    cuda.memcpy_dtoh(selected_indices, selected_indices_gpu)\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "# Example usage:\n",
    "boxes = np.array([[10, 10, 50, 50], [20, 20, 60, 60], [30, 30, 70, 70]], dtype=np.float32)\n",
    "threshold = 0.5\n",
    "\n",
    "selected_indices = nms_cuda(boxes, threshold)\n",
    "print(\"Selected Indices after NMS:\", selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4569c936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Indices after NMS: [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "# CUDA kernel for Non-Maximum Suppression\n",
    "nms_kernel = \"\"\"\n",
    "__global__ void nms(float *boxes, int *selected_indices, int num_boxes, float threshold)\n",
    "{\n",
    "    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "\n",
    "    if (idx < num_boxes)\n",
    "    {\n",
    "        float x1 = boxes[idx * 4];\n",
    "        float y1 = boxes[idx * 4 + 1];\n",
    "        float x2 = boxes[idx * 4 + 2];\n",
    "        float y2 = boxes[idx * 4 + 3];\n",
    "        float area = (x2 - x1 + 1) * (y2 - y1 + 1);\n",
    "\n",
    "        // Initialize selected index for the current box\n",
    "        selected_indices[idx] = 1;\n",
    "\n",
    "        for (int i = 0; i < num_boxes; ++i)\n",
    "        {\n",
    "            if (i != idx)\n",
    "            {\n",
    "                float xx1 = fmaxf(x1, boxes[i * 4]);\n",
    "                float yy1 = fmaxf(y1, boxes[i * 4 + 1]);\n",
    "                float xx2 = fminf(x2, boxes[i * 4 + 2]);\n",
    "                float yy2 = fminf(y2, boxes[i * 4 + 3]);\n",
    "\n",
    "                float w = fmaxf(0.0f, xx2 - xx1 + 1);\n",
    "                float h = fmaxf(0.0f, yy2 - yy1 + 1);\n",
    "                float overlap = (w * h) / area;\n",
    "\n",
    "                if (overlap > threshold)\n",
    "                {\n",
    "                    // Suppress this box\n",
    "                    selected_indices[idx] = 0;\n",
    "                    return;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def nms_cuda(boxes, threshold):\n",
    "    num_boxes = boxes.shape[0]\n",
    "    selected_indices = np.zeros(num_boxes, dtype=np.int32)\n",
    "\n",
    "    # Allocate device memory\n",
    "    boxes_gpu = cuda.mem_alloc(boxes.nbytes)\n",
    "    selected_indices_gpu = cuda.mem_alloc(selected_indices.nbytes)\n",
    "\n",
    "    # Copy data to device\n",
    "    cuda.memcpy_htod(boxes_gpu, boxes)\n",
    "    cuda.memcpy_htod(selected_indices_gpu, selected_indices)\n",
    "\n",
    "    # Define block and grid dimensions\n",
    "    block_size = 256\n",
    "    grid_size = (num_boxes + block_size - 1) // block_size\n",
    "\n",
    "    # Compile CUDA kernel\n",
    "    mod = SourceModule(nms_kernel)\n",
    "    nms_func = mod.get_function(\"nms\")\n",
    "\n",
    "    # Execute the kernel\n",
    "    nms_func(boxes_gpu, selected_indices_gpu, np.int32(num_boxes), np.float32(threshold),\n",
    "             block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "    # Copy the result back to host\n",
    "    cuda.memcpy_dtoh(selected_indices, selected_indices_gpu)\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "# Example usage:\n",
    "boxes = np.array([[10, 10, 50, 50], [20, 20, 60, 60], [30, 30, 70, 70]], dtype=np.float32)\n",
    "threshold = 0.5\n",
    "\n",
    "selected_indices = nms_cuda(boxes, threshold)\n",
    "print(\"Selected Indices after NMS:\", selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd35358b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ndarray is not contiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m P \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m0.8\u001b[39m], [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m0.9\u001b[39m], [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m0.85\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     83\u001b[0m thresh_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m---> 85\u001b[0m filtered_boxes \u001b[38;5;241m=\u001b[39m \u001b[43mnms_pytorch_pycuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh_iou\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered Boxes after NMS:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m filtered_boxes:\n",
      "Cell \u001b[0;32mIn[7], line 65\u001b[0m, in \u001b[0;36mnms_pytorch_pycuda\u001b[0;34m(P, thresh_iou)\u001b[0m\n\u001b[1;32m     63\u001b[0m cuda\u001b[38;5;241m.\u001b[39mmemcpy_htod(keep_gpu, keep)\n\u001b[1;32m     64\u001b[0m order_gpu \u001b[38;5;241m=\u001b[39m cuda\u001b[38;5;241m.\u001b[39mmem_alloc(order\u001b[38;5;241m.\u001b[39mnbytes)\n\u001b[0;32m---> 65\u001b[0m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemcpy_htod\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m block_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m     68\u001b[0m grid_size \u001b[38;5;241m=\u001b[39m (num_boxes \u001b[38;5;241m+\u001b[39m block_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m block_size\n",
      "\u001b[0;31mValueError\u001b[0m: ndarray is not contiguous"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "nms_cuda_kernel = \"\"\"\n",
    "__global__ void nms_cuda(float *P, int *order, int *keep, int num_boxes, float thresh_iou, int box_stride)\n",
    "{\n",
    "    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "\n",
    "    if (idx < num_boxes)\n",
    "    {\n",
    "        int box_offset = idx * box_stride;\n",
    "\n",
    "        float x1 = P[box_offset];\n",
    "        float y1 = P[box_offset + 1];\n",
    "        float x2 = P[box_offset + 2];\n",
    "        float y2 = P[box_offset + 3];\n",
    "        float area = (x2 - x1) * (y2 - y1);\n",
    "        float score = P[box_offset + 4];\n",
    "\n",
    "        int keep_index = atomicAdd(&keep[0], 1);\n",
    "        keep_index *= box_stride;\n",
    "        keep[keep_index] = idx;\n",
    "\n",
    "        for (int i = 0; i < num_boxes; ++i)\n",
    "        {\n",
    "            if (i != idx)\n",
    "            {\n",
    "                int other_box_offset = order[i] * box_stride;\n",
    "                float xx1 = fmaxf(x1, P[other_box_offset]);\n",
    "                float yy1 = fmaxf(y1, P[other_box_offset + 1]);\n",
    "                float xx2 = fminf(x2, P[other_box_offset + 2]);\n",
    "                float yy2 = fminf(y2, P[other_box_offset + 3]);\n",
    "                float w = fmaxf(0.0f, xx2 - xx1 + 1);\n",
    "                float h = fmaxf(0.0f, yy2 - yy1 + 1);\n",
    "                float inter = w * h;\n",
    "                float other_area = (P[other_box_offset + 2] - P[other_box_offset]) * (P[other_box_offset + 3] - P[other_box_offset + 1]);\n",
    "                float union_area = other_area - inter + area;\n",
    "                float iou = inter / union_area;\n",
    "\n",
    "                if (iou > thresh_iou)\n",
    "                {\n",
    "                    keep_index = atomicSub(&keep[0], 1) - 1;\n",
    "                    keep_index *= box_stride;\n",
    "                    keep[keep_index] = -1; // Mark box for removal\n",
    "                    return;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def nms_pytorch_pycuda(P, thresh_iou):\n",
    "    num_boxes = P.shape[0]\n",
    "    box_stride = P.shape[1]\n",
    "    order = np.argsort(P[:, 4])[::-1]\n",
    "    keep = np.zeros(num_boxes, dtype=np.int32)\n",
    "    keep[0] = order[0]  # Keep the box with the highest score\n",
    "    keep_index = np.zeros(1, dtype=np.int32)\n",
    "    keep_gpu = cuda.mem_alloc(keep.nbytes)\n",
    "    cuda.memcpy_htod(keep_gpu, keep)\n",
    "    order_gpu = cuda.mem_alloc(order.nbytes)\n",
    "    cuda.memcpy_htod(order_gpu, order)\n",
    "\n",
    "    block_size = 256\n",
    "    grid_size = (num_boxes + block_size - 1) // block_size\n",
    "\n",
    "    mod = SourceModule(nms_cuda_kernel)\n",
    "    nms_cuda_func = mod.get_function(\"nms_cuda\")\n",
    "    nms_cuda_func(cuda.InOut(P), order_gpu, keep_gpu, np.int32(num_boxes), np.float32(thresh_iou), np.int32(box_stride),\n",
    "                  block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "    cuda.memcpy_dtoh(keep, keep_gpu)\n",
    "    filtered_boxes = [P[keep[i]*box_stride:(keep[i]+1)*box_stride] for i in range(len(keep)) if keep[i] != -1]\n",
    "    return filtered_boxes\n",
    "\n",
    "# Example usage:\n",
    "import torch\n",
    "\n",
    "P = torch.tensor([[10, 10, 50, 50, 0.8], [20, 20, 60, 60, 0.9], [30, 30, 70, 70, 0.85]], dtype=torch.float32)\n",
    "thresh_iou = 0.5\n",
    "\n",
    "filtered_boxes = nms_pytorch_pycuda(P.cpu().numpy(), thresh_iou)\n",
    "print(\"Filtered Boxes after NMS:\")\n",
    "for box in filtered_boxes:\n",
    "    print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e3774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Boxes after NMS:\n",
      "[]\n",
      "[[10.   10.   50.   50.    0.8 ]\n",
      " [20.   20.   60.   60.    0.9 ]\n",
      " [30.   30.   70.   70.    0.85]]\n",
      "[[10.   10.   50.   50.    0.8 ]\n",
      " [20.   20.   60.   60.    0.9 ]\n",
      " [30.   30.   70.   70.    0.85]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3318/3655634100.py:71: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "kernel.cu(16): warning #177-D: variable \"score\" was declared but never referenced\n",
      "\n",
      "\n",
      "  mod = SourceModule(nms_cuda_kernel)\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np\n",
    "\n",
    "nms_cuda_kernel = \"\"\"\n",
    "__global__ void nms_cuda(float *P, int *order, int *keep, int num_boxes, float thresh_iou, int box_stride)\n",
    "{\n",
    "    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "\n",
    "    if (idx < num_boxes)\n",
    "    {\n",
    "        int box_offset = idx * box_stride;\n",
    "\n",
    "        float x1 = P[box_offset];\n",
    "        float y1 = P[box_offset + 1];\n",
    "        float x2 = P[box_offset + 2];\n",
    "        float y2 = P[box_offset + 3];\n",
    "        float area = (x2 - x1) * (y2 - y1);\n",
    "        float score = P[box_offset + 4];\n",
    "\n",
    "        int keep_index = atomicAdd(&keep[0], 1);\n",
    "        keep_index *= box_stride;\n",
    "        keep[keep_index] = idx;\n",
    "\n",
    "        for (int i = 0; i < num_boxes; ++i)\n",
    "        {\n",
    "            if (i != idx)\n",
    "            {\n",
    "                int other_box_offset = order[i] * box_stride;\n",
    "                float xx1 = fmaxf(x1, P[other_box_offset]);\n",
    "                float yy1 = fmaxf(y1, P[other_box_offset + 1]);\n",
    "                float xx2 = fminf(x2, P[other_box_offset + 2]);\n",
    "                float yy2 = fminf(y2, P[other_box_offset + 3]);\n",
    "                float w = fmaxf(0.0f, xx2 - xx1 + 1);\n",
    "                float h = fmaxf(0.0f, yy2 - yy1 + 1);\n",
    "                float inter = w * h;\n",
    "                float other_area = (P[other_box_offset + 2] - P[other_box_offset]) * (P[other_box_offset + 3] - P[other_box_offset + 1]);\n",
    "                float union_area = other_area - inter + area;\n",
    "                float iou = inter / union_area;\n",
    "\n",
    "                if (iou > thresh_iou)\n",
    "                {\n",
    "                    keep_index = atomicSub(&keep[0], 1) - 1;\n",
    "                    keep_index *= box_stride;\n",
    "                    keep[keep_index] = -1; // Mark box for removal\n",
    "                    return;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def nms_pytorch_pycuda(P, thresh_iou):\n",
    "    num_boxes = P.shape[0]\n",
    "    box_stride = P.shape[1]\n",
    "    order = np.argsort(P[:, 4])[::-1]\n",
    "    keep = np.zeros(num_boxes, dtype=np.int32)\n",
    "    keep[0] = order[0]  # Keep the box with the highest score\n",
    "    keep_index = np.zeros(1, dtype=np.int32)\n",
    "    keep_gpu = cuda.mem_alloc(keep.nbytes)\n",
    "    cuda.memcpy_htod(keep_gpu, keep)\n",
    "    order_contiguous = np.ascontiguousarray(order)  # Ensure order array is contiguous\n",
    "    order_gpu = cuda.mem_alloc(order_contiguous.nbytes)\n",
    "    cuda.memcpy_htod(order_gpu, order_contiguous)\n",
    "\n",
    "    block_size = 256\n",
    "    grid_size = (num_boxes + block_size - 1) // block_size\n",
    "\n",
    "    mod = SourceModule(nms_cuda_kernel)\n",
    "    nms_cuda_func = mod.get_function(\"nms_cuda\")\n",
    "    nms_cuda_func(cuda.InOut(P), order_gpu, keep_gpu, np.int32(num_boxes), np.float32(thresh_iou), np.int32(box_stride),\n",
    "                  block=(block_size, 1, 1), grid=(grid_size, 1))\n",
    "\n",
    "    cuda.memcpy_dtoh(keep, keep_gpu)\n",
    "    filtered_boxes = [P[keep[i]*box_stride:(keep[i]+1)*box_stride] for i in range(len(keep)) if keep[i] != -1]\n",
    "    return filtered_boxes\n",
    "\n",
    "# Example usage:\n",
    "import torch\n",
    "\n",
    "P = torch.tensor([[10, 10, 50, 50, 0.8], [20, 20, 60, 60, 0.9], [30, 30, 70, 70, 0.85]], dtype=torch.float32)\n",
    "thresh_iou = 0.5\n",
    "\n",
    "filtered_boxes = nms_pytorch_pycuda(P.cpu().numpy(), thresh_iou)\n",
    "print(\"Filtered Boxes after NMS:\")\n",
    "for box in filtered_boxes:\n",
    "    print(box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59862c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    " \n",
    "img = cv.imread('../input_dir/camera01.tiff')\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    " \n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    " \n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    " \n",
    "cv.imwrite('sift_keypoints.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc5b4b28",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input_dir/camera01.tiff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m----> 6\u001b[0m surf \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxfeatures2d\u001b[49m\u001b[38;5;241m.\u001b[39mSURF_create(\u001b[38;5;241m8000\u001b[39m)\n\u001b[1;32m      7\u001b[0m keypoints, descriptors \u001b[38;5;241m=\u001b[39m surf\u001b[38;5;241m.\u001b[39mdetectAndCompute(gray, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdrawKeypoints(img, keypoints, img, (\u001b[38;5;241m51\u001b[39m, \u001b[38;5;241m163\u001b[39m, \u001b[38;5;241m236\u001b[39m),\n\u001b[1;32m     10\u001b[0m                   cv2\u001b[38;5;241m.\u001b[39mDRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('../input_dir/camera01.tiff')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "surf = cv2.xfeatures2d.SURF_create(8000)\n",
    "keypoints, descriptors = surf.detectAndCompute(gray, None)\n",
    "\n",
    "cv2.drawKeypoints(img, keypoints, img, (51, 163, 236),\n",
    "                  cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('surf_keypoints', img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda3f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
