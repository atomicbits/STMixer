{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f628821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728f8dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.9258, 0.8624, 0.2548, 0.7526],\n",
      "        [0.9196, 0.7145, 0.6951, 0.7513],\n",
      "        [0.8356, 0.8861, 0.9181, 0.7395]]), tensor([[0.9258, 0.8624, 0.2548, 0.7526],\n",
      "        [0.9196, 0.7145, 0.6951, 0.7513],\n",
      "        [0.8356, 0.8861, 0.9181, 0.7395]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(x + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "print(my_cell(x, h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a97ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08ceaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape  5, torch.Size([1, 5, 10, 10]) ||| torch.Size([1, 5, 10, 10])\n",
      "Shape 10, torch.Size([1, 10, 20, 20]) ||| torch.Size([1, 10, 20, 20])\n",
      "Shape 15, torch.Size([1, 15, 30, 30]) ||| torch.Size([1, 15, 30, 30])\n",
      "Shape  5, torch.Size([1, 5, 10, 10]) ||| torch.Size([1, 5, 10, 10])\n",
      "Shape 10, torch.Size([1, 10, 20, 20]) ||| torch.Size([1, 10, 20, 20])\n",
      "Shape 15, torch.Size([1, 15, 30, 30]) ||| torch.Size([1, 15, 30, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv = torch.nn.Conv3d(5, 1, 3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_x = self.conv(x)\n",
    "        up_x = torch.nn.functional.interpolate(\n",
    "            new_x, scale_factor=2, mode=\"bicubic\", align_corners=True)\n",
    "        return up_x\n",
    "\n",
    "\n",
    "inp_5 = torch.randn( 5, 5, 5, 5)\n",
    "inp_10 = torch.randn( 5, 10, 10, 10)\n",
    "inp_15 = torch.randn( 5, 15, 15, 15)\n",
    "\n",
    "model = Model()\n",
    "model.eval()\n",
    "trace = torch.jit.trace(model, inp_10)\n",
    "trace.save(\"trace.pth\")\n",
    "\n",
    "result_model_5 = model(inp_5)\n",
    "result_model_10 = model(inp_10)\n",
    "result_model_15 = model(inp_15)\n",
    "print(\"Shape  5, {} ||| {}\".format(result_model_5.shape, result_model_5.shape))\n",
    "print(\"Shape 10, {} ||| {}\".format(result_model_10.shape, result_model_10.shape))\n",
    "print(\"Shape 15, {} ||| {}\".format(result_model_15.shape, result_model_15.shape))\n",
    "t_model = torch.jit.load(\"trace.pth\")\n",
    "result_t_model_5 = t_model(inp_5)\n",
    "result_t_model_10 = t_model(inp_10)\n",
    "result_t_model_15 = t_model(inp_15)\n",
    "\n",
    "print(\"Shape  5, {} ||| {}\".format(result_model_5.shape, result_t_model_5.shape))\n",
    "print(\"Shape 10, {} ||| {}\".format(result_model_10.shape, result_t_model_10.shape))\n",
    "print(\"Shape 15, {} ||| {}\".format(result_model_15.shape, result_t_model_15.shape))\n",
    "torch.allclose(result_model_5, result_t_model_5)\n",
    "torch.allclose(result_model_10, result_t_model_10)\n",
    "torch.allclose(result_model_15, result_t_model_15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d985af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(5, 32, 32, 32, strides=[32768, 1024, 32, 1], requires_grad=0, device=cpu),\n",
      "      %conv.weight : Float(1, 5, 3, 3, 3, strides=[135, 27, 9, 3, 1], requires_grad=1, device=cpu)):\n",
      "  %/conv/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/conv/Constant\"](), scope: __main__.Model::/torch.nn.modules.conv.Conv3d::conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:608:0\n",
      "  %/conv/Unsqueeze_output_0 : Float(1, 5, 32, 32, 32, strides=[163840, 32768, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/conv/Unsqueeze\"](%input, %/conv/Constant_output_0), scope: __main__.Model::/torch.nn.modules.conv.Conv3d::conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:608:0\n",
      "  %/conv/Conv_output_0 : Float(1, 1, 32, 32, 32, strides=[32768, 32768, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1], onnx_name=\"/conv/Conv\"](%/conv/Unsqueeze_output_0, %conv.weight), scope: __main__.Model::/torch.nn.modules.conv.Conv3d::conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:608:0\n",
      "  %/conv/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/conv/Constant_1\"](), scope: __main__.Model::/torch.nn.modules.conv.Conv3d::conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:608:0\n",
      "  %/conv/Squeeze_output_0 : Float(1, 32, 32, 32, strides=[32768, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Squeeze[onnx_name=\"/conv/Squeeze\"](%/conv/Conv_output_0, %/conv/Constant_1_output_0), scope: __main__.Model::/torch.nn.modules.conv.Conv3d::conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:608:0\n",
      "  %/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/Constant\"](), scope: __main__.Model:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3958:0\n",
      "  %onnx::Resize_10 : Tensor? = prim::Constant(), scope: __main__.Model:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3958:0\n",
      "  %11 : Float(1, 32, 64, 64, strides=[131072, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"align_corners\", cubic_coeff_a=-0.75, mode=\"cubic\", nearest_mode=\"floor\", onnx_name=\"/Resize\"](%/conv/Squeeze_output_0, %onnx::Resize_10, %/Constant_output_0), scope: __main__.Model:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3958:0\n",
      "  return (%11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# Define the model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv = torch.nn.Conv3d(5, 1, 3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_x = self.conv(x)\n",
    "        up_x = F.interpolate(\n",
    "            new_x, scale_factor=2, mode=\"bicubic\", align_corners=True)\n",
    "        return up_x\n",
    "\n",
    "# Instantiate the model\n",
    "model = Model()\n",
    "\n",
    "# Prepare dummy input data\n",
    "dummy_input = torch.randn(5, 32, 32, 32)  # Example shape, adjust according to your actual input shape\n",
    "\n",
    "# Export the model to ONNX\n",
    "torch.onnx.export(model, dummy_input, \"bi_model.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "936eae29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"bi_model.onnx\")\n",
    "\n",
    "# Prepare input data\n",
    "input_data = np.random.randn(5, 32, 32, 32).astype(np.float32)  # Example input, adjust according to your actual input\n",
    "\n",
    "# Run the ONNX model\n",
    "ort_session = onnxruntime.InferenceSession(\"bi_model.onnx\")\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: input_data}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# Convert ONNX output to PyTorch tensor\n",
    "onnx_output = torch.tensor(ort_outs[0])\n",
    "\n",
    "\n",
    "\n",
    "pytorch_model = Model()\n",
    "\n",
    "# Run the PyTorch model\n",
    "pytorch_output = pytorch_model(torch.tensor(input_data))\n",
    "\n",
    "# Compare outputs\n",
    "print(torch.allclose(pytorch_output, onnx_output, atol=1e-4))  # Check if outputs are approximately equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73d28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f4657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e291c5f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nArguments for call are not valid.\nThe following variants are available:\n  \n  interpolate(Tensor input, int? size=None, float[]? scale_factor=None, str mode=\"nearest\", bool? align_corners=None, bool? recompute_scale_factor=None, bool antialias=False) -> Tensor:\n  Expected a value of type 'Optional[List[float]]' for argument 'scale_factor' but instead found type 'int'.\n  \n  interpolate(Tensor input, int[]? size=None, float[]? scale_factor=None, str mode=\"nearest\", bool? align_corners=None, bool? recompute_scale_factor=None, bool antialias=False) -> Tensor:\n  Expected a value of type 'Optional[List[float]]' for argument 'scale_factor' but instead found type 'int'.\n  \n  interpolate(Tensor input, int? size=None, float? scale_factor=None, str mode=\"nearest\", bool? align_corners=None, bool? recompute_scale_factor=None, bool antialias=False) -> Tensor:\n  Expected a value of type 'Optional[float]' for argument 'scale_factor' but instead found type 'int'.\n  \n  interpolate(Tensor input, int[]? size=None, float? scale_factor=None, str mode=\"nearest\", bool? align_corners=None, bool? recompute_scale_factor=None, bool antialias=False) -> Tensor:\n  Expected a value of type 'Optional[float]' for argument 'scale_factor' but instead found type 'int'.\n\nThe original call is:\n  File \"/tmp/ipykernel_207/4245390919.py\", line 14\n    def forward(self, x):\n        new_x = self.conv(x)\n        up_x = torch.nn.functional.interpolate(\n               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n            new_x, scale_factor=2, mode=\"trilinear\", align_corners=True)\n        return up_x\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m up_x\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Script the model\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model_scripted \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Prepare dummy input data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)  \u001b[38;5;66;03m# Example shape, adjust according to your actual input shape\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py:1286\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m   1285\u001b[0m     obj \u001b[38;5;241m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_methods_to_compile\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_script_dict(obj)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:477\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    476\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:543\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> 543\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_stubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_stubs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;66;03m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;66;03m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:394\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    391\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m    392\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m--> 394\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nArguments for call are not valid.\nThe following variants are available:\n  \n  interpolate(Tensor input, int? size=None, float[]? scale_factor=None, str mode=\"nearest\", bool? align_corners=None, bool? recompute_scale_factor=None, bool antialias=False) -> Tensor:\n  Expected a value of type 'Optional[List[float]]' for argument 'scale_factor' but instead found type 'int'.\n  \n  interpolate(Tensor input, int[]? size=None, float[]? scale_factor=None, str mode=\"nearest\", bool? align_corners=None, bool? recompute_scale_factor=None, bool antialias=False) -> Tensor:\n  Expected a value of type 'Optional[List[float]]' for argument 'scale_factor' but instead found type 'int'.\n  \n  interpolate(Tensor input, int? size=None, float? scale_factor=None, str mode=\"nearest\", bool? align_corners=None, bool? recompute_scale_factor=None, bool antialias=False) -> Tensor:\n  Expected a value of type 'Optional[float]' for argument 'scale_factor' but instead found type 'int'.\n  \n  interpolate(Tensor input, int[]? size=None, float? scale_factor=None, str mode=\"nearest\", bool? align_corners=None, bool? recompute_scale_factor=None, bool antialias=False) -> Tensor:\n  Expected a value of type 'Optional[float]' for argument 'scale_factor' but instead found type 'int'.\n\nThe original call is:\n  File \"/tmp/ipykernel_207/4245390919.py\", line 14\n    def forward(self, x):\n        new_x = self.conv(x)\n        up_x = torch.nn.functional.interpolate(\n               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n            new_x, scale_factor=2, mode=\"trilinear\", align_corners=True)\n        return up_x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "# Define the model as scripted\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv = torch.nn.Conv3d(5, 1, 3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_x = self.conv(x)\n",
    "        up_x = torch.nn.functional.interpolate(\n",
    "            new_x, scale_factor=2, mode=\"trilinear\", align_corners=True)\n",
    "        return up_x\n",
    "\n",
    "# Script the model\n",
    "model_scripted = torch.jit.script(Model())\n",
    "\n",
    "# Prepare dummy input data\n",
    "dummy_input = torch.randn(5, 32, 32, 32)  # Example shape, adjust according to your actual input shape\n",
    "\n",
    "# Export the scripted model to ONNX\n",
    "torch.onnx.export(model_scripted, dummy_input, \"model_scripted.onnx\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490f050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ff2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ffefef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b434ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2227, -0.3328, -0.3188,  ..., -0.3511, -0.2137, -0.0189],\n",
       "          [-0.2008, -0.4195, -0.4958,  ...,  0.0945, -0.1694, -0.3552],\n",
       "          [-0.1794, -0.3575, -0.4425,  ...,  0.4274, -0.1076, -0.5864],\n",
       "          ...,\n",
       "          [ 0.1714,  0.6273,  0.8638,  ..., -0.0519,  0.1328,  0.3054],\n",
       "          [ 0.3390,  0.5549,  0.5967,  ..., -0.1187,  0.0978,  0.2802],\n",
       "          [ 0.4682,  0.3761,  0.1764,  ..., -0.1827,  0.0200,  0.1770]],\n",
       "\n",
       "         [[ 0.8741,  0.5230,  0.1654,  ..., -0.6323, -0.3302,  0.1075],\n",
       "          [ 0.2444, -0.0916, -0.3434,  ..., -0.8905, -0.4764,  0.1316],\n",
       "          [-0.2961, -0.5792, -0.7157,  ..., -0.8524, -0.4298,  0.1662],\n",
       "          ...,\n",
       "          [-0.3688, -0.3246, -0.2625,  ..., -0.8969, -0.6655, -0.2234],\n",
       "          [-0.2457, -0.0348,  0.1770,  ...,  0.0212, -0.0255,  0.0124],\n",
       "          [ 0.0385,  0.3449,  0.6517,  ...,  1.0559,  0.8050,  0.4756]],\n",
       "\n",
       "         [[-0.2796, -0.0995,  0.0552,  ...,  0.0903,  0.1187,  0.0740],\n",
       "          [-0.4286, -0.0534,  0.3349,  ..., -0.5287, -0.6136, -0.6086],\n",
       "          [-0.4200, -0.0162,  0.4427,  ..., -0.9339, -1.2078, -1.2550],\n",
       "          ...,\n",
       "          [ 1.0539,  0.6867,  0.2416,  ..., -0.6164, -0.4485, -0.0287],\n",
       "          [ 0.5130,  0.3590,  0.1138,  ..., -0.2263, -0.1528,  0.0148],\n",
       "          [-0.2564, -0.2002, -0.2266,  ...,  0.3187,  0.2356,  0.0502]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.8361,  0.9331,  0.8428,  ...,  0.1276,  0.2581,  0.4455],\n",
       "          [ 0.2449,  0.1212, -0.0936,  ..., -0.0560, -0.1340, -0.1266],\n",
       "          [-0.3487, -0.6464, -0.9194,  ...,  0.0061, -0.3060, -0.5549],\n",
       "          ...,\n",
       "          [-0.4747, -0.2161,  0.0572,  ..., -0.9569, -0.5957, -0.1008],\n",
       "          [-0.0332, -0.3276, -0.5049,  ..., -0.5274, -0.3839, -0.1924],\n",
       "          [ 0.2967, -0.4395, -0.9979,  ...,  0.1732,  0.0630, -0.1546]],\n",
       "\n",
       "         [[-0.3630, -0.5025, -0.4909,  ...,  0.1647,  0.0477, -0.1269],\n",
       "          [-0.1115, -0.1608, -0.1635,  ..., -0.0642,  0.0434,  0.1259],\n",
       "          [ 0.2119,  0.1468,  0.0523,  ..., -0.0566,  0.1305,  0.2711],\n",
       "          ...,\n",
       "          [-0.1950,  0.4468,  0.7345,  ..., -0.1212, -0.3653, -0.6908],\n",
       "          [ 0.0025,  0.2185,  0.2315,  ..., -0.0824, -0.0520, -0.1292],\n",
       "          [ 0.3527, -0.0321, -0.3813,  ...,  0.0274,  0.3289,  0.5366]],\n",
       "\n",
       "         [[ 0.0247,  0.0816,  0.0975,  ...,  0.2765,  0.2228,  0.1119],\n",
       "          [-0.0134,  0.1519,  0.2361,  ..., -0.0357,  0.2628,  0.5080],\n",
       "          [-0.0070,  0.2365,  0.3638,  ..., -0.3310,  0.2466,  0.7951],\n",
       "          ...,\n",
       "          [ 0.1045,  0.0472,  0.0542,  ...,  0.3990,  0.2050, -0.1622],\n",
       "          [-0.1996,  0.1351,  0.4710,  ...,  0.6746,  0.2103, -0.4127],\n",
       "          [-0.3955,  0.3428,  0.9975,  ...,  0.8093,  0.0628, -0.7732]]]],\n",
       "       grad_fn=<UpsampleBicubic2DBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9ea4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.4487e-01, -7.6984e-02,  3.9708e-02,  ...,  2.9346e-01,\n",
       "            1.7076e-01,  7.4563e-02],\n",
       "          [-3.4842e-01, -4.8136e-02,  2.1705e-01,  ..., -2.4384e-01,\n",
       "           -1.1211e-01,  4.2700e-02],\n",
       "          [-2.4128e-01,  4.8916e-02,  3.1589e-01,  ..., -6.4900e-01,\n",
       "           -3.2812e-01,  3.2954e-02],\n",
       "          ...,\n",
       "          [-3.7661e-01, -2.4080e-02,  1.2430e-01,  ...,  5.8830e-01,\n",
       "            5.3890e-01,  5.2177e-01],\n",
       "          [-2.6550e-01, -2.6247e-02,  1.5702e-01,  ...,  3.9481e-01,\n",
       "            3.7874e-01,  3.6470e-01],\n",
       "          [-1.2041e-01,  6.5828e-03,  2.3583e-01,  ...,  4.9067e-02,\n",
       "            1.1513e-01,  1.5927e-01]],\n",
       "\n",
       "         [[-1.6589e-01, -7.2124e-01, -1.1899e+00,  ..., -3.5382e-01,\n",
       "           -4.4075e-01, -3.8103e-01],\n",
       "          [-2.5858e-01, -4.9317e-01, -7.4639e-01,  ..., -2.1517e-01,\n",
       "           -3.2313e-01, -3.0102e-01],\n",
       "          [-2.9973e-01, -2.7149e-01, -3.1751e-01,  ..., -1.0852e-01,\n",
       "           -2.3290e-01, -2.8148e-01],\n",
       "          ...,\n",
       "          [-4.1905e-01, -2.8050e-01, -1.0894e-01,  ..., -6.0790e-01,\n",
       "            2.8640e-01,  1.1585e+00],\n",
       "          [-2.3529e-01, -2.4666e-01, -2.1512e-01,  ..., -1.9834e-01,\n",
       "            2.9438e-01,  7.2761e-01],\n",
       "          [-5.0012e-02, -2.7404e-01, -4.1957e-01,  ...,  4.4921e-01,\n",
       "            3.6845e-01,  1.4933e-01]],\n",
       "\n",
       "         [[-8.1062e-01, -6.8969e-01, -5.7883e-01,  ...,  2.0601e-01,\n",
       "            2.3400e-02, -6.6326e-02],\n",
       "          [-6.6249e-01, -3.3539e-01, -7.1166e-02,  ...,  1.7288e-01,\n",
       "            5.4939e-02, -3.5400e-02],\n",
       "          [-4.4261e-01,  4.7186e-02,  4.2196e-01,  ...,  1.0190e-01,\n",
       "            7.0242e-02, -9.2145e-04],\n",
       "          ...,\n",
       "          [ 1.6187e-01,  4.7097e-02, -1.2991e-01,  ..., -7.3457e-01,\n",
       "           -4.9149e-01, -4.7919e-02],\n",
       "          [-4.9801e-02, -8.9561e-02, -1.0636e-01,  ..., -1.5304e-01,\n",
       "           -2.1538e-01, -2.1520e-01],\n",
       "          [-2.6490e-01, -2.2700e-01, -7.8748e-02,  ...,  4.6451e-01,\n",
       "            7.4759e-02, -4.0286e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.7667e-01,  3.1739e-01,  5.7324e-02,  ..., -2.4384e-01,\n",
       "           -3.4685e-01, -4.6315e-01],\n",
       "          [ 8.3504e-01,  4.7616e-01,  1.0752e-01,  ..., -2.8935e-01,\n",
       "           -3.5937e-01, -4.5212e-01],\n",
       "          [ 9.9206e-01,  4.8361e-01,  4.7452e-02,  ..., -2.4494e-01,\n",
       "           -2.7065e-01, -3.1767e-01],\n",
       "          ...,\n",
       "          [-2.2851e-01,  1.7207e-01,  5.3566e-01,  ...,  3.8405e-02,\n",
       "            1.0498e-01,  1.1053e-01],\n",
       "          [-1.8949e-01,  1.6188e-01,  4.0258e-01,  ...,  1.0877e-01,\n",
       "            4.5725e-02,  7.6973e-03],\n",
       "          [-1.0520e-01,  8.2250e-02,  1.0098e-01,  ...,  8.7866e-04,\n",
       "           -6.6639e-02, -1.6078e-02]],\n",
       "\n",
       "         [[ 1.4234e-01,  4.4397e-02, -5.0036e-02,  ...,  1.0373e-01,\n",
       "           -2.9184e-01, -7.6090e-01],\n",
       "          [ 3.1502e-01,  3.3494e-01,  2.3541e-01,  ..., -1.0143e-01,\n",
       "           -3.0929e-01, -4.8872e-01],\n",
       "          [ 3.7435e-01,  5.2024e-01,  4.5389e-01,  ..., -2.3334e-01,\n",
       "           -2.6133e-01, -1.8271e-01],\n",
       "          ...,\n",
       "          [-9.1362e-01, -2.9125e-01,  3.2295e-01,  ...,  6.4987e-01,\n",
       "            8.7903e-02, -6.1027e-01],\n",
       "          [-6.9384e-01, -7.5185e-02,  4.7718e-01,  ...,  5.1714e-01,\n",
       "           -5.5195e-02, -7.1080e-01],\n",
       "          [-2.7767e-01,  1.4608e-01,  4.8283e-01,  ...,  1.7882e-01,\n",
       "           -2.1473e-01, -6.1502e-01]],\n",
       "\n",
       "         [[-3.3645e-01, -2.1060e-01, -1.0708e-02,  ...,  5.4693e-02,\n",
       "            8.7005e-02,  4.3540e-02],\n",
       "          [-6.5631e-02, -2.3942e-02,  3.1396e-02,  ...,  3.5192e-01,\n",
       "            1.8183e-01,  2.5475e-03],\n",
       "          [ 1.7717e-01,  1.5638e-01,  9.5829e-02,  ...,  4.5080e-01,\n",
       "            1.7880e-01, -3.4400e-02],\n",
       "          ...,\n",
       "          [-4.7857e-01, -2.4285e-01,  1.9196e-02,  ..., -1.7820e-01,\n",
       "           -1.5321e-01, -4.1873e-02],\n",
       "          [-2.6930e-01, -3.4337e-02,  1.6554e-01,  ...,  1.2821e-01,\n",
       "            9.2750e-04, -7.8752e-02],\n",
       "          [ 1.5764e-01,  2.6839e-01,  2.9263e-01,  ...,  3.7283e-01,\n",
       "            1.4624e-01, -7.6238e-02]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4bef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[ 0.5909,  0.5538,  0.7614,  0.0835],\n",
      "        [ 0.0673,  0.1451,  0.7798,  0.0643],\n",
      "        [ 0.7146, -0.0390,  0.3463, -0.2745]], grad_fn=<TanhBackward0>), tensor([[ 0.5909,  0.5538,  0.7614,  0.0835],\n",
      "        [ 0.0673,  0.1451,  0.7798,  0.0643],\n",
      "        [ 0.7146, -0.0390,  0.3463, -0.2745]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d601438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (dg): MyDecisionGate()\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[ 0.8818,  0.4849,  0.7097,  0.0984],\n",
      "        [ 0.7700,  0.2646,  0.8844, -0.0608],\n",
      "        [ 0.8700,  0.0560,  0.2545, -0.3650]], grad_fn=<TanhBackward0>), tensor([[ 0.8818,  0.4849,  0.7097,  0.0984],\n",
      "        [ 0.7700,  0.2646,  0.8844, -0.0608],\n",
      "        [ 0.8700,  0.0560,  0.2545, -0.3650]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33a8e0",
   "metadata": {},
   "source": [
    "## Tracing scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf4b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  original_name=MyCell\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6391, 0.6892, 0.8042, 0.5016],\n",
       "         [0.0427, 0.8648, 0.7200, 0.5320],\n",
       "         [0.3587, 0.8346, 0.6829, 0.4864]], grad_fn=<TanhBackward0>),\n",
       " tensor([[0.6391, 0.6892, 0.8042, 0.5016],\n",
       "         [0.0427, 0.8648, 0.7200, 0.5320],\n",
       "         [0.3587, 0.8346, 0.6829, 0.4864]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell)\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6cd3bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.MyCell,\n",
      "      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n",
      "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
      "  %linear : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
      "  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n",
      "  %11 : int = prim::Constant[value=1]() # /tmp/ipykernel_1218/260609686.py:7:0\n",
      "  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%20, %h, %11) # /tmp/ipykernel_1218/260609686.py:7:0\n",
      "  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%12) # /tmp/ipykernel_1218/260609686.py:7:0\n",
      "  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%13, %13)\n",
      "  return (%14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3680f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7fe8027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.6391, 0.6892, 0.8042, 0.5016],\n",
      "        [0.0427, 0.8648, 0.7200, 0.5320],\n",
      "        [0.3587, 0.8346, 0.6829, 0.4864]], grad_fn=<TanhBackward0>), tensor([[0.6391, 0.6892, 0.8042, 0.5016],\n",
      "        [0.0427, 0.8648, 0.7200, 0.5320],\n",
      "        [0.3587, 0.8346, 0.6829, 0.4864]], grad_fn=<TanhBackward0>))\n",
      "(tensor([[0.6391, 0.6892, 0.8042, 0.5016],\n",
      "        [0.0427, 0.8648, 0.7200, 0.5320],\n",
      "        [0.3587, 0.8346, 0.6829, 0.4864]], grad_fn=<TanhBackward0>), tensor([[0.6391, 0.6892, 0.8042, 0.5016],\n",
      "        [0.0427, 0.8648, 0.7200, 0.5320],\n",
      "        [0.3587, 0.8346, 0.6829, 0.4864]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(my_cell(x, h))\n",
    "print(traced_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304b9b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  return torch.neg(argument_1)\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  _1 = torch.tanh(_0)\n",
      "  return (_1, _1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218/4234398751.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "\n",
    "print(traced_cell.dg.code)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbce2e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "\n",
    "my_cell = MyCell(scripted_gate)\n",
    "scripted_cell = torch.jit.script(my_cell)\n",
    "\n",
    "print(scripted_gate.code)\n",
    "print(scripted_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1f12b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.6794,  0.8707,  0.4962,  0.2333],\n",
      "        [ 0.5400,  0.3965,  0.6403,  0.6984],\n",
      "        [ 0.6505, -0.0650,  0.3179,  0.2074]], grad_fn=<TanhBackward0>), tensor([[ 0.6794,  0.8707,  0.4962,  0.2333],\n",
      "        [ 0.5400,  0.3965,  0.6403,  0.6984],\n",
      "        [ 0.6505, -0.0650,  0.3179,  0.2074]], grad_fn=<TanhBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# New inputs\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "print(scripted_cell(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfe6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
