{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ce21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import moviepy \n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from ref_alphaction.config import cfg\n",
    "from ref_alphaction.modeling.detector import build_detection_model\n",
    "from ref_alphaction.utils.checkpoint import ActionCheckpointer\n",
    "from ref_alphaction.utils.comm import get_world_size\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'VMAEv2'\n",
    "\n",
    "\n",
    "person_threshold = 0.6 # confidence threshold on actor. 0.6 is the defualt\n",
    "sampling_rate = 3 # sampling rate: 4 is the defualt\n",
    "top_k = 5 # number of actions per person\n",
    "video_path = '../input_dir/markt2_fight.mp4'\n",
    "\n",
    "slice_height = 800\n",
    "slice_width = 1000\n",
    "overlap_ratio = 0.1\n",
    "\n",
    "starting_frame_index = 100\n",
    "length_input = 200\n",
    "\n",
    "exp_dict = {'model_name': model_name,\n",
    "            'model_params': {'person_threshold': person_threshold, \n",
    "                             'sampling_rate': sampling_rate},\n",
    "            'orig_post_processing':{'top_k': top_k},\n",
    "            'aggregation': {'method': {}, \n",
    "                            'params': {}},\n",
    "            'video_path': video_path,\n",
    "            'slicing_params': {'slice_height': slice_height, \n",
    "                               'slice_width': slice_width, \n",
    "                               'overlap_ratio':overlap_ratio},\n",
    "            'video_params': {'st_frame_index': starting_frame_index, \n",
    "                             'length_input':length_input\n",
    "                             }\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e298259",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'VMAEv2':\n",
    "    config_file = '../config_files/VMAEv2-ViTB-16x4.yaml'\n",
    "if model_name == 'VMAE':\n",
    "    config_file = '../config_files/VMAE-ViTB-16x4.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41000f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model weight path\n",
    "if model_name == 'VMAEv2':\n",
    "    cfg.merge_from_list([\"MODEL.WEIGHT\", \"../checkpoints/VMAEv2_ViTB_16x4.pth\"])\n",
    "if model_name == 'VMAE':\n",
    "    cfg.merge_from_list([\"MODEL.WEIGHT\", \"../checkpoints/VMAE_ViTB_16x4.pth\"])\n",
    "\n",
    "# change output dir\n",
    "cfg.merge_from_list([\"OUTPUT_DIR\", \"../output_dir/\"])\n",
    "\n",
    "# change person threshold\n",
    "cfg.merge_from_list([\"MODEL.STM.PERSON_THRESHOLD\", person_threshold])\n",
    "\n",
    "# change sampling rate\n",
    "cfg.merge_from_list([\"DATA.SAMPLING_RATE\", sampling_rate])\n",
    "\n",
    "# change path for data_dir\n",
    "cfg.merge_from_list([\"DATA.PATH_TO_DATA_DIR\", \"/work/ava\"])\n",
    "\n",
    "# folder name of annotations\n",
    "cfg.merge_from_list([\"AVA.ANNOTATION_DIR\", \"annotations/\"])\n",
    "\n",
    "# file name of  frame_lists\n",
    "cfg.merge_from_list([\"AVA.TRAIN_LISTS\", ['sample.csv']])\n",
    "cfg.merge_from_list([\"AVA.TEST_LISTS\", ['sample.csv']])\n",
    "\n",
    "# file name of predicted_bboxes\n",
    "cfg.merge_from_list([\"AVA.TRAIN_GT_BOX_LISTS\", ['ava_sample_predicted_boxes.csv']])\n",
    "cfg.merge_from_list([\"AVA.TEST_GT_BOX_LISTS\", ['ava_sample_predicted_boxes.csv']])\n",
    "\n",
    "# file name of exlusions\n",
    "cfg.merge_from_list([\"AVA.EXCLUSION_FILE\", 'ava_sample_train_excluded_timestamps_v2.2.csv'])\n",
    "\n",
    "# number of batches in test scenario\n",
    "cfg.merge_from_list([\"TEST.VIDEOS_PER_BATCH\", 1])\n",
    "\n",
    "# number of workers\n",
    "cfg.merge_from_list([\"DATALOADER.NUM_WORKERS\", 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.ViT.USE_CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33630fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_list([\"ViT.USE_CHECKPOINT\", False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.ViT.USE_CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    # The shape of model input should be divisible into this. Otherwise, padding 0 to left and bottum. \n",
    "    print(\"cfg.DATALOADER.SIZE_DIVISIBILITY: \", cfg.DATALOADER.SIZE_DIVISIBILITY)\n",
    "    \n",
    "    # Sampling rate in constructing the clips.\n",
    "    self_sample_rate =  cfg.DATA.SAMPLING_RATE\n",
    "    print(\"cfg.DATA.SAMPLING_RATE: \", cfg.DATA.SAMPLING_RATE)\n",
    "    \n",
    "    # Length of clip\n",
    "    self_video_length = cfg.DATA.NUM_FRAMES\n",
    "    print(\"cfg.DATA.NUM_FRAMES: \", cfg.DATA.NUM_FRAMES)\n",
    "    \n",
    "    # Length of sequence frames from which a clip is constructed.\n",
    "    self_seq_len = self_video_length * self_sample_rate\n",
    "    print(\"self_seq_len: \", self_seq_len)\n",
    "    \n",
    "    self_num_classes = cfg.MODEL.STM.ACTION_CLASSES\n",
    "    print(\"cfg.MODEL.STM.ACTION_CLASSES: \", self_num_classes)\n",
    "    \n",
    "    # Augmentation params.\n",
    "    self_data_mean = cfg.DATA.MEAN\n",
    "    self_data_std = cfg.DATA.STD\n",
    "    self_use_bgr = cfg.AVA.BGR\n",
    "    print(\"Augmentation params: \", self_data_mean, self_data_std, self_use_bgr)\n",
    "    \n",
    "    self_jitter_min_scale = cfg.DATA.TEST_MIN_SCALES\n",
    "    self_jitter_max_scale = cfg.DATA.TEST_MAX_SCALE\n",
    "    self_test_force_flip = cfg.AVA.TEST_FORCE_FLIP\n",
    "\n",
    "    print(\"scale and flip params\", self_jitter_min_scale, self_jitter_max_scale, self_test_force_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detection_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ActionCheckpointer(cfg, model, save_dir=\"../output_dir/\")\n",
    "checkpointer.load(cfg.MODEL.WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02126c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_video = torch.randn(1, 3, 16, 256, 320).to('cuda')\n",
    "\n",
    "\n",
    "model = model.eval().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fdb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(slow_video)# NOTE THAT THE INPUT TO THIS VERISIN IS A TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cf184",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feec3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b07c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf857d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861bcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cba924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfb1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ee4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x, y):\n",
    "    return torch.zeros_like(x) + y[1]\n",
    "\n",
    "sc_fo = torch.jit.script(foo)\n",
    "\n",
    "print(torch.jit.script(foo, (torch.rand(4, 4), [10,10])).code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.ViT.USE_CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7066f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_fo(torch.rand(4, 4), [10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470bc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpol = Interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.script(Interpolate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017d18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new positional embeddings: torch.Size([3, 225, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class Interpolate(torch.jit.ScriptModule):\n",
    "    __constants__ = [\"scale_factor\", \"mode\", \"align_corners\"]\n",
    "\n",
    "    def __init__(self, scale_factor=(15.0,15.0) , mode=\"bicubic\", align_corners=None):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.align_corners = align_corners\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, X):\n",
    "        return nn.functional.interpolate(X, scale_factor=self.scale_factor,\n",
    "                                         mode=self.mode, align_corners=self.align_corners)\n",
    "    \n",
    "def interpolate_pos_embed_online(\n",
    "        pos_embed, orig_size: Tuple[int], new_size: Tuple[int], num_extra_tokens: int\n",
    "):\n",
    "    extra_tokens = pos_embed[:, :num_extra_tokens]\n",
    "    pos_tokens = pos_embed[:, num_extra_tokens:]\n",
    "    embedding_size = pos_tokens.shape[-1]\n",
    "    pos_tokens = pos_tokens.reshape(\n",
    "        -1, orig_size[0], orig_size[1], embedding_size\n",
    "    ).permute(0, 3, 1, 2)\n",
    "    pos_tokens = torch.nn.functional.interpolate(\n",
    "        pos_tokens, size=new_size, mode=\"bicubic\", align_corners=False,\n",
    "    )\n",
    "    pos_tokens = pos_tokens.permute(0, 2, 3, 1).flatten(1, 2)\n",
    "    new_pos_embed = torch.cat((extra_tokens, pos_tokens), dim=1)\n",
    "    return new_pos_embed\n",
    "\n",
    "# Example input\n",
    "pos_embed = torch.randn(3, 100, 20)  # Assuming 3 batches, 100 tokens, and 20 embedding dimensions\n",
    "orig_size = (10, 10)  # Original size of positional embeddings\n",
    "new_size = (15, 15)   # New size to interpolate to\n",
    "num_extra_tokens = 0  # Number of extra tokens at the beginning of the positional embeddings\n",
    "\n",
    "# Test the function\n",
    "new_pos_embed = interpolate_pos_embed_online(pos_embed, orig_size, new_size, num_extra_tokens)\n",
    "print(\"Shape of new positional embeddings:\", new_pos_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40865f5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\n'torch.Tensor' object in attribute 'Interpolate.scale_factor' is not a valid constant.\nValid constants are:\n1. a nn.ModuleList\n2. a value of type {bool, float, int, str, NoneType, torch.device, torch.layout, torch.dtype}\n3. a list or tuple of (2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mInterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_embed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py:307\u001b[0m, in \u001b[0;36mScriptMeta.__init__.<locals>.init_then_script\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m infer_methods_to_compile(module)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_actual_script_module\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 307\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_stubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madded_methods_in_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Delete the Python attributes that now shadow the ScriptModule\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# ones, so that __getattr__ and __setattr__ will properly find\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# the scripted versions.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m concrete_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_script_module\u001b[38;5;241m.\u001b[39m_concrete_type\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:474\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nn_module, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mRecursiveScriptModule)\n\u001b[1;32m    473\u001b[0m check_module_initialized(nn_module)\n\u001b[0;32m--> 474\u001b[0m concrete_type \u001b[38;5;241m=\u001b[39m \u001b[43mget_module_concrete_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    476\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:425\u001b[0m, in \u001b[0;36mget_module_concrete_type\u001b[0;34m(nn_module, share_types)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn_module\u001b[38;5;241m.\u001b[39m_concrete_type\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m share_types:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;66;03m# Look into the store of cached JIT types\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     concrete_type \u001b[38;5;241m=\u001b[39m \u001b[43mconcrete_type_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_concrete_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# Get a concrete type directly, without trying to re-use an existing JIT\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;66;03m# type from the type store.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m     concrete_type_builder \u001b[38;5;241m=\u001b[39m infer_concrete_type_builder(nn_module, share_types)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:366\u001b[0m, in \u001b[0;36mConcreteTypeStore.get_or_create_concrete_type\u001b[0;34m(self, nn_module)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_or_create_concrete_type\u001b[39m(\u001b[38;5;28mself\u001b[39m, nn_module):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    Infer a ConcreteType from this `nn.Module` instance. Underlying JIT\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    types are re-used if possible.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     concrete_type_builder \u001b[38;5;241m=\u001b[39m \u001b[43minfer_concrete_type_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     nn_module_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(nn_module)\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nn_module_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_store:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:268\u001b[0m, in \u001b[0;36minfer_concrete_type_builder\u001b[0;34m(nn_module, share_types)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(nn_module, name)\n\u001b[0;32m--> 268\u001b[0m     concrete_type_builder\u001b[38;5;241m.\u001b[39madd_constant(name, \u001b[43m_get_valid_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    269\u001b[0m     added_names\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# populate overloads\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:111\u001b[0m, in \u001b[0;36m_get_valid_constant\u001b[0;34m(attr, v, owner_type)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(_get_valid_constant(attr, x, owner_type) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m v)\n\u001b[1;32m    110\u001b[0m constants \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(torch\u001b[38;5;241m.\u001b[39mtypename(typ) \u001b[38;5;28;01mfor\u001b[39;00m typ \u001b[38;5;129;01min\u001b[39;00m _constant_types)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object in attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a valid constant.\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124m    Valid constants are:\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124m    1. a nn.ModuleList\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124m    2. a value of type \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m}}\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124m    3. a list or tuple of (2)\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(torch\u001b[38;5;241m.\u001b[39mtypename(\u001b[38;5;28mtype\u001b[39m(v)), owner_type, attr, constants)))\n",
      "\u001b[0;31mTypeError\u001b[0m: \n'torch.Tensor' object in attribute 'Interpolate.scale_factor' is not a valid constant.\nValid constants are:\n1. a nn.ModuleList\n2. a value of type {bool, float, int, str, NoneType, torch.device, torch.layout, torch.dtype}\n3. a list or tuple of (2)\n"
     ]
    }
   ],
   "source": [
    "Interpolate(pos_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea5e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30252898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb958d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py:1243: UserWarning: `optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\nTuple index out of range. Tuple is length 1 and index is 1:\n  File \"/tmp/ipykernel_3803/2346981515.py\", line 26\n    embedding_size = pos_tokens.shape[-1]\n    pos_tokens = pos_tokens.reshape(\n        -1, orig_size[0], orig_size[1], embedding_size\n                          ~~~~~~~~~~~~ <--- HERE\n    ).permute(0, 3, 1, 2)\n    pos_tokens = torch.nn.functional.interpolate(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscript\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpolate_pos_embed_online\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_extra_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py:1343\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _rcb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1342\u001b[0m     _rcb \u001b[38;5;241m=\u001b[39m _jit_internal\u001b[38;5;241m.\u001b[39mcreateResolutionCallbackFromClosure(obj)\n\u001b[0;32m-> 1343\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_script_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqualified_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_rcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_default_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;66;03m# Forward docstrings\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nTuple index out of range. Tuple is length 1 and index is 1:\n  File \"/tmp/ipykernel_3803/2346981515.py\", line 26\n    embedding_size = pos_tokens.shape[-1]\n    pos_tokens = pos_tokens.reshape(\n        -1, orig_size[0], orig_size[1], embedding_size\n                          ~~~~~~~~~~~~ <--- HERE\n    ).permute(0, 3, 1, 2)\n    pos_tokens = torch.nn.functional.interpolate(\n"
     ]
    }
   ],
   "source": [
    "m = torch.jit.script(interpolate_pos_embed_online, (orig_size, new_size, num_extra_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_pos_embed_online(\n",
    "        pos_embed, orig_size: Tuple[int], new_size: Tuple[int], num_extra_tokens: int\n",
    "):\n",
    "    extra_tokens = pos_embed[:, :num_extra_tokens]\n",
    "    pos_tokens = pos_embed[:, num_extra_tokens:]\n",
    "    embedding_size = pos_tokens.shape[-1]\n",
    "    pos_tokens = pos_tokens.reshape(\n",
    "        -1, orig_size[0], orig_size[1], embedding_size\n",
    "    ).permute(0, 3, 1, 2)\n",
    "    pos_tokens = torch.nn.functional.interpolate(\n",
    "        pos_tokens, size=new_size, mode=\"bicubic\", align_corners=False,\n",
    "    )\n",
    "    pos_tokens = pos_tokens.permute(0, 2, 3, 1).flatten(1, 2)\n",
    "    new_pos_embed = torch.cat((extra_tokens, pos_tokens), dim=1)\n",
    "    return new_pos_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77295e70",
   "metadata": {},
   "source": [
    "## INTERPOLATE POSE EMBED ONLINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f8d21be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "class MyInterpolate_Pose_Embed_Online(torch.nn.Module):\n",
    "    def __init__(self, orig_size, new_size, num_extra_tokens):\n",
    "        super(MyInterpolate_Pose_Embed_Online, self).__init__()\n",
    "        self.orig_size = orig_size\n",
    "        self.new_size = new_size\n",
    "        self.num_extra_tokens = num_extra_tokens\n",
    "    def forward(self, pos_embed):\n",
    "        extra_tokens = pos_embed[:, :self.num_extra_tokens]\n",
    "        pos_tokens = pos_embed[:, self.num_extra_tokens:]\n",
    "        embedding_size = pos_tokens.shape[-1]\n",
    "        pos_tokens = pos_tokens.reshape(\n",
    "            -1, self.orig_size[0], self.orig_size[1], embedding_size).permute(0, 3, 1, 2)\n",
    "        print(pos_tokens.shape)\n",
    "        pos_tokens = torch.nn.functional.interpolate(\n",
    "        pos_tokens, size=self.new_size, mode=\"bilinear\", align_corners=False, )\n",
    "        pos_tokens = pos_tokens.permute(0, 2, 3, 1).flatten(1, 2)\n",
    "        new_pos_embed = torch.cat((extra_tokens, pos_tokens), dim=1)\n",
    "        return new_pos_embed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3d8af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embed = torch.randn(3, 100, 20)  # Assuming 3 batches, 100 tokens, and 20 embedding dimensions\n",
    "orig_size = (10, 10)  # Original size of positional embeddings\n",
    "new_size = (15, 15)   # New size to interpolate to\n",
    "num_extra_tokens = 0  # Number of extra tokens at the beginning of the positional embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ec5c2edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pose = MyInterpolate_Pose_Embed_Online(orig_size, new_size, num_extra_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "588c3494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20, 10, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6927, -1.0217,  0.8121,  ..., -1.2881,  0.1307,  0.7297],\n",
       "         [ 1.6738,  0.2628,  0.7831,  ..., -0.7399, -0.6807, -0.0680],\n",
       "         [ 1.2520,  1.3601,  0.6529,  ..., -0.3442, -1.1591, -0.6246],\n",
       "         ...,\n",
       "         [ 1.7018, -0.3035,  0.6705,  ..., -0.7306,  0.9061,  0.0886],\n",
       "         [ 1.2231,  0.0390,  0.6591,  ..., -0.6369, -0.0131,  0.0208],\n",
       "         [ 0.2063,  0.7071,  0.4055,  ..., -0.4308, -1.2560, -0.3108]],\n",
       "\n",
       "        [[-0.0799, -0.8515,  0.3789,  ...,  0.2424, -0.3138,  0.5497],\n",
       "         [-0.2181, -0.3297, -0.3611,  ..., -0.0637,  0.6720, -0.7122],\n",
       "         [-0.6433, -0.0598, -1.0004,  ..., -0.2314,  1.6398, -1.5495],\n",
       "         ...,\n",
       "         [-0.4789, -0.7532, -0.7629,  ...,  0.4329,  1.0429, -0.1593],\n",
       "         [-0.7032, -0.6635, -0.9407,  ...,  0.2803,  1.0328,  0.0843],\n",
       "         [-0.8350, -0.5540, -0.9626,  ...,  0.3472,  0.7101,  0.5344]],\n",
       "\n",
       "        [[ 1.1857,  1.1835,  0.4705,  ..., -1.0137, -1.4482,  0.1568],\n",
       "         [-0.3859,  1.4280, -0.6051,  ..., -0.7772, -0.8751,  0.1035],\n",
       "         [-1.6343,  1.6150, -1.3206,  ..., -0.4319, -0.3478, -0.0846],\n",
       "         ...,\n",
       "         [ 0.9485,  0.8820, -0.1712,  ...,  1.4853, -1.2448,  0.9690],\n",
       "         [ 1.2310,  0.4963,  0.4524,  ...,  1.4550, -0.4323,  0.0833],\n",
       "         [ 1.4880,  0.2002,  1.2467,  ...,  1.2204,  0.5886, -0.9166]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pose(pos_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0a6c0b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pose_scipted = torch.jit.script(my_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f969681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 20, 10, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6927, -1.0217,  0.8121,  ..., -1.2881,  0.1307,  0.7297],\n",
       "         [ 1.6738,  0.2628,  0.7831,  ..., -0.7399, -0.6807, -0.0680],\n",
       "         [ 1.2520,  1.3601,  0.6529,  ..., -0.3442, -1.1591, -0.6246],\n",
       "         ...,\n",
       "         [ 1.7018, -0.3035,  0.6705,  ..., -0.7306,  0.9061,  0.0886],\n",
       "         [ 1.2231,  0.0390,  0.6591,  ..., -0.6369, -0.0131,  0.0208],\n",
       "         [ 0.2063,  0.7071,  0.4055,  ..., -0.4308, -1.2560, -0.3108]],\n",
       "\n",
       "        [[-0.0799, -0.8515,  0.3789,  ...,  0.2424, -0.3138,  0.5497],\n",
       "         [-0.2181, -0.3297, -0.3611,  ..., -0.0637,  0.6720, -0.7122],\n",
       "         [-0.6433, -0.0598, -1.0004,  ..., -0.2314,  1.6398, -1.5495],\n",
       "         ...,\n",
       "         [-0.4789, -0.7532, -0.7629,  ...,  0.4329,  1.0429, -0.1593],\n",
       "         [-0.7032, -0.6635, -0.9407,  ...,  0.2803,  1.0328,  0.0843],\n",
       "         [-0.8350, -0.5540, -0.9626,  ...,  0.3472,  0.7101,  0.5344]],\n",
       "\n",
       "        [[ 1.1857,  1.1835,  0.4705,  ..., -1.0137, -1.4482,  0.1568],\n",
       "         [-0.3859,  1.4280, -0.6051,  ..., -0.7772, -0.8751,  0.1035],\n",
       "         [-1.6343,  1.6150, -1.3206,  ..., -0.4319, -0.3478, -0.0846],\n",
       "         ...,\n",
       "         [ 0.9485,  0.8820, -0.1712,  ...,  1.4853, -1.2448,  0.9690],\n",
       "         [ 1.2310,  0.4963,  0.4524,  ...,  1.4550, -0.4323,  0.0833],\n",
       "         [ 1.4880,  0.2002,  1.2467,  ...,  1.2204,  0.5886, -0.9166]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pose_scipted(pos_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ff363728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 20, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(my_pose_scipted, \n",
    "                  args = pos_embed, \n",
    "                  f=\"pose_embeding.onnx\", \n",
    "                  input_names=[\"pose_embed\"], \n",
    "                  output_names=[\"output\"],\n",
    "                  opset_version=11,\n",
    "                  verbose=False\n",
    "                  #dynamic_axes={\"slow_video\": {0: \"batch_size\"}, \"whwh\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9c4e253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "from onnx import numpy_helper\n",
    "\n",
    "# Load the ONNX model\n",
    "pose_embeding_onnx = onnx.load(\"pose_embeding.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a4a21544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch_jit (\n",
      "  %pose_embed[FLOAT, 3x100x20]\n",
      ") {\n",
      "  %/Constant_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Constant_1_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Constant_2_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Constant_3_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Slice_output_0 = Slice(%pose_embed, %/Constant_1_output_0, %/Constant_2_output_0, %/Constant_output_0, %/Constant_3_output_0)\n",
      "  %/Constant_4_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Reshape_output_0 = Reshape(%pose_embed, %/Constant_4_output_0)\n",
      "  %/Transpose_output_0 = Transpose[perm = [0, 3, 1, 2]](%/Reshape_output_0)\n",
      "  %onnx::Slice_17 = Shape(%/Transpose_output_0)\n",
      "  %onnx::Slice_18 = Constant[value = <Tensor>]()\n",
      "  %onnx::Slice_19 = Constant[value = <Tensor>]()\n",
      "  %onnx::Slice_20 = Constant[value = <Tensor>]()\n",
      "  %onnx::Concat_21 = Slice(%onnx::Slice_17, %onnx::Slice_19, %onnx::Slice_20, %onnx::Slice_18)\n",
      "  %onnx::Concat_46 = Constant[value = <Tensor>]()\n",
      "  %onnx::Resize_23 = Concat[axis = 0](%onnx::Concat_21, %onnx::Concat_46)\n",
      "  %onnx::Resize_24 = Constant[value = <Tensor>]()\n",
      "  %onnx::Resize_25 = Constant[value = <Tensor>]()\n",
      "  %pos_tokens.3 = Resize[coordinate_transformation_mode = 'half_pixel', cubic_coeff_a = -0.75, mode = 'linear', nearest_mode = 'floor'](%/Transpose_output_0, %onnx::Resize_24, %onnx::Resize_25, %onnx::Resize_23)\n",
      "  %/Transpose_1_output_0 = Transpose[perm = [0, 2, 3, 1]](%pos_tokens.3)\n",
      "  %/Shape_output_0 = Shape(%/Transpose_1_output_0)\n",
      "  %/Constant_5_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Constant_6_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Constant_7_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Slice_1_output_0 = Slice(%/Shape_output_0, %/Constant_6_output_0, %/Constant_7_output_0, %/Constant_5_output_0)\n",
      "  %/Constant_8_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Constant_9_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Constant_10_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Slice_2_output_0 = Slice(%/Shape_output_0, %/Constant_9_output_0, %/Constant_10_output_0, %/Constant_8_output_0)\n",
      "  %/Constant_11_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Concat_output_0 = Concat[axis = 0](%/Slice_1_output_0, %/Constant_11_output_0, %/Slice_2_output_0)\n",
      "  %/Reshape_1_output_0 = Reshape(%/Transpose_1_output_0, %/Concat_output_0)\n",
      "  %output = Concat[axis = 1](%/Slice_output_0, %/Reshape_1_output_0)\n",
      "  return %output\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(onnx.helper.printable_graph(pose_embeding_onnx.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "660e0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "ort_session = ort.InferenceSession(\"pose_embeding.onnx\")\n",
    "pose_embed_np = pos_embed.numpy().astype(np.float32)\n",
    "\n",
    "onnx.checker.check_model(\"pose_embeding.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4727d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "outputs = ort_session.run([\"output\"], {\"pose_embed\": pose_embed_np})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c64821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8dba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987acb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d80711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecece14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9ea39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc932a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60332124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef4014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0b8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cecd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f65ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0930b74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.64137936,  0.02309975, -0.23200642, ..., -0.32407302,\n",
       "          1.519191  ,  0.5005934 ],\n",
       "        [ 0.00505867,  0.78447485, -0.09199175, ...,  0.89557576,\n",
       "         -1.5344915 , -1.5433446 ],\n",
       "        [-1.0785986 ,  0.5127451 ,  0.17516923, ..., -2.270945  ,\n",
       "         -0.14369453, -0.7394889 ],\n",
       "        ...,\n",
       "        [-1.3477877 , -0.42172876,  0.02565104, ...,  0.748587  ,\n",
       "         -0.3982138 ,  0.7097116 ],\n",
       "        [-1.8790638 ,  0.64939225, -0.9743109 , ...,  0.34152257,\n",
       "          1.6852396 ,  1.177382  ],\n",
       "        [ 0.542683  , -1.2692044 ,  0.42710724, ..., -0.8933482 ,\n",
       "         -0.8667681 , -1.0421079 ]],\n",
       "\n",
       "       [[ 0.40192738, -1.4155567 , -2.0919912 , ..., -1.4260367 ,\n",
       "         -1.3999703 , -0.4659327 ],\n",
       "        [-1.0190424 , -0.27929085, -2.0398881 , ..., -0.8584975 ,\n",
       "          0.24301495, -0.58877426],\n",
       "        [ 1.532979  ,  1.101683  ,  0.61486924, ...,  1.5265759 ,\n",
       "          0.629919  ,  0.538811  ],\n",
       "        ...,\n",
       "        [-0.7861958 , -1.4978276 ,  0.9127483 , ...,  0.19850503,\n",
       "         -0.47360972, -0.15618242],\n",
       "        [-1.0814437 , -0.4714652 , -0.08728374, ..., -1.0171391 ,\n",
       "          0.14188752,  1.4922736 ],\n",
       "        [ 0.63010377, -0.9760565 , -0.16187702, ...,  0.7766855 ,\n",
       "          0.18600088,  0.8537299 ]],\n",
       "\n",
       "       [[ 0.5190737 ,  0.8958156 , -0.68305266, ...,  1.3988918 ,\n",
       "          1.5434532 , -0.8849615 ],\n",
       "        [-0.17627496,  3.2188556 ,  0.38810784, ...,  0.7338493 ,\n",
       "          0.6484748 ,  0.8378898 ],\n",
       "        [-0.12663136, -0.87621635, -0.02522457, ...,  1.0991125 ,\n",
       "          1.0506874 ,  0.18775678],\n",
       "        ...,\n",
       "        [ 1.7411283 , -0.27074245,  1.7297595 , ...,  1.2154309 ,\n",
       "          1.0450988 ,  0.70197695],\n",
       "        [-0.43074256, -2.4770803 , -1.5876818 , ..., -0.06619986,\n",
       "          1.9770583 , -0.2584925 ],\n",
       "        [-0.78825694,  1.0458708 , -1.1484292 , ..., -0.01015294,\n",
       "          2.1399298 , -0.3072838 ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82dd73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19a3c95a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Input Error: Only 3D, 4D and 5D input Tensors supported (got 5D) for the modes: nearest | linear | bilinear | bicubic | trilinear | area | nearest-exact (got bicubic)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m Model()\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 22\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_10\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m trace\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m result_model_5 \u001b[38;5;241m=\u001b[39m model(inp_5)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:792\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    809\u001b[0m ):\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:1049\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1048\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m-> 1049\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1410\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1410\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[52], line 11\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     10\u001b[0m     new_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m---> 11\u001b[0m     up_x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbicubic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m up_x\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3973\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3971\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot 5D input, but bilinear mode needs 4D input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3973\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   3974\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Error: Only 3D, 4D and 5D input Tensors supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3975\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mD) for the modes: nearest | linear | bilinear | bicubic | trilinear | area | nearest-exact\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3976\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), mode)\n\u001b[1;32m   3977\u001b[0m )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Input Error: Only 3D, 4D and 5D input Tensors supported (got 5D) for the modes: nearest | linear | bilinear | bicubic | trilinear | area | nearest-exact (got bicubic)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv = torch.nn.Conv3d(5, 1, 3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_x = self.conv(x)\n",
    "        up_x = torch.nn.functional.interpolate(\n",
    "            new_x, scale_factor=(2,2,2), mode=\"bicubic\", align_corners=True)\n",
    "        return up_x\n",
    "\n",
    "\n",
    "inp_5 = torch.randn(1, 5, 5, 5, 5)\n",
    "inp_10 = torch.randn(1, 5, 10, 10, 10)\n",
    "inp_15 = torch.randn(1, 5, 15, 15, 15)\n",
    "\n",
    "model = Model()\n",
    "model.eval()\n",
    "trace = torch.jit.trace(model, inp_10)\n",
    "trace.save(\"trace.pth\")\n",
    "\n",
    "result_model_5 = model(inp_5)\n",
    "result_model_10 = model(inp_10)\n",
    "result_model_15 = model(inp_15)\n",
    "print(\"Shape  5, {} ||| {}\".format(result_model_5.shape, result_model_5.shape))\n",
    "print(\"Shape 10, {} ||| {}\".format(result_model_10.shape, result_model_10.shape))\n",
    "print(\"Shape 15, {} ||| {}\".format(result_model_15.shape, result_model_15.shape))\n",
    "t_model = torch.jit.load(\"trace.pth\")\n",
    "result_t_model_5 = t_model(inp_5)\n",
    "result_t_model_10 = t_model(inp_10)\n",
    "result_t_model_15 = t_model(inp_15)\n",
    "\n",
    "print(\"Shape  5, {} ||| {}\".format(result_model_5.shape, result_t_model_5.shape))\n",
    "print(\"Shape 10, {} ||| {}\".format(result_model_10.shape, result_t_model_10.shape))\n",
    "print(\"Shape 15, {} ||| {}\".format(result_model_15.shape, result_t_model_15.shape))\n",
    "torch.allclose(result_model_5, result_t_model_5)\n",
    "torch.allclose(result_model_10, result_t_model_10)\n",
    "torch.allclose(result_model_15, result_t_model_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5154c301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2240, 2240])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(original_name=Model)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(Model, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "    def forward(self, x):\n",
    "        xp = nn.functional.interpolate(\n",
    "            x,\n",
    "            scale_factor=(self.scale_factor),\n",
    "            mode=\"bicubic\",\n",
    "        )\n",
    "        return xp\n",
    "\n",
    "\n",
    "\n",
    "model = Model((10,10))\n",
    "model.eval()\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "y = model(x)\n",
    "print(y.shape)\n",
    "\n",
    "# This will fail\n",
    "torch.jit.trace(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "def0c1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(original_name=Model)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.jit.script(Model(torch.tensor((10,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7ddf0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelv2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelv2, self).__init__()\n",
    "    def forward(self, x, scale_factor):\n",
    "        xp = nn.functional.interpolate(\n",
    "            x,\n",
    "            scale_factor=(scale_factor),\n",
    "            mode=\"bicubic\",\n",
    "        )\n",
    "        return xp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57232e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = (10, 10)\n",
    "modelv2 = Modelv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b298695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2163,  0.2205,  0.2179,  ..., -2.2976, -2.2993, -2.2966],\n",
       "          [ 0.2241,  0.2285,  0.2258,  ..., -2.3270, -2.3287, -2.3259],\n",
       "          [ 0.2193,  0.2236,  0.2209,  ..., -2.3089, -2.3105, -2.3078],\n",
       "          ...,\n",
       "          [ 2.2916,  2.3073,  2.2976,  ..., -0.2974, -0.2997, -0.2960],\n",
       "          [ 2.2995,  2.3152,  2.3055,  ..., -0.2991, -0.3014, -0.2977],\n",
       "          [ 2.2868,  2.3024,  2.2928,  ..., -0.2963, -0.2986, -0.2949]],\n",
       "\n",
       "         [[-0.7826, -0.7892, -0.7851,  ..., -0.5792, -0.5839, -0.5763],\n",
       "          [-0.7868, -0.7935, -0.7894,  ..., -0.5793, -0.5840, -0.5763],\n",
       "          [-0.7842, -0.7909, -0.7868,  ..., -0.5792, -0.5839, -0.5763],\n",
       "          ...,\n",
       "          [ 0.4657,  0.4742,  0.4689,  ...,  1.0051,  1.0062,  1.0044],\n",
       "          [ 0.4671,  0.4756,  0.4704,  ...,  1.0064,  1.0074,  1.0057],\n",
       "          [ 0.4648,  0.4732,  0.4680,  ...,  1.0043,  1.0054,  1.0036]],\n",
       "\n",
       "         [[-1.9678, -1.9872, -1.9752,  ..., -0.2263, -0.2298, -0.2241],\n",
       "          [-1.9812, -2.0006, -1.9886,  ..., -0.2423, -0.2461, -0.2400],\n",
       "          [-1.9729, -1.9923, -1.9803,  ..., -0.2324, -0.2360, -0.2302],\n",
       "          ...,\n",
       "          [-0.6697, -0.6741, -0.6714,  ..., -1.3688, -1.3754, -1.3647],\n",
       "          [-0.6701, -0.6745, -0.6718,  ..., -1.3766, -1.3833, -1.3724],\n",
       "          [-0.6694, -0.6738, -0.6711,  ..., -1.3639, -1.3705, -1.3599]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelv2(x, scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97d964f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_modelv2 = torch.jit.script(Modelv2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b04e8b07",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/tmp/ipykernel_3803/558728084.py\", line 5, in forward\n    def forward(self, x, scale_factor):\n        xp = nn.functional.interpolate(\n             ~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n            x,\n            scale_factor=(scale_factor),\nRuntimeError: Cannot input a tensor of dimension other than 0 as a scalar argument\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscripted_modelv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/tmp/ipykernel_3803/558728084.py\", line 5, in forward\n    def forward(self, x, scale_factor):\n        xp = nn.functional.interpolate(\n             ~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n            x,\n            scale_factor=(scale_factor),\nRuntimeError: Cannot input a tensor of dimension other than 0 as a scalar argument\n"
     ]
    }
   ],
   "source": [
    "scripted_modelv2(x, torch.tensor(scale_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34e29307",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "forward() Expected a value of type 'Tensor (inferred)' for argument 'scale_factor' but instead found type 'tuple'.\nInferred 'scale_factor' to be of type 'Tensor' because it was not annotated with an explicit type.\nPosition: 2\nValue: (10, 10)\nDeclaration: forward(__torch__.___torch_mangle_21.Modelv2 self, Tensor x, Tensor scale_factor) -> Tensor\nCast error details: Unable to cast (10, 10) to Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscripted_modelv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mRuntimeError\u001b[0m: forward() Expected a value of type 'Tensor (inferred)' for argument 'scale_factor' but instead found type 'tuple'.\nInferred 'scale_factor' to be of type 'Tensor' because it was not annotated with an explicit type.\nPosition: 2\nValue: (10, 10)\nDeclaration: forward(__torch__.___torch_mangle_21.Modelv2 self, Tensor x, Tensor scale_factor) -> Tensor\nCast error details: Unable to cast (10, 10) to Tensor"
     ]
    }
   ],
   "source": [
    "scripted_modelv2(x, scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65e489d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelv3(torch.jit.ScriptModule):\n",
    "    def __init__(self):\n",
    "        super(Modelv3, self).__init__()\n",
    "        \n",
    "    @torch.jit.script_method \n",
    "    def forward(self, x, scale_factor):\n",
    "        \n",
    "        xp = nn.functional.interpolate(\n",
    "            x,\n",
    "            scale_factor=(scale_factor),\n",
    "            mode=\"bicubic\",\n",
    "        )\n",
    "        return xp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19a544d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_modelv3 = Modelv3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47030668",
   "metadata": {},
   "source": [
    "scripted_modelv3(x, scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51de2bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "forward() Expected a value of type 'Tensor (inferred)' for argument 'scale_factor' but instead found type 'tuple'.\nInferred 'scale_factor' to be of type 'Tensor' because it was not annotated with an explicit type.\nPosition: 2\nValue: (10, 10)\nDeclaration: forward(__torch__.___torch_mangle_23.Modelv3 self, Tensor x, Tensor scale_factor) -> Tensor\nCast error details: Unable to cast (10, 10) to Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscripted_modelv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mRuntimeError\u001b[0m: forward() Expected a value of type 'Tensor (inferred)' for argument 'scale_factor' but instead found type 'tuple'.\nInferred 'scale_factor' to be of type 'Tensor' because it was not annotated with an explicit type.\nPosition: 2\nValue: (10, 10)\nDeclaration: forward(__torch__.___torch_mangle_23.Modelv3 self, Tensor x, Tensor scale_factor) -> Tensor\nCast error details: Unable to cast (10, 10) to Tensor"
     ]
    }
   ],
   "source": [
    "scripted_modelv3(x, scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a239f6f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/tmp/ipykernel_3803/4183376326.py\", line 8, in forward\n    def forward(self, x, scale_factor):\n        \n        xp = nn.functional.interpolate(\n             ~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n            x,\n            scale_factor=(scale_factor),\nRuntimeError: Cannot input a tensor of dimension other than 0 as a scalar argument\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscripted_modelv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/tmp/ipykernel_3803/4183376326.py\", line 8, in forward\n    def forward(self, x, scale_factor):\n        \n        xp = nn.functional.interpolate(\n             ~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n            x,\n            scale_factor=(scale_factor),\nRuntimeError: Cannot input a tensor of dimension other than 0 as a scalar argument\n"
     ]
    }
   ],
   "source": [
    "scripted_modelv3(x, torch.tensor(scale_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98656b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelv4(torch.jit.ScriptModule):\n",
    "    def __init__(self):\n",
    "        super(Modelv4, self).__init__()\n",
    "        \n",
    "    @torch.jit.script_method \n",
    "    def forward(self, x, scale_factor):\n",
    "        \n",
    "        scale_factor_list = scale_factor.tolist()\n",
    "        xp = nn.functional.interpolate(\n",
    "            x,\n",
    "            scale_factor=(scale_factor_list),\n",
    "            mode=\"bicubic\",\n",
    "        )\n",
    "        return xp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f62db35",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nExpected type hint for result of tolist():\n  File \"/tmp/ipykernel_3803/2478107352.py\", line 8\n    def forward(self, x, scale_factor):\n        \n        scale_factor_list = scale_factor.tolist()\n                            ~~~~~~~~~~~~~~~~~~~ <--- HERE\n        xp = nn.functional.interpolate(\n            x,\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scripted_modelv4 \u001b[38;5;241m=\u001b[39m \u001b[43mModelv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py:307\u001b[0m, in \u001b[0;36mScriptMeta.__init__.<locals>.init_then_script\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m infer_methods_to_compile(module)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_actual_script_module\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 307\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_script_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_stubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madded_methods_in_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Delete the Python attributes that now shadow the ScriptModule\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# ones, so that __getattr__ and __setattr__ will properly find\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# the scripted versions.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m concrete_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actual_script_module\u001b[38;5;241m.\u001b[39m_concrete_type\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:477\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    476\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[38;5;241m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_script_module_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstubs_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:543\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m concrete_type_store\u001b[38;5;241m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> 543\u001b[0m     \u001b[43mcreate_methods_and_properties_from_stubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcrete_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_stubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_stubs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;66;03m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;66;03m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:394\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    391\u001b[0m property_defs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdef_ \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[1;32m    392\u001b[0m property_rcbs \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mresolution_callback \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m property_stubs]\n\u001b[0;32m--> 394\u001b[0m \u001b[43mconcrete_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_methods_and_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperty_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_rcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_defaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nExpected type hint for result of tolist():\n  File \"/tmp/ipykernel_3803/2478107352.py\", line 8\n    def forward(self, x, scale_factor):\n        \n        scale_factor_list = scale_factor.tolist()\n                            ~~~~~~~~~~~~~~~~~~~ <--- HERE\n        xp = nn.functional.interpolate(\n            x,\n"
     ]
    }
   ],
   "source": [
    "scripted_modelv4 = Modelv4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532cf05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
