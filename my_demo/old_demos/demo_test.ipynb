{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5673ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8771f1d6",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd592897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from alphaction.config import cfg\n",
    "from alphaction.dataset import make_data_loader\n",
    "from alphaction.engine.inference import inference\n",
    "from alphaction.modeling.detector import build_detection_model\n",
    "from alphaction.utils.checkpoint import ActionCheckpointer\n",
    "from torch.utils.collect_env import get_pretty_env_info\n",
    "from alphaction.utils.comm import synchronize, get_rank\n",
    "from alphaction.utils.logger import setup_logger\n",
    "#pytorch issuse #973\n",
    "import resource\n",
    "\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (rlimit[1], rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e8871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048576, 1048576)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlimit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3fff25",
   "metadata": {},
   "source": [
    "### Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd57312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../config_files/VMAE-ViTB-16x4.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288d28f",
   "metadata": {},
   "source": [
    "changing config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec4c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(config_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42634bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model weight path\n",
    "cfg.merge_from_list([\"MODEL.WEIGHT\", \"../checkpoints/VMAE_ViTB_16x4.pth\"])\n",
    "# change output dir\n",
    "cfg.merge_from_list([\"OUTPUT_DIR\", \"../output_dir/\"])\n",
    "\n",
    "\n",
    "# change path for data_dir\n",
    "cfg.merge_from_list([\"DATA.PATH_TO_DATA_DIR\", \"/work/ava\"])\n",
    "\n",
    "# folder name of annotations\n",
    "cfg.merge_from_list([\"AVA.ANNOTATION_DIR\", \"annotations/\"])\n",
    "\n",
    "# file name of  frame_lists\n",
    "cfg.merge_from_list([\"AVA.TRAIN_LISTS\", ['sample.csv']])\n",
    "cfg.merge_from_list([\"AVA.TEST_LISTS\", ['sample.csv']])\n",
    "\n",
    "# file name of predicted_bboxes\n",
    "cfg.merge_from_list([\"AVA.TRAIN_GT_BOX_LISTS\", ['ava_sample_predicted_boxes.csv']])\n",
    "cfg.merge_from_list([\"AVA.TEST_GT_BOX_LISTS\", ['ava_sample_predicted_boxes.csv']])\n",
    "\n",
    "# file name of exlusions\n",
    "cfg.merge_from_list([\"AVA.EXCLUSION_FILE\", 'ava_sample_train_excluded_timestamps_v2.2.csv'])\n",
    "\n",
    "# number of batches in test scenario\n",
    "cfg.merge_from_list([\"TEST.VIDEOS_PER_BATCH\", 1])\n",
    "\n",
    "# number of workers\n",
    "cfg.merge_from_list([\"DATALOADER.NUM_WORKERS\", 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8736c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 09:51:16,183 alphaction INFO: Using 1 GPUs\n",
      "2024-01-22 09:51:16,184 alphaction INFO: AK:\n",
      "  TEST_GT_BOX_LISTS: ['kinetics/ak_val_gt.csv']\n",
      "AVA:\n",
      "  ANNOTATION_DIR: annotations/\n",
      "  BGR: False\n",
      "  EXCLUSION_FILE: ava_sample_train_excluded_timestamps_v2.2.csv\n",
      "  FRAME_DIR: frames/\n",
      "  FRAME_LIST_DIR: frame_lists/\n",
      "  GROUNDTRUTH_FILE: ava_val_v2.2.csv\n",
      "  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt\n",
      "  STRICT_EVAL: True\n",
      "  TEST_FORCE_FLIP: False\n",
      "  TEST_GT_BOX_LISTS: ['ava_sample_predicted_boxes.csv']\n",
      "  TEST_LISTS: ['sample.csv']\n",
      "  TRAIN_GT_BOX_LISTS: ['ava_sample_predicted_boxes.csv']\n",
      "  TRAIN_LISTS: ['sample.csv']\n",
      "  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]\n",
      "  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]\n",
      "  TRAIN_PCA_JITTER_ONLY: True\n",
      "  TRAIN_USE_COLOR_AUGMENTATION: False\n",
      "DATA:\n",
      "  DATASETS: ['ava_v2.2']\n",
      "  DECODING_BACKEND: pyav\n",
      "  INPUT_CHANNEL_NUM: [3]\n",
      "  MEAN: [0.45, 0.45, 0.45]\n",
      "  NUM_FRAMES: 16\n",
      "  PATH_TO_DATA_DIR: /work/ava\n",
      "  RANDOM_FLIP: True\n",
      "  REVERSE_INPUT_CHANNEL: False\n",
      "  SAMPLING_RATE: 4\n",
      "  STD: [0.225, 0.225, 0.225]\n",
      "  TARGET_FPS: 30\n",
      "  TEST_MAX_SCALE: 1333\n",
      "  TEST_MIN_SCALES: [256]\n",
      "  TRAIN_MAX_SCALE: 1333\n",
      "  TRAIN_MIN_SCALES: [256, 320]\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: False\n",
      "  NUM_WORKERS: 1\n",
      "  SIZE_DIVISIBILITY: 32\n",
      "KINETICS:\n",
      "  ANNOTATION_DIR: kinetics/annotations/\n",
      "  FRAME_LIST_DIR: kinetics/frame_lists/\n",
      "  TEST_GT_BOX_LISTS: ['kinetics_val_curated.csv']\n",
      "  TEST_LISTS: ['val.csv']\n",
      "  TRAIN_GT_BOX_LISTS: ['kinetics_train_curated.csv']\n",
      "  TRAIN_LISTS: ['train.csv']\n",
      "  VIDEO_DIR: \n",
      "MODEL:\n",
      "  BACKBONE:\n",
      "    BN_EPSILON: 1e-05\n",
      "    BN_INIT_GAMMA: 0.0\n",
      "    BN_MOMENTUM: 0.1\n",
      "    CONV_BODY: MAE-ViT-B\n",
      "    FROZEN_BN: False\n",
      "    I3D:\n",
      "      CONV3_GROUP_NL: False\n",
      "      CONV3_NONLOCAL: True\n",
      "      CONV4_NONLOCAL: True\n",
      "    PATHWAYS: 1\n",
      "    SLOWFAST:\n",
      "      BETA: 0.125\n",
      "      FAST:\n",
      "        ACTIVE: True\n",
      "        CONV3_GROUP_NL: False\n",
      "        CONV3_NONLOCAL: False\n",
      "        CONV4_NONLOCAL: False\n",
      "      LATERAL: tconv\n",
      "      SLOW:\n",
      "        ACTIVE: True\n",
      "        CONV3_GROUP_NL: False\n",
      "        CONV3_NONLOCAL: True\n",
      "        CONV4_NONLOCAL: True\n",
      "  NONLOCAL:\n",
      "    BN_EPSILON: 1e-05\n",
      "    BN_INIT_GAMMA: 0.0\n",
      "    BN_MOMENTUM: 0.1\n",
      "    CONV_INIT_STD: 0.01\n",
      "    FROZEN_BN: False\n",
      "    NO_BIAS: False\n",
      "    USE_BN: True\n",
      "    USE_MAXPOOL: True\n",
      "    USE_SCALE: True\n",
      "    USE_SOFTMAX: True\n",
      "    USE_ZERO_INIT_CONV: False\n",
      "  STM:\n",
      "    ACTION_CLASSES: 80\n",
      "    ACTION_WEIGHT: 24.0\n",
      "    ACTIVATION: ReLU\n",
      "    BACKGROUND_WEIGHT: 0.1\n",
      "    DIM_FEEDFORWARD: 2048\n",
      "    DROPOUT: 0.0\n",
      "    GIOU_WEIGHT: 2.0\n",
      "    HIDDEN_DIM: 256\n",
      "    INTERMEDIATE_SUPERVISION: True\n",
      "    L1_WEIGHT: 2.0\n",
      "    MEM_ACTIVE: False\n",
      "    NUM_ACT: 1\n",
      "    NUM_CLS: 1\n",
      "    NUM_FCS: 2\n",
      "    NUM_HEADS: 8\n",
      "    NUM_QUERIES: 100\n",
      "    NUM_REG: 1\n",
      "    NUM_STAGES: 6\n",
      "    N_GROUPS: 4\n",
      "    OBJECT_CLASSES: 1\n",
      "    OBJECT_WEIGHT: 2.0\n",
      "    OUT_MULTIPLIER: 4\n",
      "    PERSON_THRESHOLD: 0.6\n",
      "    SPATIAL_POINTS: 32\n",
      "    TEMPORAL_POINTS: 8\n",
      "  WEIGHT: ../checkpoints/VMAE_ViTB_16x4.pth\n",
      "NONLOCAL:\n",
      "  GROUP: [[1], [1], [1], [1]]\n",
      "  INSTANTIATION: dot_product\n",
      "  LOCATION: [[[]], [[]], [[]], [[]]]\n",
      "  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]\n",
      "OUTPUT_DIR: ../output_dir/\n",
      "RESNET:\n",
      "  DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "  DEPTH: 50\n",
      "  INPLACE_RELU: True\n",
      "  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]\n",
      "  NUM_GROUPS: 1\n",
      "  SPATIAL_DILATIONS: [[1], [1], [1], [1]]\n",
      "  SPATIAL_STRIDES: [[1], [2], [2], [2]]\n",
      "  STRIDE_1X1: False\n",
      "  TRANS_FUNC: bottleneck_transform\n",
      "  WIDTH_PER_GROUP: 64\n",
      "  ZERO_INIT_FINAL_BN: False\n",
      "SLOWFAST:\n",
      "  ALPHA: 8\n",
      "  BETA_INV: 8\n",
      "  FUSION_CONV_CHANNEL_RATIO: 2\n",
      "  FUSION_KERNEL_SZ: 5\n",
      "SOLVER:\n",
      "  BASE_LR: 1e-05\n",
      "  BETAS: (0.9, 0.999)\n",
      "  CHECKPOINT_PERIOD: 1\n",
      "  EVAL_AFTER: 3\n",
      "  EVAL_PERIOD: 1\n",
      "  GAMMA: 0.1\n",
      "  ITER_PER_EPOCH: 23048\n",
      "  MAX_EPOCH: 12\n",
      "  OPTIMIZING_METHOD: adamw\n",
      "  SCHEDULER: warmup_multi_step\n",
      "  STEPS: (5, 8)\n",
      "  VIDEOS_PER_BATCH: 8\n",
      "  WARMUP_EPOCH: 2\n",
      "  WARMUP_FACTOR: 0.1\n",
      "  WARMUP_METHOD: linear\n",
      "  WARMUP_ON: True\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BN: 0.0\n",
      "TEST:\n",
      "  VIDEOS_PER_BATCH: 1\n",
      "ViT:\n",
      "  ATTN_DROP_RATE: 0.0\n",
      "  DEPTH: 12\n",
      "  DROP_PATH_RATE: 0.2\n",
      "  DROP_RATE: 0.0\n",
      "  EMBED_DIM: 768\n",
      "  INIT_VALUES: 0.0\n",
      "  IN_CHANS: 3\n",
      "  LAYER_DECAY: 1.0\n",
      "  MLP_RATIO: 4\n",
      "  NO_WEIGHT_DECAY: ['pos_embed']\n",
      "  NUM_HEADS: 12\n",
      "  PATCH_SIZE: 16\n",
      "  PRETRAIN_IMG_SIZE: 224\n",
      "  QKV_BIAS: True\n",
      "  QK_SCALE: None\n",
      "  TUBELET_SIZE: 2\n",
      "  USE_CHECKPOINT: True\n",
      "  USE_LEARNABLE_POS_EMB: False\n",
      "  WEIGHT_DECAY: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Print experimental infos.\n",
    "save_dir = \"\"\n",
    "logger = setup_logger(\"alphaction\", save_dir, get_rank())\n",
    "logger.info(\"Using {} GPUs\".format(1))\n",
    "logger.info(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179f666c",
   "metadata": {},
   "source": [
    "### building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e8af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detection_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e1f412e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STMDetector(\n",
       "  (backbone): ViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0181818176060915)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.036363635212183)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05454545468091965)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.072727270424366)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09090908616781235)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10909091681241989)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12727272510528564)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1454545557498932)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16363637149333954)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1818181872367859)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000000298023224)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose3d(384, 192, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (4): Conv3d(192, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (5): LayerNorm()\n",
       "      (6): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): Conv3d(384, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (1): LayerNorm()\n",
       "      (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (stm_head): STMDecoder(\n",
       "    (init_spatial_queries): Embedding(100, 256)\n",
       "    (init_temporal_queries): Embedding(100, 256)\n",
       "    (decoder_stages): ModuleList(\n",
       "      (0): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (1): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (2): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (3): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (4): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (5): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): SetCriterion(\n",
       "      (matcher): HungarianMatcher()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0e7e7",
   "metadata": {},
   "source": [
    "### loading weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b10e5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[43mcfg\u001b[49m\u001b[38;5;241m.\u001b[39mOUTPUT_DIR\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "output_dir = cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850dcaa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ActionCheckpointer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m \u001b[43mActionCheckpointer\u001b[49m(cfg, model, save_dir\u001b[38;5;241m=\u001b[39moutput_dir)\n\u001b[1;32m      2\u001b[0m checkpointer\u001b[38;5;241m.\u001b[39mload(cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mWEIGHT)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ActionCheckpointer' is not defined"
     ]
    }
   ],
   "source": [
    "checkpointer = ActionCheckpointer(cfg, model, save_dir=output_dir)\n",
    "checkpointer.load(cfg.MODEL.WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7b2e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1056f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed = num_gpus > 1\n",
    "distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "717a6bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ava_v2.2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.DATA.DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af7a42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folders = [None] * len(cfg.DATA.DATASETS)\n",
    "output_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f694f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ava_v2.2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names = cfg.DATA.DATASETS\n",
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7064af06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_active = cfg.MODEL.STM.MEM_ACTIVE\n",
    "mem_active  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "654fb536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output_dir/inference/ava_v2.2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cfg.OUTPUT_DIR:\n",
    "    for idx, dataset_name in enumerate(dataset_names):\n",
    "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\", dataset_name)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_folders[idx] = output_folder\n",
    "\n",
    "output_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e72c9f",
   "metadata": {},
   "source": [
    "### create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4c0bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 09:51:24,751 alphaction.dataset.datasets.ava_helper INFO: Finished loading image paths from: /work/ava/frame_lists/sample.csv\n",
      "2024-01-22 09:51:24,766 alphaction.dataset.datasets.ava_helper INFO: Finished loading annotations from: /work/ava/annotations/ava_sample_predicted_boxes.csv\n",
      "2024-01-22 09:51:24,767 alphaction.dataset.datasets.ava_helper INFO: Number of unique boxes: 1828\n",
      "2024-01-22 09:51:24,768 alphaction.dataset.datasets.ava_helper INFO: Number of annotations: 2300\n",
      "2024-01-22 09:51:24,769 alphaction.dataset.datasets.ava_helper INFO: 860 keyframes used.\n",
      "2024-01-22 09:51:24,770 alphaction.dataset.datasets.ava_dataset INFO: === AVA dataset summary ===\n",
      "2024-01-22 09:51:24,771 alphaction.dataset.datasets.ava_dataset INFO: Split: test\n",
      "2024-01-22 09:51:24,772 alphaction.dataset.datasets.ava_dataset INFO: Number of videos: 1\n",
      "2024-01-22 09:51:24,772 alphaction.dataset.datasets.ava_dataset INFO: Number of frames: 27030\n",
      "2024-01-22 09:51:24,773 alphaction.dataset.datasets.ava_dataset INFO: Number of key frames: 860\n",
      "2024-01-22 09:51:24,774 alphaction.dataset.datasets.ava_dataset INFO: Number of boxes: 1828.\n"
     ]
    }
   ],
   "source": [
    "data_loaders_test = make_data_loader(cfg, is_train=False, is_distributed=distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d1fbe",
   "metadata": {},
   "source": [
    "### INSIDE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84cd3835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output_dir/inference/ava_v2.2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder = output_folders[0]\n",
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b93d9107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ava_v2.2'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = dataset_names[0]\n",
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c3f2eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7ff136dd9ee0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader_test = data_loaders_test[0]\n",
    "data_loader_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1295f6",
   "metadata": {},
   "source": [
    "#### IMPORTING OF MODULES INSIDE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39065440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from alphaction.dataset.datasets.evaluation import evaluate\n",
    "from alphaction.utils.comm import get_rank, is_main_process, all_gather, gather, synchronize, get_world_size\n",
    "from alphaction.structures.memory_pool import MemoryPool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8815f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20ce209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fbe2745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_devices = get_world_size()\n",
    "num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd612f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"alphaction.inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba8d36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_loader_test.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46580201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 09:51:24,841 alphaction.inference INFO: Start evaluation on ava_v2.2 dataset(860 videos).\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Start evaluation on {} dataset({} videos).\".format(dataset_name, len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "555dd6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STMDetector(\n",
       "  (backbone): ViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0181818176060915)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.036363635212183)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05454545468091965)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.072727270424366)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09090908616781235)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10909091681241989)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12727272510528564)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1454545557498932)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16363637149333954)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1818181872367859)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000000298023224)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose3d(384, 192, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (4): Conv3d(192, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (5): LayerNorm()\n",
       "      (6): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): Conv3d(384, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (1): LayerNorm()\n",
       "      (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (stm_head): STMDecoder(\n",
       "    (init_spatial_queries): Embedding(100, 256)\n",
       "    (init_temporal_queries): Embedding(100, 256)\n",
       "    (decoder_stages): ModuleList(\n",
       "      (0): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (1): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (2): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (3): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (4): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (5): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): SetCriterion(\n",
       "      (matcher): HungarianMatcher()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49d50e",
   "metadata": {},
   "source": [
    "If False, 'compute_on_dataset' will call 'compute_on_dataset_1stage',else, call 'compute_on_dataset_2stage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b74dd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef184b",
   "metadata": {},
   "source": [
    "##### inside of 'compute_on_dataset_1stage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94ed4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict = compute_on_dataset_1stage(model, data_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653c9c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "if get_world_size() == 1:\n",
    "    extra_args = {}\n",
    "else:\n",
    "    rank = get_rank()\n",
    "    extra_args = dict(desc=\"rank {}\".format(rank))\n",
    "    \n",
    "extra_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c010ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c306bb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.8322, -0.9194, -0.9368,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.5359, -0.6231, -0.6928,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.5185, -0.6580, -0.8148,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.7800, -0.8148, -0.8148,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.5359, -0.6057, -0.6580,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.5882, -0.7277, -0.8497,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.8780, -1.8780, -1.8780,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8780, -1.8780, -1.8780,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8780, -1.8780, -1.8780,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.7451, -0.8148, -0.8148,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.5534, -0.6231, -0.6754,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.5534, -0.6405, -0.7625,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[-1.8257, -1.8257, -1.8257,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.4837, -0.5185, -0.5534,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.6231, -0.6928, -0.7800,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.4597, -1.5468, -1.6514,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.8257, -1.8257, -1.8257,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.3965, -0.4314, -0.5011,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.7974, -0.8671, -0.9368,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.5643, -1.6166, -1.7037,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.8257, -1.8257, -1.8257,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.3965, -0.4314, -0.4837,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.1285, -1.1808, -1.2680,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.6340, -1.7037, -1.8083,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       " \n",
       " \n",
       "          [[[-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.1525, -0.2397, -0.2222,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1264,  0.0392, -0.0131,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1612,  0.0218, -0.1351,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.1002, -0.1525, -0.1525,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1264,  0.0392,  0.0044,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0566, -0.0828, -0.2048,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.7908, -1.7908, -1.7908,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7908, -1.7908, -1.7908,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7908, -1.7908, -1.7908,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.0828, -0.1525, -0.1525,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1089,  0.0218, -0.0131,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0915,  0.0044, -0.1176,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[-1.7386, -1.7386, -1.7386,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.1786,  0.1786,  0.1612,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0392, -0.0131, -0.0654,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.7974, -0.8671, -0.9368,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.7386, -1.7386, -1.7386,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.1786,  0.1438,  0.1264,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.2397, -0.2919, -0.3617,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.0065, -1.0588, -1.1285,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.7386, -1.7386, -1.7386,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.7560, -1.7560, -1.7560,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [ 0.1786,  0.1786,  0.1438,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.5534, -0.5882, -0.6405,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.0588, -1.0937, -1.1808,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       " \n",
       " \n",
       "          [[[-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.4314, -0.5011, -0.5011,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.1525, -0.2397, -0.2919,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.1525, -0.2919, -0.4488,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.3617, -0.4139, -0.4139,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.1525, -0.2397, -0.2745,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.2397, -0.3791, -0.5011,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.8954, -1.8954, -1.8954,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8954, -1.8954, -1.8954,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8954, -1.8954, -1.8954,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.3442, -0.4139, -0.4139,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.1699, -0.2397, -0.2919,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.2048, -0.3094, -0.4139,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           ...,\n",
       " \n",
       "           [[-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.0479, -0.0654, -0.0828,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.1874, -0.2397, -0.3094,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.0240, -1.0937, -1.1808,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.0131, -0.0479, -0.0828,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.4314, -0.4837, -0.5534,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.1983, -1.2505, -1.3203,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "           [[-1.8431, -1.8431, -1.8431,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.8606, -1.8606, -1.8606,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            ...,\n",
       "            [-0.0131, -0.0305, -0.0654,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-0.7451, -0.7800, -0.8497,  ...,  0.0000,  0.0000,  0.0000],\n",
       "            [-1.2505, -1.2854, -1.3725,  ...,  0.0000,  0.0000,  0.0000]]]]]),\n",
       " None,\n",
       " tensor([[346., 256., 346., 256.]]),\n",
       " (array([[112.6656,  47.36  , 162.432 , 227.072 ],\n",
       "         [112.6656,  47.36  , 162.432 , 227.072 ],\n",
       "         [216.3456,  39.168 , 275.4432, 214.528 ],\n",
       "         [175.5648,  29.952 , 223.9488, 198.912 ],\n",
       "         [ 76.7232,   7.936 , 125.1072, 135.424 ],\n",
       "         [  1.0368,  32.    ,  41.1264, 214.272 ],\n",
       "         [ 37.3248,  36.608 ,  97.8048, 206.08  ],\n",
       "         [267.1488,  36.608 , 297.9072,  89.856 ],\n",
       "         [243.9936,  26.88  , 271.9872,  79.36  ],\n",
       "         [278.208 ,  73.984 , 344.5632, 253.696 ],\n",
       "         [294.4512,  44.8   , 321.0624,  85.76  ]]),),\n",
       " (array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32),),\n",
       " ([0, 902],),\n",
       " (0,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "712f2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader_test, **extra_args):\n",
    "            slow_video, fast_video, whwh, boxes, labels, metadata, idx = batch\n",
    "            slow_video = slow_video.to(device)\n",
    "            if fast_video is not None:\n",
    "                fast_video = fast_video.to(device)\n",
    "            whwh = whwh.to(device)\n",
    "            action_score_list, box_list = model(slow_video, fast_video, whwh, boxes, labels)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e8a39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    slow_video, fast_video, whwh, boxes, labels, metadata, idx = batch\n",
    "\n",
    "    slow_video = slow_video.to(device)\n",
    "\n",
    "\n",
    "    if fast_video is not None:\n",
    "        fast_video = fast_video.to(device)\n",
    "    whwh = whwh.to(device)\n",
    "    \n",
    "    # INFERENCE\n",
    "    action_score_list, box_list = model(slow_video, fast_video, whwh, boxes, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d60e49",
   "metadata": {},
   "source": [
    "### INPUT BATCH DECOMPOSITION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8985b3",
   "metadata": {},
   "source": [
    "#### slow_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a775ab72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 256, 352])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_video.shape # 1x3x16x256x352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5f3926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_video.dtype, slow_video.device # torch.float32, device(type='cuda', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a27dc3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8606, -1.8606, -1.8606, -1.8606, -1.8606],\n",
       "        [-1.8606, -1.8606, -1.8606, -1.8606, -1.8606],\n",
       "        [-1.8606, -1.8606, -1.8606, -1.8606, -1.8606],\n",
       "        [-1.8431, -1.8431, -1.8431, -1.8431, -1.8431],\n",
       "        [-1.8257, -1.8257, -1.8257, -1.8257, -1.8257]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_video[0,2,0,0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b193220",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfast_video\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "fast_video.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa0d2c",
   "metadata": {},
   "source": [
    "#### whwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e1677fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[346., 256., 346., 256.]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whwh # tensor([[346., 256., 346., 256.]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db6bd1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4]), torch.float32, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whwh.shape, whwh.dtype, whwh.device # torch.Size([1, 4]), torch.float32, device(type='cuda', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a92cc2",
   "metadata": {},
   "source": [
    "### OUPUT MODEL DECOMPOSITION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bd3e75",
   "metadata": {},
   "source": [
    "#### action_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbbbb385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[9.1237e-04, 1.8565e-06, 3.8518e-04, 5.2749e-03, 1.0854e-04, 1.1021e-04,\n",
       "          4.8070e-04, 1.1244e-04, 3.7187e-02, 3.0474e-04, 6.2452e-04, 9.7247e-01,\n",
       "          4.7521e-06, 2.7996e-03, 7.5738e-05, 3.3534e-06, 9.5618e-02, 3.4626e-04,\n",
       "          2.2128e-06, 5.8158e-06, 1.6095e-05, 4.5821e-04, 1.6409e-06, 1.5436e-05,\n",
       "          7.7230e-07, 2.0286e-04, 1.5550e-03, 1.4416e-05, 1.8330e-04, 1.5747e-05,\n",
       "          4.1002e-06, 1.7715e-09, 2.1835e-05, 9.0983e-04, 1.5934e-04, 4.9503e-05,\n",
       "          1.5614e-03, 1.3252e-04, 1.9455e-05, 5.2948e-06, 1.4612e-03, 4.8311e-05,\n",
       "          1.2096e-04, 1.1396e-05, 3.6527e-04, 1.2366e-04, 7.0961e-05, 2.1094e-05,\n",
       "          1.3564e-04, 7.7215e-08, 4.4962e-05, 1.2097e-04, 2.2823e-06, 1.5885e-03,\n",
       "          4.0419e-05, 5.5051e-03, 2.5459e-04, 2.1811e-03, 7.6489e-03, 2.3249e-05,\n",
       "          8.6529e-04, 5.5949e-06, 1.0235e-04, 1.0506e-02, 6.0015e-05, 8.2875e-03,\n",
       "          9.4192e-04, 8.3792e-05, 1.2272e-02, 8.4177e-04, 7.4537e-05, 8.0691e-05,\n",
       "          1.2542e-04, 3.9908e-01, 7.4738e-05, 2.7076e-03, 1.1440e-02, 1.8044e-04,\n",
       "          6.5097e-02, 8.0956e-01],\n",
       "         [2.7564e-03, 9.7457e-06, 3.2352e-03, 3.9616e-03, 2.5154e-04, 8.3979e-04,\n",
       "          2.4075e-03, 1.2219e-04, 9.0672e-01, 7.3921e-04, 4.6526e-04, 8.6366e-02,\n",
       "          7.6875e-06, 2.5804e-03, 1.4090e-04, 8.3569e-08, 1.5715e-02, 7.4525e-05,\n",
       "          5.1954e-08, 9.1362e-06, 6.3670e-07, 5.1328e-05, 2.0429e-07, 2.3751e-05,\n",
       "          5.4745e-06, 1.4335e-04, 5.5860e-04, 9.1727e-06, 3.1628e-04, 9.1707e-07,\n",
       "          4.9195e-07, 4.9048e-09, 1.0586e-06, 4.2092e-03, 1.5347e-04, 3.8443e-04,\n",
       "          3.1009e-04, 7.3746e-05, 7.0839e-07, 8.6557e-08, 5.0254e-04, 2.4896e-05,\n",
       "          1.6541e-05, 1.0430e-06, 4.9018e-04, 2.3477e-04, 4.7713e-05, 4.9933e-05,\n",
       "          3.6387e-05, 1.1308e-08, 1.8310e-05, 4.5884e-05, 2.1790e-06, 6.8764e-04,\n",
       "          4.3843e-06, 8.2167e-03, 1.0408e-04, 6.4232e-04, 4.0324e-03, 5.8525e-06,\n",
       "          2.8349e-04, 4.1152e-06, 1.0941e-05, 7.3367e-02, 8.6430e-05, 7.9741e-03,\n",
       "          8.2736e-04, 1.9695e-05, 1.4259e-03, 1.2580e-03, 6.3640e-04, 5.8438e-05,\n",
       "          4.6405e-04, 7.8899e-02, 4.2299e-05, 2.8472e-04, 1.6636e-03, 1.1305e-04,\n",
       "          3.5900e-02, 5.6618e-01],\n",
       "         [6.6954e-04, 3.7178e-06, 1.3655e-03, 1.5721e-03, 8.1749e-05, 2.5048e-04,\n",
       "          4.5936e-04, 7.6151e-05, 5.4792e-02, 2.3723e-04, 3.1226e-03, 9.3698e-01,\n",
       "          1.7387e-05, 2.1270e-03, 1.9918e-04, 2.9165e-06, 1.3351e-01, 3.4083e-04,\n",
       "          2.0397e-06, 5.9679e-06, 1.9544e-05, 3.7776e-04, 2.6412e-06, 2.5698e-05,\n",
       "          7.4711e-07, 1.4918e-04, 4.3579e-03, 3.2545e-05, 2.4584e-04, 4.7664e-06,\n",
       "          1.6528e-06, 3.1183e-09, 8.6339e-06, 2.2230e-03, 6.7497e-05, 1.1987e-04,\n",
       "          8.6368e-04, 1.5884e-04, 1.2663e-05, 2.0210e-05, 2.8651e-03, 9.2973e-05,\n",
       "          1.5090e-04, 9.9988e-06, 3.4469e-04, 2.2972e-04, 9.3412e-05, 4.3463e-05,\n",
       "          9.5796e-05, 3.3036e-07, 8.1318e-05, 2.2784e-04, 1.4271e-06, 1.0335e-03,\n",
       "          6.2465e-05, 2.2191e-02, 2.8322e-04, 1.1828e-03, 4.9842e-03, 1.7343e-05,\n",
       "          8.2991e-04, 1.0905e-05, 1.0829e-04, 1.2690e-02, 1.3911e-04, 1.0003e-02,\n",
       "          2.9311e-03, 6.0575e-05, 2.2302e-02, 5.7109e-04, 5.8606e-05, 9.9665e-05,\n",
       "          2.9523e-04, 2.6801e-01, 1.3416e-04, 1.1704e-03, 6.1020e-03, 2.7817e-04,\n",
       "          5.4247e-02, 8.5216e-01],\n",
       "         [5.8249e-03, 1.1910e-05, 1.1412e-02, 2.2157e-02, 2.5646e-04, 1.1357e-03,\n",
       "          4.9768e-03, 5.8198e-05, 3.9530e-01, 1.2059e-03, 1.2286e-03, 4.6090e-01,\n",
       "          2.1886e-05, 1.9940e-03, 1.3516e-04, 7.2881e-07, 1.1356e-01, 4.3643e-04,\n",
       "          6.0264e-07, 9.6578e-06, 7.7941e-06, 1.5162e-04, 3.0866e-07, 4.3712e-05,\n",
       "          9.1386e-06, 3.7421e-04, 1.1537e-03, 3.4697e-05, 4.3977e-04, 3.9111e-06,\n",
       "          3.0216e-06, 8.4868e-09, 3.6786e-06, 3.3852e-03, 3.2744e-04, 5.9160e-04,\n",
       "          1.4206e-03, 9.3431e-05, 2.0615e-06, 1.0318e-06, 8.5174e-04, 1.2077e-04,\n",
       "          7.5680e-05, 8.1032e-06, 1.0982e-03, 2.6339e-04, 8.6484e-05, 6.2598e-05,\n",
       "          9.5332e-05, 2.5602e-08, 3.7206e-05, 6.5461e-05, 5.7799e-06, 1.1412e-03,\n",
       "          2.7466e-05, 1.2727e-02, 2.5518e-04, 3.3944e-03, 7.2735e-03, 1.9329e-05,\n",
       "          2.3383e-04, 3.3432e-06, 2.5306e-05, 2.1839e-02, 9.3185e-05, 9.7407e-03,\n",
       "          5.2543e-04, 5.4829e-05, 1.2149e-02, 2.7890e-03, 2.7300e-04, 1.0797e-04,\n",
       "          8.0071e-04, 2.9552e-01, 1.4996e-04, 7.5723e-04, 6.4755e-03, 3.5513e-04,\n",
       "          1.4402e-01, 6.0480e-01],\n",
       "         [2.6142e-03, 1.6234e-05, 3.0111e-03, 4.4262e-03, 3.8531e-04, 7.4315e-04,\n",
       "          3.1746e-03, 1.3139e-04, 9.4164e-01, 9.6655e-04, 3.7448e-04, 6.5271e-02,\n",
       "          8.0191e-06, 3.4450e-03, 2.0154e-04, 7.7046e-08, 1.5396e-02, 5.2412e-05,\n",
       "          3.8516e-08, 1.0302e-05, 6.5447e-07, 3.9683e-05, 1.6512e-07, 1.3162e-05,\n",
       "          8.4302e-06, 1.3018e-04, 4.2844e-04, 9.5954e-06, 2.9588e-04, 1.1193e-06,\n",
       "          6.4497e-07, 3.8175e-09, 5.0231e-07, 3.1941e-03, 2.6332e-04, 4.8815e-04,\n",
       "          2.6581e-04, 7.2699e-05, 5.6623e-07, 6.9325e-08, 3.5653e-04, 1.3212e-05,\n",
       "          1.0922e-05, 1.0245e-06, 4.8102e-04, 2.1151e-04, 4.1135e-05, 4.8827e-05,\n",
       "          3.0605e-05, 9.3488e-09, 1.6490e-05, 6.3887e-05, 3.3840e-06, 6.7338e-04,\n",
       "          5.0871e-06, 1.1148e-02, 7.6880e-05, 1.1332e-03, 4.9498e-03, 4.9758e-06,\n",
       "          2.2086e-04, 2.9011e-06, 8.7357e-06, 1.9053e-01, 7.3647e-05, 6.9528e-03,\n",
       "          6.9186e-04, 2.0508e-05, 1.0844e-03, 1.3340e-03, 1.7319e-03, 4.8764e-05,\n",
       "          7.3921e-04, 6.5757e-02, 4.3221e-05, 4.5382e-04, 9.0157e-04, 9.3043e-05,\n",
       "          2.1275e-02, 6.0459e-01],\n",
       "         [2.6256e-03, 4.3494e-06, 5.9378e-03, 1.6071e-02, 3.0617e-04, 8.9337e-04,\n",
       "          9.8500e-03, 7.4002e-05, 1.1003e-01, 1.5872e-03, 3.7907e-03, 8.0989e-01,\n",
       "          1.2166e-05, 2.9189e-03, 1.6053e-04, 1.0489e-06, 8.3874e-02, 4.4927e-04,\n",
       "          1.6032e-06, 1.1452e-05, 2.3431e-05, 2.5459e-04, 7.7486e-07, 5.0973e-05,\n",
       "          2.5992e-06, 1.6167e-04, 4.3629e-03, 1.1168e-04, 5.8036e-04, 4.8840e-06,\n",
       "          2.9899e-06, 4.0107e-09, 8.7866e-06, 4.4195e-03, 1.3623e-04, 2.4405e-04,\n",
       "          3.5379e-03, 1.2343e-04, 5.0546e-06, 4.1729e-06, 2.5869e-03, 1.2820e-04,\n",
       "          9.2760e-05, 1.3406e-05, 4.2333e-04, 2.6938e-04, 7.0327e-05, 7.9331e-05,\n",
       "          4.8989e-04, 9.3785e-08, 1.1156e-04, 2.4340e-04, 3.7652e-06, 1.9916e-03,\n",
       "          8.0542e-05, 1.5120e-02, 5.4029e-04, 2.5768e-03, 4.7576e-03, 2.5184e-05,\n",
       "          6.8485e-04, 4.5988e-06, 1.3564e-04, 8.7690e-03, 5.9342e-05, 5.8980e-03,\n",
       "          2.5329e-03, 4.7814e-05, 6.7231e-02, 5.1509e-04, 8.0927e-05, 6.8621e-05,\n",
       "          3.1574e-04, 5.7449e-01, 1.1752e-04, 5.7156e-04, 2.5633e-02, 2.6053e-04,\n",
       "          9.7369e-02, 6.0752e-01],\n",
       "         [8.2686e-04, 1.0572e-06, 4.2583e-04, 1.4928e-03, 1.7416e-05, 3.3747e-04,\n",
       "          1.1243e-04, 3.7981e-05, 6.3297e-03, 2.8931e-04, 5.7322e-03, 9.7235e-01,\n",
       "          6.5604e-06, 2.2092e-03, 2.0757e-04, 5.8197e-06, 6.5418e-02, 8.0317e-05,\n",
       "          3.3242e-06, 2.5194e-06, 5.6414e-05, 1.9483e-04, 2.8317e-06, 1.1748e-05,\n",
       "          8.4505e-08, 2.3511e-05, 4.7212e-03, 3.4820e-05, 2.4195e-04, 3.8341e-06,\n",
       "          4.6634e-07, 5.0790e-09, 2.3943e-06, 5.2307e-04, 2.3856e-05, 7.9741e-05,\n",
       "          1.0164e-02, 1.7112e-04, 3.1815e-05, 5.0279e-05, 8.8227e-03, 3.8289e-05,\n",
       "          1.0146e-04, 1.0260e-05, 5.7322e-05, 6.1163e-05, 4.3110e-05, 1.6472e-04,\n",
       "          1.1337e-04, 2.7669e-07, 3.2626e-05, 2.6234e-04, 3.1525e-07, 2.6905e-03,\n",
       "          9.3869e-05, 6.2264e-03, 3.4105e-04, 8.2401e-04, 3.4902e-03, 1.4545e-05,\n",
       "          8.7775e-04, 4.4713e-06, 4.6796e-04, 2.6252e-03, 7.7283e-05, 3.1704e-03,\n",
       "          8.9250e-03, 3.5409e-05, 3.7833e-02, 1.9744e-04, 1.2505e-05, 4.0458e-05,\n",
       "          8.8091e-05, 2.9150e-01, 6.4391e-05, 3.0901e-04, 2.5970e-02, 2.1088e-04,\n",
       "          4.3579e-02, 9.3608e-01],\n",
       "         [2.9138e-02, 5.7550e-06, 1.0059e-02, 3.6296e-04, 9.7419e-05, 1.9580e-03,\n",
       "          1.5655e-04, 6.2537e-05, 1.1423e-01, 3.3364e-04, 2.1403e-02, 7.3146e-01,\n",
       "          7.0356e-06, 9.3326e-04, 1.2444e-04, 5.8567e-07, 2.9156e-03, 1.7582e-05,\n",
       "          5.8167e-08, 4.0396e-06, 3.8819e-06, 1.7670e-05, 6.0770e-07, 5.4107e-06,\n",
       "          9.9118e-07, 2.9322e-05, 3.5391e-04, 4.0467e-05, 6.1022e-04, 1.2014e-06,\n",
       "          1.5868e-07, 5.9005e-09, 5.0077e-07, 1.6874e-04, 1.5245e-05, 8.0492e-05,\n",
       "          1.6068e-03, 1.3079e-04, 1.5804e-06, 2.4133e-06, 6.7743e-05, 1.5356e-06,\n",
       "          1.5589e-05, 2.6464e-06, 4.5663e-05, 1.1644e-05, 3.6910e-05, 3.6799e-05,\n",
       "          1.2598e-04, 5.0940e-08, 6.6861e-06, 6.1640e-05, 2.6196e-06, 9.9108e-04,\n",
       "          7.6707e-06, 2.6411e-03, 1.1971e-04, 2.6009e-04, 1.0485e-02, 7.7961e-06,\n",
       "          2.9383e-04, 1.3829e-06, 1.5938e-05, 6.1548e-03, 3.8002e-05, 9.5878e-04,\n",
       "          8.4599e-05, 1.3569e-05, 8.2730e-04, 1.6014e-04, 4.5975e-05, 1.7884e-05,\n",
       "          4.7595e-05, 5.3235e-01, 1.2261e-05, 2.3992e-04, 2.1181e-04, 5.2890e-05,\n",
       "          2.6507e-03, 9.6691e-01],\n",
       "         [4.4533e-04, 7.6658e-07, 4.8485e-04, 7.2377e-05, 5.4657e-06, 1.8999e-04,\n",
       "          5.8649e-06, 9.7837e-05, 2.8687e-03, 1.1807e-04, 7.2294e-02, 9.1805e-01,\n",
       "          3.0972e-06, 7.4831e-04, 1.7555e-04, 4.0930e-06, 3.2553e-02, 3.0963e-05,\n",
       "          4.6553e-07, 1.6104e-06, 1.3004e-05, 8.7770e-05, 1.5142e-06, 7.1253e-06,\n",
       "          1.5179e-08, 1.5374e-05, 9.5235e-04, 6.4924e-05, 7.6724e-04, 3.5314e-06,\n",
       "          6.3122e-08, 6.0375e-09, 8.9933e-07, 5.3036e-05, 3.2698e-06, 4.1191e-05,\n",
       "          4.3234e-03, 1.4771e-04, 9.2344e-06, 6.6646e-05, 1.2607e-03, 6.7554e-06,\n",
       "          4.1647e-05, 4.0446e-06, 3.7633e-05, 1.0476e-05, 4.2106e-05, 5.3939e-05,\n",
       "          1.0254e-04, 2.0538e-07, 9.0560e-06, 4.5374e-05, 5.5488e-08, 2.8818e-03,\n",
       "          2.9989e-05, 8.4093e-04, 9.6671e-05, 1.6843e-04, 1.0037e-02, 1.1069e-05,\n",
       "          2.0308e-04, 5.3596e-06, 1.1419e-04, 4.5465e-04, 3.7899e-05, 5.4033e-04,\n",
       "          5.2658e-04, 1.7563e-05, 2.7844e-03, 8.0306e-05, 2.3695e-06, 9.0935e-06,\n",
       "          2.7770e-05, 3.6344e-01, 1.4789e-05, 1.2072e-04, 1.1458e-03, 6.0905e-05,\n",
       "          3.2616e-03, 9.7573e-01],\n",
       "         [2.1586e-03, 8.4812e-06, 3.0881e-03, 1.0005e-02, 2.4566e-04, 8.3134e-04,\n",
       "          1.9196e-03, 2.1443e-04, 9.1031e-01, 9.1036e-04, 4.9154e-04, 5.0088e-02,\n",
       "          9.1541e-06, 2.5969e-03, 9.0263e-05, 7.3476e-08, 1.6648e-02, 9.7355e-05,\n",
       "          3.2067e-08, 6.9851e-06, 4.5721e-07, 4.0130e-05, 1.6492e-07, 2.2316e-05,\n",
       "          4.6445e-06, 1.7763e-04, 2.3184e-04, 5.4787e-06, 2.8893e-04, 1.3662e-06,\n",
       "          5.2203e-07, 6.8078e-09, 1.2349e-06, 1.9834e-03, 2.1483e-04, 5.6169e-04,\n",
       "          3.4578e-04, 3.9010e-05, 6.1187e-07, 3.9289e-08, 2.3073e-04, 2.6604e-05,\n",
       "          1.4523e-05, 6.9716e-07, 4.7792e-04, 1.8006e-04, 5.7450e-05, 8.7272e-05,\n",
       "          2.9021e-05, 6.0206e-09, 1.8544e-05, 2.0874e-05, 1.2746e-06, 8.2441e-04,\n",
       "          3.8473e-06, 4.4052e-03, 1.5330e-04, 1.2537e-03, 4.7888e-03, 3.8286e-06,\n",
       "          2.6803e-04, 3.6193e-06, 7.7977e-06, 5.4084e-02, 7.6389e-05, 3.9248e-03,\n",
       "          6.9101e-04, 2.1672e-05, 1.4430e-03, 9.2304e-04, 7.4487e-04, 5.3314e-05,\n",
       "          3.4420e-04, 1.0497e-01, 3.6558e-05, 1.6412e-04, 1.8999e-03, 1.5000e-04,\n",
       "          5.3750e-02, 5.4874e-01]], device='cuda:0')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1ab040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_score_list) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efb139ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 80]), torch.float32, device(type='cuda', index=0), False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_score_list[0].shape, action_score_list[0].dtype, action_score_list[0].device, action_score_list[0].requires_grad\n",
    "\n",
    "# (torch.Size([10, 80]), torch.float32, device(type='cuda', index=0), True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d8e2b",
   "metadata": {},
   "source": [
    "#### bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e57a2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2160, 0.0277, 0.3633, 0.5164],\n",
       "         [0.5058, 0.1586, 0.6449, 0.7940],\n",
       "         [0.6798, 0.0875, 0.7881, 0.3152],\n",
       "         [0.1277, 0.1867, 0.2822, 0.8096],\n",
       "         [0.6339, 0.1676, 0.8083, 0.8363],\n",
       "         [0.0031, 0.1619, 0.1232, 0.8392],\n",
       "         [0.7782, 0.1503, 0.8620, 0.3536],\n",
       "         [0.8028, 0.2952, 0.9971, 0.9894],\n",
       "         [0.8480, 0.1634, 0.9498, 0.4398],\n",
       "         [0.3250, 0.1778, 0.4951, 0.8835]], device='cuda:0')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f024cc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([10, 4]), torch.float32, False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(box_list), box_list[0].shape, box_list[0].dtype, box_list[0].requires_grad\n",
    "# (1, torch.Size([10, 4]), torch.float32, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fccdab6",
   "metadata": {},
   "source": [
    "#### Output of compute_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "550b20b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict.update(\n",
    "                {video_id: (box.cpu(), action_score.cpu()) for video_id, box, action_score in zip(idx, box_list, action_score_list)}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e4b184b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea0a3a",
   "metadata": {},
   "source": [
    "#### inside of '_accumulate_predictions_from_multiple_gpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "407491d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphaction.engine.inference import _accumulate_predictions_from_multiple_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "789a508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "248603cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = copy.deepcopy(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86e88320",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = _accumulate_predictions_from_multiple_gpus(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c23ec3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions), len(predictions)\n",
    "# (list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75316467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions[0]), len(predictions[0]) # tuple, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc698096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 4]), device(type='cpu'))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0].shape, predictions[0][0].device\n",
    "# (torch.Size([10, 4]), device(type='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e996a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2160, 0.0277, 0.3633, 0.5164])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0][0,:]\n",
    "# tensor([0.2160, 0.0277, 0.3633, 0.5164])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9274a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 80]), device(type='cpu'))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][1].shape, predictions[0][1].device\n",
    "# (torch.Size([10, 80]), device(type='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04631903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.1237e-04, 1.8565e-06, 3.8518e-04, 5.2749e-03, 1.0854e-04, 1.1021e-04,\n",
       "        4.8070e-04, 1.1244e-04, 3.7187e-02, 3.0474e-04, 6.2452e-04, 9.7247e-01,\n",
       "        4.7521e-06, 2.7996e-03, 7.5738e-05, 3.3534e-06, 9.5618e-02, 3.4626e-04,\n",
       "        2.2128e-06, 5.8158e-06, 1.6095e-05, 4.5821e-04, 1.6409e-06, 1.5436e-05,\n",
       "        7.7230e-07, 2.0286e-04, 1.5550e-03, 1.4416e-05, 1.8330e-04, 1.5747e-05,\n",
       "        4.1002e-06, 1.7715e-09, 2.1835e-05, 9.0983e-04, 1.5934e-04, 4.9503e-05,\n",
       "        1.5614e-03, 1.3252e-04, 1.9455e-05, 5.2948e-06, 1.4612e-03, 4.8311e-05,\n",
       "        1.2096e-04, 1.1396e-05, 3.6527e-04, 1.2366e-04, 7.0961e-05, 2.1094e-05,\n",
       "        1.3564e-04, 7.7215e-08, 4.4962e-05, 1.2097e-04, 2.2823e-06, 1.5885e-03,\n",
       "        4.0419e-05, 5.5051e-03, 2.5459e-04, 2.1811e-03, 7.6489e-03, 2.3249e-05,\n",
       "        8.6529e-04, 5.5949e-06, 1.0235e-04, 1.0506e-02, 6.0015e-05, 8.2875e-03,\n",
       "        9.4192e-04, 8.3792e-05, 1.2272e-02, 8.4177e-04, 7.4537e-05, 8.0691e-05,\n",
       "        1.2542e-04, 3.9908e-01, 7.4738e-05, 2.7076e-03, 1.1440e-02, 1.8044e-04,\n",
       "        6.5097e-02, 8.0956e-01])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][1][0,:]\n",
    "# tensor([9.1237e-04, 1.8565e-06, 3.8518e-04, 5.2749e-03, 1.0854e-04, 1.1021e-04,\n",
    "#        4.8070e-04, 1.1244e-04, 3.7187e-02, 3.0474e-04, 6.2452e-04, 9.7247e-01,\n",
    "#        4.7521e-06, 2.7996e-03, 7.5738e-05, 3.3534e-06, 9.5618e-02, 3.4626e-04,\n",
    "#        2.2128e-06, 5.8158e-06, 1.6095e-05, 4.5821e-04, 1.6409e-06, 1.5436e-05,\n",
    "#        7.7230e-07, 2.0286e-04, 1.5550e-03, 1.4416e-05, 1.8330e-04, 1.5747e-05,\n",
    "#        4.1002e-06, 1.7715e-09, 2.1835e-05, 9.0983e-04, 1.5934e-04, 4.9503e-05,\n",
    "#        1.5614e-03, 1.3252e-04, 1.9455e-05, 5.2948e-06, 1.4612e-03, 4.8311e-05,\n",
    "#        1.2096e-04, 1.1396e-05, 3.6527e-04, 1.2366e-04, 7.0961e-05, 2.1094e-05,\n",
    "#        1.3564e-04, 7.7215e-08, 4.4962e-05, 1.2097e-04, 2.2823e-06, 1.5885e-03,\n",
    "#        4.0419e-05, 5.5051e-03, 2.5459e-04, 2.1811e-03, 7.6489e-03, 2.3249e-05,\n",
    "#        8.6529e-04, 5.5949e-06, 1.0235e-04, 1.0506e-02, 6.0015e-05, 8.2875e-03,\n",
    "#        9.4192e-04, 8.3792e-05, 1.2272e-02, 8.4177e-04, 7.4537e-05, 8.0691e-05,\n",
    "#        1.2542e-04, 3.9908e-01, 7.4738e-05, 2.7076e-03, 1.1440e-02, 1.8044e-04,\n",
    "#        6.5097e-02, 8.0956e-01])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2d6cf",
   "metadata": {},
   "source": [
    "#### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc34daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphaction.dataset.datasets.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7c3786d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output_dir/inference/ava_v2.2'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f47928aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<alphaction.dataset.datasets.ava_dataset.Ava at 0x7ff136dd38e0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76de74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "706f3799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 09:58:23,583 alphaction.inference INFO: performing ava evaluation.\n",
      "2024-01-22 09:58:23,585 alphaction.inference INFO: Preparing results for AVA format\n",
      "2024-01-22 09:58:23,586 alphaction.inference INFO: Evaluating predictions\n",
      "2024-01-22 09:58:23,594 alphaction.inference INFO: ==> 0.00683141 seconds to write file ../output_dir/inference/ava_v2.2/result.csv\n",
      "2024-01-22 09:58:23,600 alphaction.inference INFO: CATEGORIES (60):\n",
      "[ {'id': 1, 'name': 'bend/bow (at the waist)'},\n",
      "  {'id': 3, 'name': 'crouch/kneel'},\n",
      "  {'id': 4, 'name': 'dance'},\n",
      "  {'id': 5, 'name': 'fall down'},\n",
      "  {'id': 6, 'name': 'get up'},\n",
      "  {'id': 7, 'name': 'jump/leap'},\n",
      "  {'id': 8, 'name': 'lie/sleep'},\n",
      "  {'id': 9, 'name': 'martial art'},\n",
      "  {'id': 10, 'name': 'run/jog'},\n",
      "  {'id': 11, 'name': 'sit'},\n",
      "  {'id': 12, 'name': 'stand'},\n",
      "  {'id': 13, 'name': 'swim'},\n",
      "  {'id': 14, 'name': 'walk'},\n",
      "  {'id': 15, 'name': 'answer phone'},\n",
      "  {'id': 17, 'name': 'carry/hold (an object)'},\n",
      "  {'id': 20, 'name': 'climb (e.g., a mountain)'},\n",
      "  {'id': 22, 'name': 'close (e.g., a door, a box)'},\n",
      "  {'id': 24, 'name': 'cut'},\n",
      "  {'id': 26, 'name': 'dress/put on clothing'},\n",
      "  {'id': 27, 'name': 'drink'},\n",
      "  {'id': 28, 'name': 'drive (e.g., a car, a truck)'},\n",
      "  {'id': 29, 'name': 'eat'},\n",
      "  {'id': 30, 'name': 'enter'},\n",
      "  {'id': 34, 'name': 'hit (an object)'},\n",
      "  {'id': 36, 'name': 'lift/pick up'},\n",
      "  {'id': 37, 'name': 'listen (e.g., to music)'},\n",
      "  {'id': 38, 'name': 'open (e.g., a window, a car door)'},\n",
      "  {'id': 41, 'name': 'play musical instrument'},\n",
      "  {'id': 43, 'name': 'point to (an object)'},\n",
      "  {'id': 45, 'name': 'pull (an object)'},\n",
      "  {'id': 46, 'name': 'push (an object)'},\n",
      "  {'id': 47, 'name': 'put down'},\n",
      "  {'id': 48, 'name': 'read'},\n",
      "  {'id': 49, 'name': 'ride (e.g., a bike, a car, a horse)'},\n",
      "  {'id': 51, 'name': 'sail boat'},\n",
      "  {'id': 52, 'name': 'shoot'},\n",
      "  {'id': 54, 'name': 'smoke'},\n",
      "  {'id': 56, 'name': 'take a photo'},\n",
      "  {'id': 57, 'name': 'text on/look at a cellphone'},\n",
      "  {'id': 58, 'name': 'throw'},\n",
      "  {'id': 59, 'name': 'touch (an object)'},\n",
      "  {'id': 60, 'name': 'turn (e.g., a screwdriver)'},\n",
      "  {'id': 61, 'name': 'watch (e.g., TV)'},\n",
      "  {'id': 62, 'name': 'work on a computer'},\n",
      "  {'id': 63, 'name': 'write'},\n",
      "  {'id': 64, 'name': 'fight/hit (a person)'},\n",
      "  {'id': 65, 'name': 'give/serve (an object) to (a person)'},\n",
      "  {'id': 66, 'name': 'grab (a person)'},\n",
      "  {'id': 67, 'name': 'hand clap'},\n",
      "  {'id': 68, 'name': 'hand shake'},\n",
      "  {'id': 69, 'name': 'hand wave'},\n",
      "  {'id': 70, 'name': 'hug (a person)'},\n",
      "  {'id': 72, 'name': 'kiss (a person)'},\n",
      "  {'id': 73, 'name': 'lift (a person)'},\n",
      "  {'id': 74, 'name': 'listen to (a person)'},\n",
      "  {'id': 76, 'name': 'push (another person)'},\n",
      "  {'id': 77, 'name': 'sing to (e.g., self, a person, a group)'},\n",
      "  {'id': 78, 'name': 'take (an object) from (a person)'},\n",
      "  {'id': 79, 'name': 'talk to (e.g., self, a person, a group)'},\n",
      "  {'id': 80, 'name': 'watch (a person)'}]\n",
      "2024-01-22 09:58:23,616 alphaction.inference INFO: ==> 0.0142322 seconds to read file /work/ava/annotations/ava_sample_predicted_boxes.csv\n",
      "2024-01-22 09:58:24,622 alphaction.inference INFO: ==> 1.00552 seconds to convert groundtruth\n",
      "2024-01-22 09:58:24,627 alphaction.inference INFO: ==> 0.00384474 seconds to read file ../output_dir/inference/ava_v2.2/result.csv\n",
      "2024-01-22 09:58:24,666 alphaction.inference INFO: ==> 0.0378835 seconds to convert detections\n",
      "2024-01-22 09:58:24,667 alphaction.inference INFO: The following classes have no ground truth examples: [ 2 13 15 16 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 35 37 39 40\n",
      " 41 42 43 44 49 50 51 52 53 54 55 56 57 60 62 63 65 66 67 68 69 70 71 72\n",
      " 73 75 77 78]\n",
      "2024-01-22 09:58:24,672 alphaction.inference INFO: ==> 0.00567245 seconds to run_evaluator\n",
      "2024-01-22 09:58:24,674 alphaction.inference INFO: { 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/answer phone': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/bend/bow (at the waist)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/carry/hold (an object)': 0.0014124293785310734,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/climb (e.g., a mountain)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/close (e.g., a door, a box)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/crouch/kneel': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dance': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dress/put on clothing': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drink': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drive (e.g., a car, a truck)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/eat': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/enter': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fall down': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fight/hit (a person)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/get up': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/give/serve (an object) to (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/grab (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand clap': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand shake': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand wave': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hit (an object)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hug (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/jump/leap': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/kiss (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lie/sleep': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift/pick up': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen (e.g., to music)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen to (a person)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/martial art': 0.029069767441860465,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/open (e.g., a window, a car door)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/play musical instrument': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/point to (an object)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pull (an object)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (an object)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (another person)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/put down': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/read': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/ride (e.g., a bike, a car, a horse)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/run/jog': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sail boat': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/shoot': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sing to (e.g., self, a person, a group)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/smoke': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand': 0.002403846153846154,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/swim': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take (an object) from (a person)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take a photo': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/talk to (e.g., self, a person, a group)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/text on/look at a cellphone': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/throw': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/touch (an object)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/turn (e.g., a screwdriver)': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/walk': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (a person)': 0.0037545787545787547,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (e.g., TV)': 0.0,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/work on a computer': nan,\n",
      "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/write': nan,\n",
      "  'PascalBoxes_Precision/mAP@0.5IOU': 0.0013085936331720162}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'PascalBoxes_Precision/mAP@0.5IOU': 0.0013085936331720162,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/bend/bow (at the waist)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/crouch/kneel': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dance': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fall down': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/get up': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/jump/leap': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lie/sleep': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/martial art': 0.029069767441860465,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/run/jog': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/stand': 0.002403846153846154,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/swim': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/walk': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/answer phone': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/carry/hold (an object)': 0.0014124293785310734,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/climb (e.g., a mountain)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/close (e.g., a door, a box)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/cut': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dress/put on clothing': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drink': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/drive (e.g., a car, a truck)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/eat': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/enter': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hit (an object)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift/pick up': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen (e.g., to music)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/open (e.g., a window, a car door)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/play musical instrument': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/point to (an object)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/pull (an object)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (an object)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/put down': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/read': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/ride (e.g., a bike, a car, a horse)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sail boat': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/shoot': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/smoke': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take a photo': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/text on/look at a cellphone': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/throw': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/touch (an object)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/turn (e.g., a screwdriver)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (e.g., TV)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/work on a computer': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/write': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fight/hit (a person)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/give/serve (an object) to (a person)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/grab (a person)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand clap': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand shake': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hand wave': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/hug (a person)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/kiss (a person)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lift (a person)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen to (a person)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/push (another person)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sing to (e.g., self, a person, a group)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/take (an object) from (a person)': nan,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/talk to (e.g., self, a person, a group)': 0.0,\n",
       "  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (a person)': 0.0037545787545787547},\n",
       " {'-5KQ66BBWC4,0902': {'boxes': array([[0.2159758 , 0.02766521, 0.3632796 , 0.5164119 ],\n",
       "          [0.2159758 , 0.02766521, 0.3632796 , 0.5164119 ],\n",
       "          [0.2159758 , 0.02766521, 0.3632796 , 0.5164119 ],\n",
       "          ...,\n",
       "          [0.32499602, 0.17778155, 0.4951467 , 0.88352096],\n",
       "          [0.32499602, 0.17778155, 0.4951467 , 0.88352096],\n",
       "          [0.32499602, 0.17778155, 0.4951467 , 0.88352096]], dtype=float32),\n",
       "   'scores': array([9.12367308e-04, 1.85653403e-06, 3.85179097e-04, 5.27487509e-03,\n",
       "          1.08537897e-04, 1.10207315e-04, 4.80703049e-04, 1.12435795e-04,\n",
       "          3.71872373e-02, 3.04741086e-04, 6.24520879e-04, 9.72470462e-01,\n",
       "          4.75212846e-06, 2.79958500e-03, 7.57381713e-05, 3.35343793e-06,\n",
       "          9.56182033e-02, 3.46256245e-04, 2.21277446e-06, 5.81579206e-06,\n",
       "          1.60954060e-05, 4.58211522e-04, 1.64086100e-06, 1.54360023e-05,\n",
       "          7.72302428e-07, 2.02863521e-04, 1.55500951e-03, 1.44162714e-05,\n",
       "          1.83297714e-04, 1.57467803e-05, 4.10022449e-06, 1.77154980e-09,\n",
       "          2.18347286e-05, 9.09826369e-04, 1.59337491e-04, 4.95031163e-05,\n",
       "          1.56136637e-03, 1.32522182e-04, 1.94548466e-05, 5.29479621e-06,\n",
       "          1.46118505e-03, 4.83105250e-05, 1.20955134e-04, 1.13960896e-05,\n",
       "          3.65270185e-04, 1.23660546e-04, 7.09605083e-05, 2.10935250e-05,\n",
       "          1.35642302e-04, 7.72149491e-08, 4.49617655e-05, 1.20970122e-04,\n",
       "          2.28225576e-06, 1.58849580e-03, 4.04187413e-05, 5.50513202e-03,\n",
       "          2.54590268e-04, 2.18112487e-03, 7.64893228e-03, 2.32489874e-05,\n",
       "          8.65292677e-04, 5.59485488e-06, 1.02354490e-04, 1.05059864e-02,\n",
       "          6.00147941e-05, 8.28749035e-03, 9.41922422e-04, 8.37919506e-05,\n",
       "          1.22717666e-02, 8.41771485e-04, 7.45373909e-05, 8.06910029e-05,\n",
       "          1.25423117e-04, 3.99080724e-01, 7.47376762e-05, 2.70759244e-03,\n",
       "          1.14398990e-02, 1.80441639e-04, 6.50967658e-02, 8.09560120e-01,\n",
       "          2.75643985e-03, 9.74573049e-06, 3.23523441e-03, 3.96155706e-03,\n",
       "          2.51543155e-04, 8.39787128e-04, 2.40745232e-03, 1.22194397e-04,\n",
       "          9.06722844e-01, 7.39213545e-04, 4.65258549e-04, 8.63656923e-02,\n",
       "          7.68752670e-06, 2.58044014e-03, 1.40896518e-04, 8.35687572e-08,\n",
       "          1.57151297e-02, 7.45253055e-05, 5.19536876e-08, 9.13616259e-06,\n",
       "          6.36696200e-07, 5.13278428e-05, 2.04293599e-07, 2.37505647e-05,\n",
       "          5.47447416e-06, 1.43353202e-04, 5.58598374e-04, 9.17273337e-06,\n",
       "          3.16283084e-04, 9.17065336e-07, 4.91945855e-07, 4.90484942e-09,\n",
       "          1.05857191e-06, 4.20917571e-03, 1.53472225e-04, 3.84429324e-04,\n",
       "          3.10090341e-04, 7.37459632e-05, 7.08385642e-07, 8.65566676e-08,\n",
       "          5.02540730e-04, 2.48963297e-05, 1.65413257e-05, 1.04296771e-06,\n",
       "          4.90178470e-04, 2.34765757e-04, 4.77129397e-05, 4.99326197e-05,\n",
       "          3.63867803e-05, 1.13081420e-08, 1.83095817e-05, 4.58840805e-05,\n",
       "          2.17903994e-06, 6.87635795e-04, 4.38433926e-06, 8.21665395e-03,\n",
       "          1.04075487e-04, 6.42319035e-04, 4.03238600e-03, 5.85250200e-06,\n",
       "          2.83493631e-04, 4.11518113e-06, 1.09409921e-05, 7.33670518e-02,\n",
       "          8.64297326e-05, 7.97407515e-03, 8.27364624e-04, 1.96953588e-05,\n",
       "          1.42590876e-03, 1.25797372e-03, 6.36404089e-04, 5.84375302e-05,\n",
       "          4.64052893e-04, 7.88994059e-02, 4.22992962e-05, 2.84724985e-04,\n",
       "          1.66363048e-03, 1.13053546e-04, 3.59003320e-02, 5.66181242e-01,\n",
       "          6.69538975e-04, 3.71780038e-06, 1.36552530e-03, 1.57211022e-03,\n",
       "          8.17491236e-05, 2.50483426e-04, 4.59356030e-04, 7.61511910e-05,\n",
       "          5.47924824e-02, 2.37233005e-04, 3.12261074e-03, 9.36976373e-01,\n",
       "          1.73866865e-05, 2.12704903e-03, 1.99180460e-04, 2.91645119e-06,\n",
       "          1.33508503e-01, 3.40830855e-04, 2.03966283e-06, 5.96789141e-06,\n",
       "          1.95438442e-05, 3.77761084e-04, 2.64118489e-06, 2.56979729e-05,\n",
       "          7.47113404e-07, 1.49180341e-04, 4.35785064e-03, 3.25452165e-05,\n",
       "          2.45841569e-04, 4.76639798e-06, 1.65281301e-06, 3.11825343e-09,\n",
       "          8.63385321e-06, 2.22304603e-03, 6.74966577e-05, 1.19873628e-04,\n",
       "          8.63683526e-04, 1.58842377e-04, 1.26631221e-05, 2.02102892e-05,\n",
       "          2.86511146e-03, 9.29732414e-05, 1.50902575e-04, 9.99880649e-06,\n",
       "          3.44690488e-04, 2.29723897e-04, 9.34117925e-05, 4.34628746e-05,\n",
       "          9.57962766e-05, 3.30358148e-07, 8.13180814e-05, 2.27837067e-04,\n",
       "          1.42706347e-06, 1.03347423e-03, 6.24647728e-05, 2.21905597e-02,\n",
       "          2.83218338e-04, 1.18278735e-03, 4.98419162e-03, 1.73427197e-05,\n",
       "          8.29913013e-04, 1.09048151e-05, 1.08287000e-04, 1.26904594e-02,\n",
       "          1.39106880e-04, 1.00025907e-02, 2.93110055e-03, 6.05752211e-05,\n",
       "          2.23017521e-02, 5.71088167e-04, 5.86056231e-05, 9.96648960e-05,\n",
       "          2.95232254e-04, 2.68014133e-01, 1.34159171e-04, 1.17040682e-03,\n",
       "          6.10199384e-03, 2.78170686e-04, 5.42466715e-02, 8.52158666e-01,\n",
       "          5.82491420e-03, 1.19104625e-05, 1.14122638e-02, 2.21569836e-02,\n",
       "          2.56460800e-04, 1.13572425e-03, 4.97680018e-03, 5.81976237e-05,\n",
       "          3.95297259e-01, 1.20587391e-03, 1.22856419e-03, 4.60902333e-01,\n",
       "          2.18858859e-05, 1.99401123e-03, 1.35163558e-04, 7.28807834e-07,\n",
       "          1.13560244e-01, 4.36433183e-04, 6.02643411e-07, 9.65778872e-06,\n",
       "          7.79408674e-06, 1.51615663e-04, 3.08659764e-07, 4.37124800e-05,\n",
       "          9.13857548e-06, 3.74210853e-04, 1.15370017e-03, 3.46972956e-05,\n",
       "          4.39769967e-04, 3.91113417e-06, 3.02161311e-06, 8.48675796e-09,\n",
       "          3.67863117e-06, 3.38522252e-03, 3.27437214e-04, 5.91603748e-04,\n",
       "          1.42058358e-03, 9.34313139e-05, 2.06148661e-06, 1.03176092e-06,\n",
       "          8.51743680e-04, 1.20768418e-04, 7.56799127e-05, 8.10321308e-06,\n",
       "          1.09817495e-03, 2.63386435e-04, 8.64841350e-05, 6.25983521e-05,\n",
       "          9.53315102e-05, 2.56024570e-08, 3.72063587e-05, 6.54613323e-05,\n",
       "          5.77988476e-06, 1.14116177e-03, 2.74662434e-05, 1.27272857e-02,\n",
       "          2.55181279e-04, 3.39435320e-03, 7.27349147e-03, 1.93286851e-05,\n",
       "          2.33833969e-04, 3.34324181e-06, 2.53055568e-05, 2.18392145e-02,\n",
       "          9.31846589e-05, 9.74067952e-03, 5.25433104e-04, 5.48292628e-05,\n",
       "          1.21486587e-02, 2.78898189e-03, 2.72998936e-04, 1.07967062e-04,\n",
       "          8.00708658e-04, 2.95523852e-01, 1.49955900e-04, 7.57231901e-04,\n",
       "          6.47546444e-03, 3.55133263e-04, 1.44019276e-01, 6.04803503e-01,\n",
       "          2.61417008e-03, 1.62343604e-05, 3.01106623e-03, 4.42624651e-03,\n",
       "          3.85306368e-04, 7.43151701e-04, 3.17463023e-03, 1.31389635e-04,\n",
       "          9.41643238e-01, 9.66547581e-04, 3.74479365e-04, 6.52714074e-02,\n",
       "          8.01914848e-06, 3.44500039e-03, 2.01539209e-04, 7.70462023e-08,\n",
       "          1.53957726e-02, 5.24123134e-05, 3.85157399e-08, 1.03019047e-05,\n",
       "          6.54467783e-07, 3.96829164e-05, 1.65124689e-07, 1.31621828e-05,\n",
       "          8.43020098e-06, 1.30181681e-04, 4.28444037e-04, 9.59537101e-06,\n",
       "          2.95881502e-04, 1.11930160e-06, 6.44970385e-07, 3.81753384e-09,\n",
       "          5.02306875e-07, 3.19406018e-03, 2.63324153e-04, 4.88149730e-04,\n",
       "          2.65809504e-04, 7.26991566e-05, 5.66230995e-07, 6.93253526e-08,\n",
       "          3.56534962e-04, 1.32123359e-05, 1.09220391e-05, 1.02453055e-06,\n",
       "          4.81015217e-04, 2.11510123e-04, 4.11354777e-05, 4.88272308e-05,\n",
       "          3.06052898e-05, 9.34876265e-09, 1.64899502e-05, 6.38866259e-05,\n",
       "          3.38396421e-06, 6.73379458e-04, 5.08714174e-06, 1.11476667e-02,\n",
       "          7.68798927e-05, 1.13322411e-03, 4.94981743e-03, 4.97578594e-06,\n",
       "          2.20861650e-04, 2.90111097e-06, 8.73565841e-06, 1.90532818e-01,\n",
       "          7.36474394e-05, 6.95276447e-03, 6.91856316e-04, 2.05084725e-05,\n",
       "          1.08435855e-03, 1.33403053e-03, 1.73190399e-03, 4.87636644e-05,\n",
       "          7.39210402e-04, 6.57574087e-02, 4.32213274e-05, 4.53823828e-04,\n",
       "          9.01567866e-04, 9.30431270e-05, 2.12747268e-02, 6.04588866e-01,\n",
       "          2.62564444e-03, 4.34944877e-06, 5.93779469e-03, 1.60709936e-02,\n",
       "          3.06174741e-04, 8.93365592e-04, 9.84998699e-03, 7.40018950e-05,\n",
       "          1.10033683e-01, 1.58720999e-03, 3.79067403e-03, 8.09891164e-01,\n",
       "          1.21655667e-05, 2.91887508e-03, 1.60527139e-04, 1.04887658e-06,\n",
       "          8.38742405e-02, 4.49270243e-04, 1.60324817e-06, 1.14522200e-05,\n",
       "          2.34313484e-05, 2.54585932e-04, 7.74864702e-07, 5.09729362e-05,\n",
       "          2.59921580e-06, 1.61672462e-04, 4.36289934e-03, 1.11682049e-04,\n",
       "          5.80356340e-04, 4.88396427e-06, 2.98985810e-06, 4.01068867e-09,\n",
       "          8.78656647e-06, 4.41952143e-03, 1.36229239e-04, 2.44050316e-04,\n",
       "          3.53794149e-03, 1.23426827e-04, 5.05463913e-06, 4.17285219e-06,\n",
       "          2.58685090e-03, 1.28197280e-04, 9.27595538e-05, 1.34062748e-05,\n",
       "          4.23327496e-04, 2.69381533e-04, 7.03273981e-05, 7.93307918e-05,\n",
       "          4.89885162e-04, 9.37845002e-08, 1.11555397e-04, 2.43398041e-04,\n",
       "          3.76515982e-06, 1.99156627e-03, 8.05417149e-05, 1.51196690e-02,\n",
       "          5.40287583e-04, 2.57677073e-03, 4.75757709e-03, 2.51842430e-05,\n",
       "          6.84852072e-04, 4.59876310e-06, 1.35643859e-04, 8.76903534e-03,\n",
       "          5.93418845e-05, 5.89798437e-03, 2.53286469e-03, 4.78139664e-05,\n",
       "          6.72310665e-02, 5.15091873e-04, 8.09266494e-05, 6.86209896e-05,\n",
       "          3.15735379e-04, 5.74489415e-01, 1.17521260e-04, 5.71558659e-04,\n",
       "          2.56327111e-02, 2.60527275e-04, 9.73694772e-02, 6.07522547e-01,\n",
       "          8.26861302e-04, 1.05720289e-06, 4.25829727e-04, 1.49279612e-03,\n",
       "          1.74161432e-05, 3.37465870e-04, 1.12428301e-04, 3.79809208e-05,\n",
       "          6.32970221e-03, 2.89305637e-04, 5.73216239e-03, 9.72346604e-01,\n",
       "          6.56041539e-06, 2.20920634e-03, 2.07570949e-04, 5.81967015e-06,\n",
       "          6.54182136e-02, 8.03165312e-05, 3.32418517e-06, 2.51940992e-06,\n",
       "          5.64144793e-05, 1.94832639e-04, 2.83169697e-06, 1.17482650e-05,\n",
       "          8.45051460e-08, 2.35111929e-05, 4.72115586e-03, 3.48203394e-05,\n",
       "          2.41945934e-04, 3.83413317e-06, 4.66343749e-07, 5.07896747e-09,\n",
       "          2.39426595e-06, 5.23069990e-04, 2.38557768e-05, 7.97408866e-05,\n",
       "          1.01642013e-02, 1.71121908e-04, 3.18145612e-05, 5.02788971e-05,\n",
       "          8.82274378e-03, 3.82885482e-05, 1.01462989e-04, 1.02595895e-05,\n",
       "          5.73221805e-05, 6.11629875e-05, 4.31096087e-05, 1.64720172e-04,\n",
       "          1.13365102e-04, 2.76694578e-07, 3.26261688e-05, 2.62342364e-04,\n",
       "          3.15246524e-07, 2.69054458e-03, 9.38686280e-05, 6.22643624e-03,\n",
       "          3.41047155e-04, 8.24005343e-04, 3.49018909e-03, 1.45446847e-05,\n",
       "          8.77754181e-04, 4.47127286e-06, 4.67957900e-04, 2.62516504e-03,\n",
       "          7.72827625e-05, 3.17043671e-03, 8.92497972e-03, 3.54092263e-05,\n",
       "          3.78334783e-02, 1.97440691e-04, 1.25051183e-05, 4.04576895e-05,\n",
       "          8.80910666e-05, 2.91502148e-01, 6.43912281e-05, 3.09010211e-04,\n",
       "          2.59695351e-02, 2.10884042e-04, 4.35785651e-02, 9.36081886e-01,\n",
       "          2.91377753e-02, 5.75495778e-06, 1.00593371e-02, 3.62956314e-04,\n",
       "          9.74190771e-05, 1.95803144e-03, 1.56546172e-04, 6.25370158e-05,\n",
       "          1.14233620e-01, 3.33637989e-04, 2.14032363e-02, 7.31462479e-01,\n",
       "          7.03563683e-06, 9.33255476e-04, 1.24436032e-04, 5.85674513e-07,\n",
       "          2.91560567e-03, 1.75823916e-05, 5.81671706e-08, 4.03961076e-06,\n",
       "          3.88193394e-06, 1.76695303e-05, 6.07700315e-07, 5.41074132e-06,\n",
       "          9.91181196e-07, 2.93224966e-05, 3.53910116e-04, 4.04669081e-05,\n",
       "          6.10222633e-04, 1.20138498e-06, 1.58679114e-07, 5.90048810e-09,\n",
       "          5.00773865e-07, 1.68735438e-04, 1.52454368e-05, 8.04918018e-05,\n",
       "          1.60678732e-03, 1.30788874e-04, 1.58041360e-06, 2.41326302e-06,\n",
       "          6.77433709e-05, 1.53558346e-06, 1.55893522e-05, 2.64644927e-06,\n",
       "          4.56631606e-05, 1.16439514e-05, 3.69103509e-05, 3.67993562e-05,\n",
       "          1.25981445e-04, 5.09396827e-08, 6.68610710e-06, 6.16403195e-05,\n",
       "          2.61955688e-06, 9.91078909e-04, 7.67069105e-06, 2.64111767e-03,\n",
       "          1.19714503e-04, 2.60092202e-04, 1.04853157e-02, 7.79611582e-06,\n",
       "          2.93825462e-04, 1.38289079e-06, 1.59381998e-05, 6.15477702e-03,\n",
       "          3.80024067e-05, 9.58783203e-04, 8.45989198e-05, 1.35690370e-05,\n",
       "          8.27303855e-04, 1.60136377e-04, 4.59747862e-05, 1.78838964e-05,\n",
       "          4.75954221e-05, 5.32352805e-01, 1.22612973e-05, 2.39923276e-04,\n",
       "          2.11814244e-04, 5.28898527e-05, 2.65074894e-03, 9.66905177e-01,\n",
       "          4.45333892e-04, 7.66583355e-07, 4.84849064e-04, 7.23770936e-05,\n",
       "          5.46566343e-06, 1.89992221e-04, 5.86494480e-06, 9.78372700e-05,\n",
       "          2.86866142e-03, 1.18072778e-04, 7.22939894e-02, 9.18049872e-01,\n",
       "          3.09715892e-06, 7.48309540e-04, 1.75554480e-04, 4.09297354e-06,\n",
       "          3.25530060e-02, 3.09634743e-05, 4.65533191e-07, 1.61038906e-06,\n",
       "          1.30042508e-05, 8.77700877e-05, 1.51422807e-06, 7.12526025e-06,\n",
       "          1.51794310e-08, 1.53742531e-05, 9.52350034e-04, 6.49243157e-05,\n",
       "          7.67242280e-04, 3.53136147e-06, 6.31222932e-08, 6.03752337e-09,\n",
       "          8.99328484e-07, 5.30358120e-05, 3.26983491e-06, 4.11913752e-05,\n",
       "          4.32340289e-03, 1.47714178e-04, 9.23438347e-06, 6.66456835e-05,\n",
       "          1.26069167e-03, 6.75539150e-06, 4.16468720e-05, 4.04457933e-06,\n",
       "          3.76326789e-05, 1.04763649e-05, 4.21064397e-05, 5.39387693e-05,\n",
       "          1.02539918e-04, 2.05376196e-07, 9.05600064e-06, 4.53736320e-05,\n",
       "          5.54878490e-08, 2.88181519e-03, 2.99887124e-05, 8.40934168e-04,\n",
       "          9.66709849e-05, 1.68430983e-04, 1.00365514e-02, 1.10687770e-05,\n",
       "          2.03076212e-04, 5.35964091e-06, 1.14189010e-04, 4.54645604e-04,\n",
       "          3.78987570e-05, 5.40328503e-04, 5.26578689e-04, 1.75629848e-05,\n",
       "          2.78440211e-03, 8.03058065e-05, 2.36945903e-06, 9.09352548e-06,\n",
       "          2.77695181e-05, 3.63435507e-01, 1.47888522e-05, 1.20717079e-04,\n",
       "          1.14575063e-03, 6.09050840e-05, 3.26162344e-03, 9.75733042e-01,\n",
       "          2.15863762e-03, 8.48124546e-06, 3.08812386e-03, 1.00048622e-02,\n",
       "          2.45664909e-04, 8.31340381e-04, 1.91961590e-03, 2.14428641e-04,\n",
       "          9.10311401e-01, 9.10364848e-04, 4.91537736e-04, 5.00875339e-02,\n",
       "          9.15405872e-06, 2.59691081e-03, 9.02632673e-05, 7.34759453e-08,\n",
       "          1.66479517e-02, 9.73545320e-05, 3.20668931e-08, 6.98510075e-06,\n",
       "          4.57214327e-07, 4.01302641e-05, 1.64917111e-07, 2.23158349e-05,\n",
       "          4.64448613e-06, 1.77632799e-04, 2.31836442e-04, 5.47868922e-06,\n",
       "          2.88932963e-04, 1.36624158e-06, 5.22026198e-07, 6.80783963e-09,\n",
       "          1.23487825e-06, 1.98337855e-03, 2.14825879e-04, 5.61689609e-04,\n",
       "          3.45778244e-04, 3.90104215e-05, 6.11869325e-07, 3.92885084e-08,\n",
       "          2.30731894e-04, 2.66036568e-05, 1.45233544e-05, 6.97158441e-07,\n",
       "          4.77921072e-04, 1.80063187e-04, 5.74500737e-05, 8.72719975e-05,\n",
       "          2.90206026e-05, 6.02057293e-09, 1.85440003e-05, 2.08742222e-05,\n",
       "          1.27463409e-06, 8.24405870e-04, 3.84726764e-06, 4.40518139e-03,\n",
       "          1.53295259e-04, 1.25366333e-03, 4.78880433e-03, 3.82859025e-06,\n",
       "          2.68026313e-04, 3.61928278e-06, 7.79772199e-06, 5.40842041e-02,\n",
       "          7.63885837e-05, 3.92479356e-03, 6.91007881e-04, 2.16719200e-05,\n",
       "          1.44299155e-03, 9.23036423e-04, 7.44869583e-04, 5.33137027e-05,\n",
       "          3.44198575e-04, 1.04966208e-01, 3.65578708e-05, 1.64122524e-04,\n",
       "          1.89987640e-03, 1.50002656e-04, 5.37504964e-02, 5.48740089e-01],\n",
       "         dtype=float32),\n",
       "   'action_ids': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "          18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "          35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "          52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "          69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,  1,  2,  3,  4,  5,\n",
       "           6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "          23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
       "          40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56,\n",
       "          57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73,\n",
       "          74, 75, 76, 77, 78, 79, 80,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
       "          11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
       "          28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,\n",
       "          45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
       "          62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78,\n",
       "          79, 80,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "          16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,\n",
       "          33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
       "          50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
       "          67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,  1,  2,  3,\n",
       "           4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "          21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "          38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "          55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "          72, 73, 74, 75, 76, 77, 78, 79, 80,  1,  2,  3,  4,  5,  6,  7,  8,\n",
       "           9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
       "          26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
       "          43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
       "          60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,\n",
       "          77, 78, 79, 80,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
       "          14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "          31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "          48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
       "          65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,  1,\n",
       "           2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "          36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
       "          53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
       "          70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,  1,  2,  3,  4,  5,  6,\n",
       "           7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "          24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
       "          41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
       "          58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
       "          75, 76, 77, 78, 79, 80,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
       "          12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
       "          29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
       "          46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62,\n",
       "          63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n",
       "          80])}})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "        dataset=dataset,\n",
    "        predictions=predictions,\n",
    "        output_folder=output_folder,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37696377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
