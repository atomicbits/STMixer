{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1adfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import moviepy \n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from alphaction.config import cfg\n",
    "from alphaction.modeling.detector import build_detection_model\n",
    "from alphaction.utils.checkpoint import ActionCheckpointer\n",
    "from alphaction.utils.comm import get_world_size\n",
    "\n",
    "\n",
    "from my_utils.gen_utils import create_experiment_folder\n",
    "from my_utils.video_processing import get_video_info, get_frame_from_video\n",
    "from my_utils.slicing import get_slice_bboxes, generate_sliding_window_gif\n",
    "\n",
    "from my_utils.video_processing import segment_crop_video\n",
    "from my_utils.my_ava_preprocessing import ava_preprocessing_cv2, clip_constructor, prepare_collated_batches\n",
    "from my_utils.ava_postprocessing import concatenate_results\n",
    "from my_utils.visualization import action_visualizer_frame_index\n",
    "\n",
    "from my_utils.gen_utils import parse_label_file\n",
    "\n",
    "from my_utils.ava_postprocessing import clip_boxes_tensor, map_bbox_from_prep_to_crop, map_bbox_from_crop_to_orig\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8dbf9",
   "metadata": {},
   "source": [
    "### 1. CONFIG\n",
    "#### 1.1 Main Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b529302b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'VMAEv2',\n",
       " 'model_params': {'person_threshold': 0.3, 'sampling_rate': 3},\n",
       " 'orig_post_processing': {'top_k': 5},\n",
       " 'aggregation': {'method': {}, 'params': {}},\n",
       " 'video_path': '../input_dir/markt2_fight.mp4',\n",
       " 'slicing_params': {'slice_height': 800,\n",
       "  'slice_width': 1000,\n",
       "  'overlap_ratio': 0.2},\n",
       " 'video_params': {'st_frame_index': 50, 'length_input': 100}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'VMAEv2'\n",
    "\n",
    "\n",
    "person_threshold = 0.3 # confidence threshold on actor. 0.6 is the defualt\n",
    "sampling_rate = 3 # sampling rate: 4 is the defualt\n",
    "top_k = 5 # number of actions per person\n",
    "video_path = '../input_dir/markt2_fight.mp4' # path to video\n",
    "\n",
    "slice_height = 800 # patch height\n",
    "slice_width = 1000 # patch width\n",
    "overlap_ratio = 0.2 # patch overlap\n",
    "\n",
    "starting_frame_index = 50 # starting frame index, defualt = 0\n",
    "length_input = 100 # number of frames to be processed\n",
    "\n",
    "exp_dict = {'model_name': model_name,\n",
    "            'model_params': {'person_threshold': person_threshold, \n",
    "                             'sampling_rate': sampling_rate},\n",
    "            'orig_post_processing':{'top_k': top_k},\n",
    "            'aggregation': {'method': {}, \n",
    "                            'params': {}},\n",
    "            'video_path': video_path,\n",
    "            'slicing_params': {'slice_height': slice_height, \n",
    "                               'slice_width': slice_width, \n",
    "                               'overlap_ratio':overlap_ratio},\n",
    "            'video_params': {'st_frame_index': starting_frame_index, \n",
    "                             'length_input':length_input\n",
    "                             }\n",
    "           }\n",
    "\n",
    "exp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f606b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output_dir/markt2_fight/VMAEv2/patch_batch/exp_5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_name = os.path.basename(video_path).split('.')[0]\n",
    "output_directory = f'../output_dir/{video_name}/{model_name}/patch_batch/' \n",
    "output_directory = create_experiment_folder(output_directory, 'exp')\n",
    "output_directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28971ba",
   "metadata": {},
   "source": [
    "#### 1.2 Model Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbefc292",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'VMAEv2':\n",
    "    config_file = '../config_files/VMAEv2-ViTB-16x4.yaml'\n",
    "if model_name == 'VMAE':\n",
    "    config_file = '../config_files/VMAE-ViTB-16x4.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1102a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfd71644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model weight path\n",
    "if model_name == 'VMAEv2':\n",
    "    cfg.merge_from_list([\"MODEL.WEIGHT\", \"../checkpoints/VMAEv2_ViTB_16x4.pth\"])\n",
    "if model_name == 'VMAE':\n",
    "    cfg.merge_from_list([\"MODEL.WEIGHT\", \"../checkpoints/VMAE_ViTB_16x4.pth\"])\n",
    "\n",
    "# change output dir\n",
    "cfg.merge_from_list([\"OUTPUT_DIR\", \"../output_dir/\"])\n",
    "\n",
    "# change person threshold\n",
    "cfg.merge_from_list([\"MODEL.STM.PERSON_THRESHOLD\", person_threshold])\n",
    "\n",
    "# change sampling rate\n",
    "cfg.merge_from_list([\"DATA.SAMPLING_RATE\", sampling_rate])\n",
    "\n",
    "# change path for data_dir\n",
    "cfg.merge_from_list([\"DATA.PATH_TO_DATA_DIR\", \"/work/ava\"])\n",
    "\n",
    "# folder name of annotations\n",
    "cfg.merge_from_list([\"AVA.ANNOTATION_DIR\", \"annotations/\"])\n",
    "\n",
    "# file name of  frame_lists\n",
    "cfg.merge_from_list([\"AVA.TRAIN_LISTS\", ['sample.csv']])\n",
    "cfg.merge_from_list([\"AVA.TEST_LISTS\", ['sample.csv']])\n",
    "\n",
    "# file name of predicted_bboxes\n",
    "cfg.merge_from_list([\"AVA.TRAIN_GT_BOX_LISTS\", ['ava_sample_predicted_boxes.csv']])\n",
    "cfg.merge_from_list([\"AVA.TEST_GT_BOX_LISTS\", ['ava_sample_predicted_boxes.csv']])\n",
    "\n",
    "# file name of exlusions\n",
    "cfg.merge_from_list([\"AVA.EXCLUSION_FILE\", 'ava_sample_train_excluded_timestamps_v2.2.csv'])\n",
    "\n",
    "# number of batches in test scenario\n",
    "cfg.merge_from_list([\"TEST.VIDEOS_PER_BATCH\", 1])\n",
    "\n",
    "# number of workers\n",
    "cfg.merge_from_list([\"DATALOADER.NUM_WORKERS\", 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9b66c",
   "metadata": {},
   "source": [
    "### 2. ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c841ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.DATALOADER.SIZE_DIVISIBILITY:  32\n",
      "cfg.DATA.SAMPLING_RATE:  3\n",
      "cfg.DATA.NUM_FRAMES:  16\n",
      "self_seq_len:  48\n",
      "cfg.MODEL.STM.ACTION_CLASSES:  80\n",
      "Augmentation params:  [0.45, 0.45, 0.45] [0.225, 0.225, 0.225] False\n",
      "scale and flip params [256] 1333 False\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    # The shape of model input should be divisible into this. Otherwise, padding 0 to left and bottum. \n",
    "    print(\"cfg.DATALOADER.SIZE_DIVISIBILITY: \", cfg.DATALOADER.SIZE_DIVISIBILITY)\n",
    "    \n",
    "    # Sampling rate in constructing the clips.\n",
    "    self_sample_rate =  cfg.DATA.SAMPLING_RATE\n",
    "    print(\"cfg.DATA.SAMPLING_RATE: \", cfg.DATA.SAMPLING_RATE)\n",
    "    \n",
    "    # Length of clip\n",
    "    self_video_length = cfg.DATA.NUM_FRAMES\n",
    "    print(\"cfg.DATA.NUM_FRAMES: \", cfg.DATA.NUM_FRAMES)\n",
    "    \n",
    "    # Length of sequence frames from which a clip is constructed.\n",
    "    self_seq_len = self_video_length * self_sample_rate\n",
    "    print(\"self_seq_len: \", self_seq_len)\n",
    "    \n",
    "    self_num_classes = cfg.MODEL.STM.ACTION_CLASSES\n",
    "    print(\"cfg.MODEL.STM.ACTION_CLASSES: \", self_num_classes)\n",
    "    \n",
    "    # Augmentation params.\n",
    "    self_data_mean = cfg.DATA.MEAN\n",
    "    self_data_std = cfg.DATA.STD\n",
    "    self_use_bgr = cfg.AVA.BGR\n",
    "    print(\"Augmentation params: \", self_data_mean, self_data_std, self_use_bgr)\n",
    "    \n",
    "    self_jitter_min_scale = cfg.DATA.TEST_MIN_SCALES\n",
    "    self_jitter_max_scale = cfg.DATA.TEST_MAX_SCALE\n",
    "    self_test_force_flip = cfg.AVA.TEST_FORCE_FLIP\n",
    "\n",
    "    print(\"scale and flip params\", self_jitter_min_scale, self_jitter_max_scale, self_test_force_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a9b6d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "seq_len = cfg.DATA.NUM_FRAMES * cfg.DATA.SAMPLING_RATE\n",
    "print(seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c476721",
   "metadata": {},
   "source": [
    "### 3. VIDEO Info and Slicing Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b2b062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = get_video_info(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ffd500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame_count': 368,\n",
       " 'frame_rate': 16.999,\n",
       " 'width': 2592,\n",
       " 'height': 1944,\n",
       " 'fps': 16.999}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206abdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'VMAEv2',\n",
       " 'model_params': {'person_threshold': 0.3, 'sampling_rate': 3},\n",
       " 'orig_post_processing': {'top_k': 5},\n",
       " 'aggregation': {'method': {}, 'params': {}},\n",
       " 'video_path': '../input_dir/markt2_fight.mp4',\n",
       " 'slicing_params': {'slice_height': 800,\n",
       "  'slice_width': 1000,\n",
       "  'overlap_ratio': 0.2},\n",
       " 'video_params': {'st_frame_index': 50,\n",
       "  'length_input': 100,\n",
       "  'frame_count': 368,\n",
       "  'frame_rate': 16.999,\n",
       "  'width': 2592,\n",
       "  'height': 1944,\n",
       "  'fps': 16.999}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dict['video_params'].update(video_info)\n",
    "exp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ae5ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_height = video_info['height']\n",
    "frame_width = video_info['width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9437a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_coordinates = get_slice_bboxes(frame_height, frame_width, slice_height, slice_width, False, overlap_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50a76e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82969bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1000, 800],\n",
       " [800, 0, 1800, 800],\n",
       " [1592, 0, 2592, 800],\n",
       " [0, 640, 1000, 1440],\n",
       " [800, 640, 1800, 1440],\n",
       " [1592, 640, 2592, 1440],\n",
       " [0, 1144, 1000, 1944],\n",
       " [800, 1144, 1800, 1944],\n",
       " [1592, 1144, 2592, 1944]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "092706bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frame = get_frame_from_video(video_path, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae2508b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    generate_sliding_window_gif(sample_frame, patches_coordinates, gif_filename='sliding_window.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2cd609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4b6873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    display(Image(filename='sliding_window.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31835a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'sliding_window.gif': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    !rm sliding_window.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a21cd1",
   "metadata": {},
   "source": [
    "### 4. building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73b580b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detection_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de5b23c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STMDetector(\n",
       "  (backbone): ViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0181818176060915)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.036363635212183)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05454545468091965)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.072727270424366)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09090908616781235)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10909091681241989)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12727272510528564)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1454545557498932)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16363637149333954)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1818181872367859)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000000298023224)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose3d(384, 192, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (4): Conv3d(192, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (5): LayerNorm()\n",
       "      (6): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): Conv3d(384, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (1): LayerNorm()\n",
       "      (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (stm_head): STMDecoder(\n",
       "    (init_spatial_queries): Embedding(100, 256)\n",
       "    (init_temporal_queries): Embedding(100, 256)\n",
       "    (decoder_stages): ModuleList(\n",
       "      (0): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (1): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (2): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (3): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (4): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (5): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): SetCriterion(\n",
       "      (matcher): HungarianMatcher()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d541b8f",
   "metadata": {},
   "source": [
    "### 5. loading weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14f4d3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output_dir/'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = cfg.OUTPUT_DIR\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "750d81f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ActionCheckpointer(cfg, model, save_dir=output_dir)\n",
    "checkpointer.load(cfg.MODEL.WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7298a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d7b9b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_active = cfg.MODEL.STM.MEM_ACTIVE\n",
    "mem_active  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "222717c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35d1e8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_devices = get_world_size()\n",
    "num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10ee7162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STMDetector(\n",
       "  (backbone): ViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0181818176060915)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.036363635212183)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05454545468091965)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.072727270424366)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09090908616781235)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10909091681241989)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12727272510528564)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1454545557498932)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16363637149333954)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1818181872367859)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000000298023224)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose3d(384, 192, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (4): Conv3d(192, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (5): LayerNorm()\n",
       "      (6): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): Conv3d(384, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (1): LayerNorm()\n",
       "      (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (stm_head): STMDecoder(\n",
       "    (init_spatial_queries): Embedding(100, 256)\n",
       "    (init_temporal_queries): Embedding(100, 256)\n",
       "    (decoder_stages): ModuleList(\n",
       "      (0): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (1): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (2): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (3): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (4): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (5): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): SetCriterion(\n",
       "      (matcher): HungarianMatcher()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0e7d5",
   "metadata": {},
   "source": [
    "## 6. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04d05976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1000, 800],\n",
       " [800, 0, 1800, 800],\n",
       " [1592, 0, 2592, 800],\n",
       " [0, 640, 1000, 1440],\n",
       " [800, 640, 1800, 1440],\n",
       " [1592, 640, 2592, 1440],\n",
       " [0, 1144, 1000, 1944],\n",
       " [800, 1144, 1800, 1944],\n",
       " [1592, 1144, 2592, 1944]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf4445e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'bend/bow (at the waist)', 2: 'crawl', 3: 'crouch/kneel', 4: 'dance', 5: 'fall down', 6: 'get up', 7: 'jump/leap', 8: 'lie/sleep', 9: 'martial art', 10: 'run/jog', 11: 'sit', 12: 'stand', 13: 'swim', 14: 'walk', 15: 'answer phone', 16: 'brush teeth', 17: 'carry/hold (an object)', 18: 'catch (an object)', 19: 'chop', 20: 'climb (e.g., a mountain)', 21: 'clink glass', 22: 'close (e.g., a door, a box)', 23: 'cook', 24: 'cut', 25: 'dig', 26: 'dress/put on clothing', 27: 'drink', 28: 'drive (e.g., a car, a truck)', 29: 'eat', 30: 'enter', 31: 'exit', 32: 'extract', 33: 'fishing', 34: 'hit (an object)', 35: 'kick (an object)', 36: 'lift/pick up', 37: 'listen (e.g., to music)', 38: 'open (e.g., a window, a car door)', 39: 'paint', 40: 'play board game', 41: 'play musical instrument', 42: 'play with pets', 43: 'point to (an object)', 44: 'press', 45: 'pull (an object)', 46: 'push (an object)', 47: 'put down', 48: 'read', 49: 'ride (e.g., a bike, a car, a horse)', 50: 'row boat', 51: 'sail boat', 52: 'shoot', 53: 'shovel', 54: 'smoke', 55: 'stir', 56: 'take a photo', 57: 'text on/look at a cellphone', 58: 'throw', 59: 'touch (an object)', 60: 'turn (e.g., a screwdriver)', 61: 'watch (e.g., TV)', 62: 'work on a computer', 63: 'write', 64: 'fight/hit (a person)', 65: 'give/serve (an object) to (a person)', 66: 'grab (a person)', 67: 'hand clap', 68: 'hand shake', 69: 'hand wave', 70: 'hug (a person)', 71: 'kick (a person)', 72: 'kiss (a person)', 73: 'lift (a person)', 74: 'listen to (a person)', 75: 'play with kids', 76: 'push (another person)', 77: 'sing to (e.g., self, a person, a group)', 78: 'take (an object) from (a person)', 79: 'talk to (e.g., self, a person, a group)', 80: 'watch (a person)'}\n"
     ]
    }
   ],
   "source": [
    "file_path = 'labels.txt'  # Specify the path to your text file\n",
    "label_dict = parse_label_file(file_path)\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8753da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing patches: 0it [00:00, ?it/s]\n",
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:02<01:56,  2.23s/it]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:02<00:59,  1.16s/it]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:03<00:39,  1.25it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:03<00:30,  1.59it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:03<00:25,  1.86it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:04<00:22,  2.08it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:04<00:20,  2.23it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:04<00:19,  2.32it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:05<00:18,  2.40it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:05<00:17,  2.47it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:06<00:16,  2.51it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:06<00:15,  2.56it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:06<00:15,  2.59it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:07<00:14,  2.62it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:07<00:14,  2.62it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:07<00:14,  2.61it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:08<00:13,  2.60it/s]\u001b[A\n",
      "Processing frames:  34%|                                                                              | 18/53 [00:08<00:13,  2.64it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:09<00:12,  2.66it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:09<00:12,  2.65it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:09<00:12,  2.66it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:10<00:11,  2.66it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:10<00:11,  2.68it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:10<00:10,  2.68it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:11<00:10,  2.70it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:11<00:10,  2.68it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:12<00:09,  2.68it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:12<00:09,  2.67it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:12<00:08,  2.69it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:13<00:08,  2.70it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:13<00:08,  2.68it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:13<00:07,  2.64it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:14<00:07,  2.62it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:14<00:07,  2.64it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:15<00:06,  2.58it/s]\u001b[A\n",
      "Processing frames:  68%|                                      | 36/53 [00:15<00:06,  2.58it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:15<00:06,  2.60it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:16<00:05,  2.62it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:16<00:05,  2.65it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:17<00:05,  2.57it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:17<00:04,  2.51it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:17<00:04,  2.49it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:18<00:04,  2.50it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:18<00:03,  2.55it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:18<00:03,  2.59it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:19<00:02,  2.61it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:19<00:02,  2.66it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:20<00:01,  2.67it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:20<00:01,  2.68it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:20<00:01,  2.60it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:21<00:00,  2.55it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:21<00:00,  2.54it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:22<00:00,  2.40it/s]\u001b[A\n",
      "Processing patches: 1it [00:26, 26.23s/it]\n",
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:00<00:18,  2.76it/s]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:00<00:18,  2.77it/s]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:01<00:18,  2.77it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:01<00:17,  2.73it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:01<00:17,  2.72it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:02<00:17,  2.69it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:02<00:16,  2.72it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:02<00:16,  2.71it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:03<00:16,  2.71it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:03<00:15,  2.70it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:04<00:15,  2.73it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:04<00:14,  2.75it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:04<00:14,  2.77it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:05<00:14,  2.78it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:05<00:13,  2.79it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:05<00:13,  2.79it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:06<00:12,  2.79it/s]\u001b[A\n",
      "Processing frames:  34%|                                                                              | 18/53 [00:06<00:12,  2.79it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:06<00:12,  2.77it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:07<00:11,  2.79it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:07<00:11,  2.77it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:08<00:11,  2.75it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:08<00:11,  2.70it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:08<00:10,  2.71it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:09<00:10,  2.71it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:09<00:09,  2.72it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:09<00:09,  2.75it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:10<00:09,  2.76it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:10<00:08,  2.77it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:10<00:08,  2.78it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:11<00:07,  2.75it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:11<00:07,  2.74it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:12<00:07,  2.77it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:12<00:06,  2.76it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:12<00:06,  2.78it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  68%|                                      | 36/53 [00:13<00:06,  2.79it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:13<00:05,  2.80it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:13<00:05,  2.80it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:14<00:04,  2.80it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:14<00:04,  2.80it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:14<00:04,  2.80it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:15<00:03,  2.81it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:15<00:03,  2.81it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:15<00:03,  2.82it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:16<00:02,  2.80it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:16<00:02,  2.81it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:16<00:02,  2.82it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:17<00:01,  2.83it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:17<00:01,  2.83it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:18<00:01,  2.80it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:18<00:00,  2.81it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:18<00:00,  2.82it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:19<00:00,  2.77it/s]\u001b[A\n",
      "Processing patches: 2it [00:49, 24.50s/it]\n",
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:00<00:18,  2.87it/s]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:00<00:17,  2.88it/s]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:01<00:17,  2.88it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:01<00:17,  2.84it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:01<00:16,  2.85it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:02<00:16,  2.84it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:02<00:16,  2.85it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:02<00:15,  2.86it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:03<00:15,  2.86it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:03<00:14,  2.87it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:03<00:14,  2.87it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:04<00:14,  2.87it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:04<00:13,  2.86it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:04<00:13,  2.87it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:05<00:13,  2.86it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:05<00:12,  2.86it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:05<00:12,  2.86it/s]\u001b[A\n",
      "Processing frames:  34%|                                                                              | 18/53 [00:06<00:12,  2.86it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:06<00:11,  2.85it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:06<00:11,  2.85it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:07<00:11,  2.85it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:07<00:10,  2.84it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:08<00:10,  2.85it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:08<00:10,  2.82it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:08<00:09,  2.84it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:09<00:09,  2.84it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:09<00:09,  2.85it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:09<00:08,  2.86it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:10<00:08,  2.85it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:10<00:08,  2.85it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:10<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:11<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:11<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:11<00:06,  2.86it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:12<00:06,  2.85it/s]\u001b[A\n",
      "Processing frames:  68%|                                      | 36/53 [00:12<00:05,  2.86it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:12<00:05,  2.86it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:13<00:05,  2.85it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:13<00:04,  2.85it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:14<00:04,  2.86it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:14<00:04,  2.86it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:14<00:03,  2.86it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:15<00:03,  2.88it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:15<00:03,  2.88it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:15<00:02,  2.88it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:16<00:02,  2.87it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:16<00:02,  2.86it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:16<00:01,  2.88it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:17<00:01,  2.86it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:17<00:01,  2.85it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:17<00:00,  2.86it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:18<00:00,  2.86it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:18<00:00,  2.86it/s]\u001b[A\n",
      "Processing patches: 3it [01:12, 23.90s/it]\n",
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:00<00:18,  2.86it/s]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:00<00:17,  2.85it/s]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:01<00:17,  2.83it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:01<00:17,  2.82it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:01<00:17,  2.81it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:02<00:16,  2.80it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:02<00:16,  2.80it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:02<00:15,  2.84it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:03<00:15,  2.86it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:03<00:14,  2.87it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:03<00:14,  2.89it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:04<00:14,  2.88it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:04<00:13,  2.89it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:04<00:13,  2.87it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:05<00:13,  2.86it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:05<00:12,  2.86it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:05<00:12,  2.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  34%|                                                                              | 18/53 [00:06<00:12,  2.87it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:06<00:11,  2.87it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:07<00:11,  2.88it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:07<00:11,  2.88it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:07<00:10,  2.89it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:08<00:10,  2.87it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:08<00:10,  2.87it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:08<00:09,  2.86it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:09<00:09,  2.82it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:09<00:09,  2.81it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:09<00:08,  2.80it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:10<00:08,  2.81it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:10<00:08,  2.82it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:10<00:07,  2.81it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:11<00:07,  2.83it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:11<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:11<00:06,  2.86it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:12<00:06,  2.88it/s]\u001b[A\n",
      "Processing frames:  68%|                                      | 36/53 [00:12<00:05,  2.86it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:12<00:05,  2.85it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:13<00:05,  2.81it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:13<00:04,  2.81it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:14<00:04,  2.82it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:14<00:04,  2.83it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:14<00:03,  2.81it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:15<00:03,  2.82it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:15<00:03,  2.83it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:15<00:02,  2.81it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:16<00:02,  2.77it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:16<00:02,  2.76it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:16<00:01,  2.76it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:17<00:01,  2.75it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:17<00:01,  2.74it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:18<00:00,  2.74it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:18<00:00,  2.75it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:18<00:00,  2.82it/s]\u001b[A\n",
      "Processing patches: 4it [01:35, 23.51s/it]\n",
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:00<00:18,  2.75it/s]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:00<00:18,  2.82it/s]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:01<00:17,  2.83it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:01<00:17,  2.84it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:01<00:16,  2.85it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:02<00:16,  2.85it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:02<00:16,  2.86it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:02<00:15,  2.84it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:03<00:15,  2.81it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:03<00:15,  2.82it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:03<00:14,  2.82it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:04<00:14,  2.83it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:04<00:14,  2.82it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:04<00:13,  2.83it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:05<00:13,  2.83it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:05<00:13,  2.81it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:06<00:12,  2.82it/s]\u001b[A\n",
      "Processing frames:  34%|                                                                              | 18/53 [00:06<00:12,  2.81it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:06<00:12,  2.81it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:07<00:11,  2.82it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:07<00:11,  2.82it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:07<00:11,  2.80it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:08<00:10,  2.81it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:08<00:10,  2.80it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:08<00:10,  2.79it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:09<00:09,  2.80it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:09<00:09,  2.79it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:09<00:08,  2.79it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:10<00:08,  2.80it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:10<00:08,  2.81it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:11<00:07,  2.83it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:11<00:07,  2.83it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:11<00:07,  2.84it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:12<00:06,  2.84it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:12<00:06,  2.84it/s]\u001b[A\n",
      "Processing frames:  68%|                                      | 36/53 [00:12<00:05,  2.84it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:13<00:05,  2.83it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:13<00:05,  2.83it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:13<00:04,  2.83it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:14<00:04,  2.84it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:14<00:04,  2.83it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:14<00:03,  2.80it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:15<00:03,  2.80it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:15<00:03,  2.80it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:15<00:02,  2.81it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:16<00:02,  2.80it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:16<00:02,  2.78it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:17<00:01,  2.80it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:17<00:01,  2.81it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:17<00:01,  2.82it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:18<00:00,  2.83it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:18<00:00,  2.83it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:18<00:00,  2.82it/s]\u001b[A\n",
      "Processing patches: 5it [01:58, 23.45s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:00<00:17,  2.99it/s]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:00<00:17,  2.89it/s]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:01<00:17,  2.87it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:01<00:17,  2.87it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:01<00:16,  2.87it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:02<00:16,  2.88it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:02<00:16,  2.85it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:02<00:15,  2.83it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:03<00:15,  2.83it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:03<00:15,  2.83it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:03<00:15,  2.80it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:04<00:14,  2.82it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:04<00:14,  2.82it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:04<00:13,  2.84it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:05<00:13,  2.84it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:05<00:13,  2.84it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:05<00:12,  2.84it/s]\u001b[A\n",
      "Processing frames:  34%|                                                                              | 18/53 [00:06<00:12,  2.84it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:06<00:11,  2.84it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:07<00:11,  2.84it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:07<00:11,  2.84it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:07<00:10,  2.84it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:08<00:10,  2.84it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:08<00:10,  2.83it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:08<00:09,  2.83it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:09<00:09,  2.83it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:09<00:09,  2.84it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:09<00:08,  2.84it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:10<00:08,  2.84it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:10<00:08,  2.85it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:10<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:11<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:11<00:07,  2.86it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:11<00:06,  2.86it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:12<00:06,  2.86it/s]\u001b[A\n",
      "Processing frames:  68%|                                      | 36/53 [00:12<00:05,  2.86it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:13<00:05,  2.86it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:13<00:05,  2.86it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:13<00:04,  2.85it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:14<00:04,  2.85it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:14<00:04,  2.85it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:14<00:03,  2.85it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:15<00:03,  2.85it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:15<00:03,  2.85it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:15<00:02,  2.85it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:16<00:02,  2.85it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:16<00:02,  2.84it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:16<00:01,  2.85it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:17<00:01,  2.84it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:17<00:01,  2.83it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:17<00:00,  2.84it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:18<00:00,  2.83it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:18<00:00,  2.84it/s]\u001b[A\n",
      "Processing patches: 6it [02:21, 23.09s/it]\n",
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:00<00:19,  2.71it/s]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:00<00:17,  2.83it/s]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:01<00:17,  2.87it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:01<00:16,  2.90it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:01<00:16,  2.93it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:02<00:15,  2.94it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:02<00:15,  2.95it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:02<00:15,  2.95it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:03<00:14,  2.94it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:03<00:14,  2.94it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:03<00:14,  2.92it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:04<00:14,  2.91it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:04<00:13,  2.91it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:04<00:13,  2.91it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:05<00:13,  2.92it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:05<00:12,  2.92it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:05<00:12,  2.91it/s]\u001b[A\n",
      "Processing frames:  34%|                                                                              | 18/53 [00:06<00:12,  2.91it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:06<00:11,  2.90it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:06<00:11,  2.90it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:07<00:11,  2.90it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:07<00:10,  2.89it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:07<00:10,  2.88it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:08<00:10,  2.88it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:08<00:09,  2.88it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:08<00:09,  2.88it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:09<00:09,  2.89it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:09<00:08,  2.88it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:09<00:08,  2.88it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:10<00:07,  2.88it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:10<00:07,  2.87it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:11<00:07,  2.88it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:11<00:06,  2.88it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:11<00:06,  2.88it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:12<00:06,  2.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  68%|                                      | 36/53 [00:12<00:05,  2.87it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:12<00:05,  2.89it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:13<00:05,  2.87it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:13<00:04,  2.85it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:13<00:04,  2.86it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:14<00:04,  2.83it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:14<00:03,  2.82it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:14<00:03,  2.83it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:15<00:03,  2.83it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:15<00:02,  2.84it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:15<00:02,  2.84it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:16<00:02,  2.84it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:16<00:01,  2.84it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:17<00:01,  2.86it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:17<00:01,  2.88it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:17<00:00,  2.86it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:18<00:00,  2.86it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:18<00:00,  2.88it/s]\u001b[A\n",
      "Processing patches: 7it [02:43, 22.88s/it]\n",
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:00<00:17,  2.95it/s]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:00<00:17,  2.91it/s]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:01<00:17,  2.91it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:01<00:16,  2.91it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:01<00:16,  2.90it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:02<00:16,  2.88it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:02<00:15,  2.89it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:02<00:15,  2.89it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:03<00:15,  2.86it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:03<00:15,  2.82it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:03<00:14,  2.85it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:04<00:14,  2.86it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:04<00:14,  2.82it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:04<00:13,  2.80it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:05<00:13,  2.81it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:05<00:13,  2.81it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:05<00:12,  2.82it/s]\u001b[A\n",
      "Processing frames:  34%|                                                                              | 18/53 [00:06<00:12,  2.82it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:06<00:12,  2.82it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:07<00:11,  2.83it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:07<00:11,  2.82it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:07<00:10,  2.83it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:08<00:10,  2.84it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:08<00:10,  2.83it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:08<00:09,  2.82it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:09<00:09,  2.82it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:09<00:09,  2.82it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:09<00:08,  2.82it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:10<00:08,  2.82it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:10<00:08,  2.82it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:10<00:07,  2.82it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:11<00:07,  2.82it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:11<00:07,  2.82it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:11<00:06,  2.82it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:12<00:06,  2.80it/s]\u001b[A\n",
      "Processing frames:  68%|                                      | 36/53 [00:12<00:06,  2.81it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:13<00:05,  2.82it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:13<00:05,  2.82it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:13<00:04,  2.82it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:14<00:04,  2.82it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:14<00:04,  2.81it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:14<00:03,  2.80it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:15<00:03,  2.81it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:15<00:03,  2.80it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:15<00:02,  2.80it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:16<00:02,  2.79it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:16<00:02,  2.81it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:16<00:01,  2.80it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:17<00:01,  2.79it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:17<00:01,  2.79it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:18<00:00,  2.77it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:18<00:00,  2.77it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:18<00:00,  2.82it/s]\u001b[A\n",
      "Processing patches: 8it [03:06, 22.69s/it]\n",
      "Processing frames:   0%|                                                                                                                                | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "Processing frames:   2%|                                                                                                                     | 1/53 [00:00<00:17,  2.90it/s]\u001b[A\n",
      "Processing frames:   4%|                                                                                                                   | 2/53 [00:00<00:17,  2.88it/s]\u001b[A\n",
      "Processing frames:   6%|                                                                                                                 | 3/53 [00:01<00:17,  2.87it/s]\u001b[A\n",
      "Processing frames:   8%|                                                                                                               | 4/53 [00:01<00:17,  2.86it/s]\u001b[A\n",
      "Processing frames:   9%|                                                                                                            | 5/53 [00:01<00:16,  2.87it/s]\u001b[A\n",
      "Processing frames:  11%|                                                                                                          | 6/53 [00:02<00:16,  2.86it/s]\u001b[A\n",
      "Processing frames:  13%|                                                                                                        | 7/53 [00:02<00:16,  2.87it/s]\u001b[A\n",
      "Processing frames:  15%|                                                                                                      | 8/53 [00:02<00:15,  2.88it/s]\u001b[A\n",
      "Processing frames:  17%|                                                                                                   | 9/53 [00:03<00:15,  2.85it/s]\u001b[A\n",
      "Processing frames:  19%|                                                                                                | 10/53 [00:03<00:15,  2.84it/s]\u001b[A\n",
      "Processing frames:  21%|                                                                                              | 11/53 [00:03<00:14,  2.84it/s]\u001b[A\n",
      "Processing frames:  23%|                                                                                            | 12/53 [00:04<00:14,  2.84it/s]\u001b[A\n",
      "Processing frames:  25%|                                                                                         | 13/53 [00:04<00:14,  2.82it/s]\u001b[A\n",
      "Processing frames:  26%|                                                                                       | 14/53 [00:04<00:13,  2.81it/s]\u001b[A\n",
      "Processing frames:  28%|                                                                                     | 15/53 [00:05<00:13,  2.82it/s]\u001b[A\n",
      "Processing frames:  30%|                                                                                   | 16/53 [00:05<00:13,  2.82it/s]\u001b[A\n",
      "Processing frames:  32%|                                                                                | 17/53 [00:05<00:12,  2.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:  34%|                                                                              | 18/53 [00:06<00:12,  2.84it/s]\u001b[A\n",
      "Processing frames:  36%|                                                                            | 19/53 [00:06<00:11,  2.83it/s]\u001b[A\n",
      "Processing frames:  38%|                                                                          | 20/53 [00:07<00:11,  2.83it/s]\u001b[A\n",
      "Processing frames:  40%|                                                                       | 21/53 [00:07<00:11,  2.83it/s]\u001b[A\n",
      "Processing frames:  42%|                                                                     | 22/53 [00:07<00:10,  2.82it/s]\u001b[A\n",
      "Processing frames:  43%|                                                                   | 23/53 [00:08<00:10,  2.83it/s]\u001b[A\n",
      "Processing frames:  45%|                                                                 | 24/53 [00:08<00:10,  2.84it/s]\u001b[A\n",
      "Processing frames:  47%|                                                              | 25/53 [00:08<00:09,  2.82it/s]\u001b[A\n",
      "Processing frames:  49%|                                                            | 26/53 [00:09<00:09,  2.83it/s]\u001b[A\n",
      "Processing frames:  51%|                                                          | 27/53 [00:09<00:09,  2.83it/s]\u001b[A\n",
      "Processing frames:  53%|                                                        | 28/53 [00:09<00:08,  2.83it/s]\u001b[A\n",
      "Processing frames:  55%|                                                      | 29/53 [00:10<00:08,  2.84it/s]\u001b[A\n",
      "Processing frames:  57%|                                                   | 30/53 [00:10<00:08,  2.84it/s]\u001b[A\n",
      "Processing frames:  58%|                                                 | 31/53 [00:10<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  60%|                                               | 32/53 [00:11<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  62%|                                             | 33/53 [00:11<00:07,  2.85it/s]\u001b[A\n",
      "Processing frames:  64%|                                          | 34/53 [00:11<00:06,  2.85it/s]\u001b[A\n",
      "Processing frames:  66%|                                        | 35/53 [00:12<00:06,  2.85it/s]\u001b[A\n",
      "Processing frames:  68%|                                      | 36/53 [00:12<00:05,  2.84it/s]\u001b[A\n",
      "Processing frames:  70%|                                    | 37/53 [00:13<00:05,  2.84it/s]\u001b[A\n",
      "Processing frames:  72%|                                 | 38/53 [00:13<00:05,  2.83it/s]\u001b[A\n",
      "Processing frames:  74%|                               | 39/53 [00:13<00:04,  2.83it/s]\u001b[A\n",
      "Processing frames:  75%|                             | 40/53 [00:14<00:04,  2.83it/s]\u001b[A\n",
      "Processing frames:  77%|                           | 41/53 [00:14<00:04,  2.84it/s]\u001b[A\n",
      "Processing frames:  79%|                        | 42/53 [00:14<00:03,  2.83it/s]\u001b[A\n",
      "Processing frames:  81%|                      | 43/53 [00:15<00:03,  2.80it/s]\u001b[A\n",
      "Processing frames:  83%|                    | 44/53 [00:15<00:03,  2.81it/s]\u001b[A\n",
      "Processing frames:  85%|                  | 45/53 [00:15<00:02,  2.81it/s]\u001b[A\n",
      "Processing frames:  87%|               | 46/53 [00:16<00:02,  2.81it/s]\u001b[A\n",
      "Processing frames:  89%|             | 47/53 [00:16<00:02,  2.80it/s]\u001b[A\n",
      "Processing frames:  91%|           | 48/53 [00:16<00:01,  2.80it/s]\u001b[A\n",
      "Processing frames:  92%|         | 49/53 [00:17<00:01,  2.80it/s]\u001b[A\n",
      "Processing frames:  94%|      | 50/53 [00:17<00:01,  2.79it/s]\u001b[A\n",
      "Processing frames:  96%|    | 51/53 [00:18<00:00,  2.79it/s]\u001b[A\n",
      "Processing frames:  98%|  | 52/53 [00:18<00:00,  2.79it/s]\u001b[A\n",
      "Processing frames: 100%|| 53/53 [00:18<00:00,  2.83it/s]\u001b[A\n",
      "Processing patches: 9it [03:29, 23.24s/it]\n"
     ]
    }
   ],
   "source": [
    "temp_results_dict = {}\n",
    "\n",
    "add_patch_index = True\n",
    "\n",
    "for patch_index, patch_coordinates in tqdm(enumerate(patches_coordinates), desc='Processing patches'):\n",
    "    \n",
    "    # cropping and segmenting input video based on patch_coordinates and temporal window  \n",
    "    cropped_video = segment_crop_video(video_path, \n",
    "                                      frame_index=starting_frame_index, \n",
    "                                      length=length_input, \n",
    "                                      crop=patch_coordinates)\n",
    "    \n",
    "    crop_height, crop_width = cropped_video[0].shape[:2]\n",
    "    \n",
    "    \n",
    "    prep_video = ava_preprocessing_cv2(cropped_video, cfg)\n",
    "    prep_height, prep_width = prep_video.shape[-2:]\n",
    "    \n",
    "    \n",
    "    prep_clips, center_frames = clip_constructor(prep_video, \n",
    "                                                 rate_sample=cfg.DATA.SAMPLING_RATE, \n",
    "                                                 num_frames=cfg.DATA.NUM_FRAMES)\n",
    "    \n",
    "    list_collated_batches = prepare_collated_batches(prep_clips, center_frames, cfg)\n",
    "    \n",
    "\n",
    "    for batch, center_frame_index in tqdm(zip(list_collated_batches, center_frames), \n",
    "                                          desc='Processing frames', \n",
    "                                          total=len(list_collated_batches)):\n",
    "        \n",
    "        # updating frame index based on starting_frame_index\n",
    "        cur_frame_index = center_frame_index + starting_frame_index\n",
    "        \n",
    "        # adding current frame index to result dict\n",
    "        if cur_frame_index not in temp_results_dict:\n",
    "            temp_results_dict[cur_frame_index] = []\n",
    "        \n",
    "        # passing batch to model\n",
    "        with torch.no_grad():\n",
    "            slow_video, fast_video, whwh, boxes, labels, metadata, idx = batch\n",
    "            clips_height, clips_width = slow_video.shape[-2:]\n",
    "            slow_video = slow_video.to(device)\n",
    "            if fast_video is not None:\n",
    "                fast_video = fast_video.to(device)\n",
    "            whwh = whwh.to(device)\n",
    "    \n",
    "            # INFERENCE\n",
    "            action_score_list, box_list, objectness_score_list = model(slow_video, fast_video, whwh, boxes, labels)\n",
    "            #print(slow_video.shape)\n",
    "        \n",
    "        # Removing batch dimension\n",
    "        if len(box_list) != 0:\n",
    "           \n",
    "            output_bbox = box_list[0]\n",
    "            output_action = action_score_list[0]\n",
    "            output_objectness = objectness_score_list[0]\n",
    "        \n",
    "            if output_bbox.shape[0] != 0:\n",
    "            \n",
    "                # denormalizing bboxes w.r.t. clips shape\n",
    "                output_bbox_inp = output_bbox.clone()\n",
    "\n",
    "                output_bbox_inp[:, 0] = output_bbox[:, 0] * clips_width\n",
    "                output_bbox_inp[:, 1] = output_bbox[:, 1] * clips_height\n",
    "                output_bbox_inp[:, 2] = output_bbox[:, 2] * clips_width\n",
    "                output_bbox_inp[:, 3] = output_bbox[:, 3] * clips_height\n",
    "    \n",
    "                # clipping bbonx coordinates with prep shape because clip shape is right/bottum padded version of prep shape.\n",
    "                output_bbox_prep = clip_boxes_tensor(output_bbox_inp, \n",
    "                                                     height=whwh[0,1], \n",
    "                                                     width = whwh[0,0])\n",
    "    \n",
    "                # Scaling bboxes from prep shape to crop shape\n",
    "                output_bbox_crop = map_bbox_from_prep_to_crop(output_bbox_prep, \n",
    "                                                              (crop_height, crop_width), \n",
    "                                                              (prep_height, prep_width))\n",
    "    \n",
    "                # mapping from crop to original frame\n",
    "                output_bbox_frame = map_bbox_from_crop_to_orig(output_bbox_crop , patch_coordinates[:2])\n",
    "                \n",
    "                # getting top_k action: scores and indices\n",
    "                top_values, top_indices = torch.topk(output_action, k=top_k, dim=1)\n",
    "    \n",
    "                output_objectness_np = np.reshape(output_objectness.cpu().numpy(), (-1, 1))\n",
    "                output_bbox_frame_np = output_bbox_frame.cpu().numpy()\n",
    "                \n",
    "                # shifting to ava dataset labeling\n",
    "                top_indices_np = top_indices.cpu().numpy() + 1\n",
    "                top_values_np = top_values.cpu().numpy()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                if add_patch_index:\n",
    "                    # adding patch index to result.\n",
    "                    patch_index_np = np.full((output_objectness_np.shape[0], 1), patch_index)\n",
    "                    agg_result = np.concatenate((output_objectness_np, \n",
    "                                                 output_bbox_frame_np, \n",
    "                                                 top_indices_np, \n",
    "                                                 top_values_np,\n",
    "                                                 patch_index_np), axis=1)\n",
    "                else:\n",
    "                    agg_result = np.concatenate((output_objectness_np, \n",
    "                                                 output_bbox_frame_np, \n",
    "                                                 top_indices_np, \n",
    "                                                 top_values_np), axis=1)\n",
    "                \n",
    "                \n",
    "                temp_results_dict[cur_frame_index].append(agg_result)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee7e4a",
   "metadata": {},
   "source": [
    "slow_video.shape, fast_video, whwh, boxes, labels\n",
    "\n",
    "\n",
    "(torch.Size([1, 3, 16, 256, 320]),\n",
    " None,\n",
    " tensor([[320., 256., 320., 256.]], device='cuda:0'),\n",
    " (None,),\n",
    " (None,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62751cbd",
   "metadata": {},
   "source": [
    "#### creating dict with keys equal to actual frames and values as np.array of shape Nx16 or Nx15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d7b1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dict = concatenate_results(temp_results_dict, top_k=top_k, patch_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb81f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = all_results_dict[94][:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e2b9816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d79d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nms_action_detection(detections, agnostic=True, type_score='obj_score', nms_method='IOU', iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression (NMS) on action detection results.\n",
    "\n",
    "    Parameters:\n",
    "        detections (numpy.ndarray): Array of shape Nx15 where N is the number of detected objects.\n",
    "                                    Each row contains [obj_score, x1, y1, x2, y2, action_id1, action_id2, ...,\n",
    "                                    action_id5, action_score1, action_score2, ..., action_score5].\n",
    "        agnostic (bool): If True, NMS will be applied to all detections together.\n",
    "                         If False, NMS will be applied separately for each class.\n",
    "        type_score (str): Type of score to be used for sorting: 'obj_score', 'action_score', or 'joint'.\n",
    "        nms_method (str): NMS method to be used: 'IOU' or 'IOS'.\n",
    "        iou_threshold (float): Threshold for IOU or IOS.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered detections after applying NMS.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort detections based on score\n",
    "    if type_score == 'obj_score':\n",
    "        score_index = 0\n",
    "    elif type_score == 'action_score':\n",
    "        score_index = slice(-5, None)  # Selecting action score columns\n",
    "    elif type_score == 'joint':\n",
    "        score_index = 0 if agnostic else slice(-5, None)\n",
    "        detections[:, score_index] *= detections[:, -5:].max(axis=1)  # Using the maximum action score\n",
    "\n",
    "    sorted_indices = np.argsort(detections[:, score_index])[::-1]\n",
    "    detections = detections[sorted_indices]\n",
    "\n",
    "    # Perform NMS\n",
    "    def compute_iou(box1, box2):\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "        if nms_method == 'IOU':\n",
    "            union = (box1[2] - box1[0]) * (box1[3] - box1[1]) + \\\n",
    "                    (box2[2] - box2[0]) * (box2[3] - box2[1]) - intersection\n",
    "        elif nms_method == 'IOS':\n",
    "            min_area = min((box1[2] - box1[0]) * (box1[3] - box1[1]),\n",
    "                           (box2[2] - box2[0]) * (box2[3] - box2[1]))\n",
    "            union = min_area\n",
    "\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        return iou\n",
    "\n",
    "    keep_indices = []\n",
    "    while len(detections) > 0:\n",
    "        keep_indices.append(detections[0])\n",
    "\n",
    "        iou_scores = np.array([compute_iou(detections[0, 1:5], detections[i, 1:5]) for i in range(1, len(detections))])\n",
    "\n",
    "        if agnostic:\n",
    "            mask = iou_scores <= iou_threshold\n",
    "        else:\n",
    "            ref_actions = np.repeat(detections[0, 5:10][np.newaxis, :], len(detections)-1, axis=0)\n",
    "            mask = np.logical_or(iou_scores <= iou_threshold, detections[1:, 5:10] != ref_actions)\n",
    "\n",
    "        detections = detections[1:][mask]\n",
    "\n",
    "    return np.array(keep_indices)\n",
    "\n",
    "# Example usage:\n",
    "# detections = np.array([[0.9, 100, 100, 200, 200, 0, 0, 0, 0, 0, 0.8, 0.7, 0.6, 0.5, 0.4],\n",
    "#                        [0.8, 150, 150, 250, 250, 1, 1, 1, 1, 1, 0.7, 0.6, 0.5, 0.4, 0.3],\n",
    "#                        [0.7, 120, 120, 220, 220, 2, 2, 2, 2, 2, 0.6, 0.5, 0.4, 0.3, 0.2]])\n",
    "# filtered_detections = nms_action_detection(detections, agnostic=True, type_score='action_score', nms_method='IOU')\n",
    "# print(filtered_detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f71b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_action_detection_per_cat(detections, type_score='obj_score', nms_method='IOU', iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression (NMS) on action detection results.\n",
    "\n",
    "    Parameters:\n",
    "        detections (numpy.ndarray): Array of shape Nx15 where N is the number of detected objects.\n",
    "                                    Each row contains [obj_score, x1, y1, x2, y2, action_id1, action_id2, ...,\n",
    "                                    action_id5, action_score1, action_score2, ..., action_score5].\n",
    "        agnostic (bool): If True, NMS will be applied to all detections together.\n",
    "                         If False, NMS will be applied separately for each action ID.\n",
    "        type_score (str): Type of score to be used for sorting: 'obj_score', 'action_score', or 'joint'.\n",
    "        nms_method (str): NMS method to be used: 'IOU' or 'IOS'.\n",
    "        iou_threshold (float): Threshold for IOU or IOS.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered detections after applying NMS.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort detections based on score\n",
    "    if type_score == 'obj_score':\n",
    "        score_index = 0\n",
    "    elif type_score == 'action_score':\n",
    "        score_index = slice(-5, None)  # Selecting action score columns\n",
    "    elif type_score == 'joint':\n",
    "        score_index = 0 if agnostic else slice(-5, None)\n",
    "        detections[:, score_index] *= detections[:, -5:].max(axis=1)  # Using the maximum action score\n",
    "\n",
    "    sorted_indices = np.argsort(detections[:, score_index])[::-1]\n",
    "    detections = detections[sorted_indices]\n",
    "    \n",
    "    # Perform NMS\n",
    "    def compute_iou(box1, box2):\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "        if nms_method == 'IOU':\n",
    "            union = (box1[2] - box1[0]) * (box1[3] - box1[1]) + \\\n",
    "                    (box2[2] - box2[0]) * (box2[3] - box2[1]) - intersection\n",
    "        elif nms_method == 'IOS':\n",
    "            min_area = min((box1[2] - box1[0]) * (box1[3] - box1[1]),\n",
    "                           (box2[2] - box2[0]) * (box2[3] - box2[1]))\n",
    "            union = min_area\n",
    "\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        return iou\n",
    "\n",
    "\n",
    "    unique_action_ids = np.unique(detections[:, 5])\n",
    "    \n",
    "    \n",
    "\n",
    "    keep_indices = []\n",
    "    for action_id in unique_action_ids:\n",
    "        action_mask = detections[:, 5] == action_id\n",
    "        action_detections = detections[action_mask]\n",
    "\n",
    "        while len(action_detections) > 0:\n",
    "            keep_indices.append(action_detections[0])\n",
    "\n",
    "            iou_scores = np.array([compute_iou(action_detections[0, 1:5], action_detections[i, 1:5]) for i in range(1, len(action_detections))])\n",
    "\n",
    "            mask = iou_scores <= iou_threshold\n",
    "            action_detections = action_detections[1:][mask]\n",
    "\n",
    "    return np.array(keep_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7f385b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_id = nms_action_detection_per_cat(ss, nms_method=\"IOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "96e2a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nms_to_dict(detections_dict, agnostic=True, type_score='obj_score', nms_method='IOS', iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply NMS post-processing on a dictionary of action detections.\n",
    "\n",
    "    Parameters:\n",
    "        detections_dict (dict): Dictionary where keys are frame indices and values are arrays of action detections.\n",
    "        agnostic (bool): If True, NMS will be applied to all detections together.\n",
    "                         If False, NMS will be applied separately for each action ID.\n",
    "        type_score (str): Type of score to be used for sorting: 'obj_score', 'action_score', or 'joint'.\n",
    "        nms_method (str): NMS method to be used: 'IOU' or 'IOS'.\n",
    "        iou_threshold (float): Threshold for IOU or IOS.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with NMS-applied detections.\n",
    "    \"\"\"\n",
    "\n",
    "    nms_applied_dict = {}\n",
    "    for frame, detections in detections_dict.items():\n",
    "        nms_applied_detections = nms_action_detection(detections, agnostic=agnostic, type_score=type_score, nms_method=nms_method, iou_threshold=iou_threshold)\n",
    "        nms_applied_dict[frame] = nms_applied_detections\n",
    "\n",
    "    return nms_applied_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4db3c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.94045496e-01, 1.34600000e+03, 6.55000000e+02, 1.45200000e+03,\n",
       "       9.19000000e+02, 1.40000000e+01, 1.70000000e+01, 8.00000000e+01,\n",
       "       7.90000000e+01, 7.40000000e+01, 9.91903603e-01, 5.57146549e-01,\n",
       "       2.39134595e-01, 8.62589404e-02, 6.32744804e-02, 4.00000000e+00])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss[20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e1529c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_all_results_dict = apply_nms_to_dict(all_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194928a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc8f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efc2270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_utils.visualization import action_visualizer_frame_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62172eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4f61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344cd6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a82ac790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_visualizer_frame_index(all_results_dict, \n",
    "                                  video_path, \n",
    "                                  label_dict, \n",
    "                                  output_directory,\n",
    "                                  top_k=5,\n",
    "                                  interesting_actions_indices = [5, 64, 71, 75],\n",
    "                                  interesting_actions_labels = {5:'fall', 64:'fight', 71:'kick', 76:'push'},\n",
    "                                  action_colors = {5: (0, 0, 210), # Blue\n",
    "                                                   64 : (255, 0, 0), # Red\n",
    "                                                   71: (255, 165, 0), # Purple\n",
    "                                                   75: (128, 0, 128)}, # Orange\n",
    "                                  action_thrshold = {5: 0.3, 64: 0.2, 71: 0.3, 76: 0.3},\n",
    "                                  other_actions_color = (0, 255, 0), # green\n",
    "                                  all_actions=False, \n",
    "                                  long_text_show=False,\n",
    "                                  add_patch_index=False,\n",
    "                                  vis_patch_lines=False,\n",
    "                                  mode='pic'):\n",
    "    \n",
    "    if mode in ['gif', 'movie']:\n",
    "        vis_frames_list = []\n",
    "    \n",
    "    \n",
    "    with tqdm(total=len(all_results_dict)) as pbar:\n",
    "        \n",
    "        for cur_frame, results_frame in all_results_dict.items():\n",
    "            \n",
    "            \n",
    "            # checking results_frame type and converting it into np\n",
    "            if isinstance(results_frame, list):\n",
    "                results_frame_np = np.concatenate(results_frame, axis=0)\n",
    "            elif isinstance(results_frame, np.ndarray):\n",
    "                results_frame_np = results_frame\n",
    "            else:\n",
    "                raise ValueError(\"Input must be a list or a numpy array\")\n",
    "                \n",
    "            \n",
    "            # getting the frame\n",
    "            frame = get_frame_from_video(video_path, int(cur_frame))\n",
    "            vis_frame = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # no detection on frame\n",
    "            if results_frame_np.shape[0] == 0:\n",
    "                if mode in ['pic', 'gif']:\n",
    "                    continue\n",
    "                else:\n",
    "                    vis_frames_list.append(vis_frame)\n",
    "                    continue\n",
    "            \n",
    "            # extracing object_score, bboxes, top action indices and score, and patch_index (if exists)\n",
    "            obj_scores_frame = results_frame_np[:, :1]\n",
    "            bboxes_frame = results_frame_np[:, 1:5]\n",
    "            top_indices_frame = results_frame_np[:, 5:5+top_k]\n",
    "            top_values_frame = results_frame_np[:, 5+top_k:5+2*top_k]\n",
    "            \n",
    "            if results_frame_np.shape[-1] != 5+2*top_k:\n",
    "                patch_indices_frame = results_frame_np[:, -1].astype(int)\n",
    "            else:\n",
    "                add_patch_index = False\n",
    "                \n",
    "            \n",
    "            # id of interesting actor starting from 0\n",
    "            id_actor = 0\n",
    "            \n",
    "            # if frame contains any interesting action\n",
    "            interesting_frame = False\n",
    "            \n",
    "            # looping over each actor\n",
    "            for object_score, bbox, top_action_indices, top_action_scores, patch_index in zip(obj_scores_frame, bboxes_frame,\n",
    "                                                                                              top_indices_frame, top_values_frame, patch_indices_frame):\n",
    "                x1, y1, x2, y2 = bbox.astype(int)\n",
    "                \n",
    "                # if actor is interesting\n",
    "                interesting_actor = False\n",
    "                for ind_act, act in enumerate(top_action_indices):\n",
    "                    if act in interesting_actions_indices and top_action_scores[ind_act] > action_thrshold[int(act)]:\n",
    "                        interesting_actor = True\n",
    "                        interesting_frame = True\n",
    "                        bbox_action_color = action_colors[int(act)]\n",
    "                        main_interesting_act = int(act) # the main interesting action of actor\n",
    "                        main_interesting_score = top_action_scores[ind_act]\n",
    "                        break\n",
    "                \n",
    "                # visualization for interesting actor\n",
    "                if interesting_actor:\n",
    "                    \n",
    "                    \n",
    "                    # plot the bbox of interesting actor \n",
    "                    cv2.rectangle(vis_frame, (x1, y1), (x2, y2), bbox_action_color, 2)\n",
    "                    \n",
    "                        # text on top of bbox of interesting actor\n",
    "                    if add_patch_index:\n",
    "                        id_text = '{}_{}_{}_{}'.format(id_actor, \n",
    "                                                       interesting_actions_labels[main_interesting_act], \n",
    "                                                       np.round(main_interesting_score, 2), \n",
    "                                                       patch_index)\n",
    "                    else:\n",
    "                        id_text = '{}_{}_{}'.format(id_actor, \n",
    "                                                    interesting_actions_labels[main_interesting_act], \n",
    "                                                    np.round(main_interesting_score, 2))\n",
    "                    id_actor += 1\n",
    "                    \n",
    "                    \n",
    "                    cv2.putText(vis_frame, id_text, (x1+10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, bbox_action_color, 2)\n",
    "            \n",
    "                     # add text containing all actions of interesting actor\n",
    "                    if long_text_show:\n",
    "                        long_text = '{}-{}:'.format(id_actor, np.round(object_score, 2)) # add ID of actor for frame visualization\n",
    "                        # add act and their scores on long text\n",
    "                        for act, score in zip(top_action_indices, top_action_scores):\n",
    "                            long_text += '{}_{}-'.format(label_dict[act].replace('(', '').replace(')', '').split('/')[0], \n",
    "                                                 (np.round(score, 2)))\n",
    "                        cv2.putText(vis_frame, long_text[:-1], (20, 100 + 20 * id_actor), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                                bbox_action_color, 2)\n",
    "                \n",
    "                # visualization for other actors\n",
    "                else:\n",
    "                    if all_actions:\n",
    "                        # plot bbox of other actors   \n",
    "                        cv2.rectangle(vis_frame, (x1, y1), (x2, y2), other_actions_color, 2)\n",
    "                        # add text\n",
    "                        if add_patch_index:\n",
    "                            id_text = '{}'.format(patch_index)\n",
    "                            cv2.putText(vis_frame, id_text, (x1+10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "                                        other_actions_color, 2)\n",
    "       \n",
    "            if interesting_frame:\n",
    "                cv2.putText(vis_frame, str(cur_frame), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 4)\n",
    "\n",
    "\n",
    "            if vis_patch_lines:\n",
    "                cv2.rectangle(vis_frame, (crop_box[0], crop_box[1]), (crop_box[2], crop_box[3]), (255, 255, 0), 1)\n",
    "               \n",
    "        \n",
    "            if mode in ['gif', 'movie']:\n",
    "                vis_frames_list.append(vis_frame)\n",
    "            else:\n",
    "                if True:\n",
    "                    frame_path = os.path.join(output_directory_frames, f\"frame_{cur_frame}.jpg\")\n",
    "                    sucess = cv2.imwrite(frame_path, cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        \n",
    "    # Update tqdm progress bar\n",
    "    pbar.update(1)\n",
    "        \n",
    "    if mode in ['gif', 'movie']:\n",
    "        return vis_frames_list\n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0f8be983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/53 [00:25<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "output_directory_frames = os.path.join(output_directory, 'frames')\n",
    "os.makedirs(output_directory_frames, exist_ok=True)\n",
    "\n",
    "ou = action_visualizer_frame_index(post_all_results_dict, \n",
    "                              video_path, \n",
    "                              label_dict, \n",
    "                              output_directory_frames,\n",
    "                              all_actions=True,\n",
    "                              long_text_show=False,\n",
    "                                   mode='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "497d87f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "96b7b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output.mp4.\n",
      "Moviepy - Writing video output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def create_video_from_frames(frames, output_path, fps=20):\n",
    "    \"\"\"\n",
    "    Create a video from a list of frames using moviepy.\n",
    "\n",
    "    Parameters:\n",
    "        frames (list): List of frames (each frame is a numpy array or an image file path).\n",
    "        output_path (str): Path to save the output video file (including file extension, e.g., 'output.mp4').\n",
    "        fps (int, optional): Frames per second for the output video (default is 30).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create video clip from frames\n",
    "    clip = ImageSequenceClip(frames, fps=fps)\n",
    "\n",
    "    # Write video file\n",
    "    clip.write_videofile(output_path)\n",
    "\n",
    "create_video_from_frames(ou, 'output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_actions_indices = [5, 64, 71, 75]\n",
    "interesting_actions_labels = {5:'fall', 64:'fight', 71:'kick', 75:'push'}\n",
    "\n",
    "vis_frames_list = []\n",
    "vis_iteresting_frames_list = []\n",
    "\n",
    "\n",
    "output_directory_frames = os.path.join(output_directory, 'frames')\n",
    "os.makedirs(output_directory_frames, exist_ok=True)\n",
    "\n",
    "\n",
    "from my_utils.video_processing import get_frame_from_video\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize tqdm with the length of all_results_dict\n",
    "with tqdm(total=len(all_results_dict)) as pbar:\n",
    "    for cur_frame, results_frame in all_results_dict.items():\n",
    "        #results_frame_np = np.concatenate(results_frame, axis=0)\n",
    "        results_frame_np = results_frame\n",
    "        obj_scores_frame = results_frame_np[:, :1]\n",
    "        bboxes_frame = results_frame_np[:, 1:5]\n",
    "        top_indices_frame = results_frame_np[:, 5:10]\n",
    "        top_values_frame = results_frame_np[:, 10:]\n",
    "        \n",
    "        frame = get_frame_from_video(video_path, cur_frame)\n",
    "        \n",
    "        vis_frame = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2RGB)\n",
    "        vis_inter_frame = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        id_actor = 0\n",
    "        interesting_frame = False\n",
    "        \n",
    "        for object_score, bbox, top_action_indices, top_action_scores in zip(obj_scores_frame, bboxes_frame, top_indices_frame, top_values_frame):\n",
    "            x1, y1, x2, y2 = bbox.astype(int)\n",
    "            small_text = ''\n",
    "            \n",
    "            interesting_actor = False\n",
    "            for ind, act in enumerate(top_action_indices):\n",
    "                if act in interesting_actions_indices:\n",
    "                    interesting_actor = True\n",
    "                    interesting_frame = True\n",
    "                    \n",
    "                    small_text += '{}_{}'.format(interesting_actions_labels[act], \n",
    "                                                 np.round(top_action_scores[ind], 2))\n",
    "            if interesting_actor:\n",
    "                long_text = '{}-{}:'.format(id_actor, np.round(object_score, 2)) # add ID of actor for frame visualization\n",
    "                for act, score in zip(top_action_indices, top_action_scores):\n",
    "                    long_text += '{}_{}-'.format(label_dict[act].replace('(', '').replace(')', '').split('/')[0], \n",
    "                                                 (np.round(score, 2)))\n",
    "                    \n",
    "            \n",
    "            if interesting_actor:\n",
    "                # plot the bbox of interesting actor and adding interesting action\n",
    "                cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(vis_frame, small_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                \n",
    "                cv2.rectangle(vis_inter_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                #id_text = '{}:{}'.format(id_actor, small_text)\n",
    "                id_text = '{}'.format(id_actor)\n",
    "                id_actor += 1\n",
    "    \n",
    "                cv2.putText(vis_inter_frame, id_text, (x1+10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 0, 0), 2)\n",
    "                cv2.putText(vis_inter_frame, str(cur_frame), (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 4)\n",
    "                \n",
    "                # add text containing all actions of interesting actor\n",
    "                if True:\n",
    "                    cv2.putText(vis_inter_frame, \n",
    "                                long_text[:-1], \n",
    "                                (20, 100 + 20 * id_actor), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                # plot the bbox of other actors\n",
    "                cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.rectangle(vis_inter_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "        \n",
    "        #cv2.rectangle(vis_frame, (crop_box[0], crop_box[1]), (crop_box[2], crop_box[3]), (255, 255, 0), 2)\n",
    "        #cv2.rectangle(vis_inter_frame, (crop_box[0], crop_box[1]), (crop_box[2], crop_box[3]), (255, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        vis_frames_list.append(vis_frame)\n",
    "        if interesting_frame:\n",
    "            vis_iteresting_frames_list.append(vis_inter_frame)\n",
    "            frame_path = os.path.join(output_directory_frames, f\"frame_{cur_frame}.jpg\")\n",
    "            cv2.imwrite(frame_path, cv2.cvtColor(vis_inter_frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Update tqdm progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd434be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "\n",
    "def create_video_from_frames(frames, output_path, fps=30):\n",
    "    \"\"\"\n",
    "    Create a video from a list of frames using moviepy.\n",
    "\n",
    "    Parameters:\n",
    "        frames (list): List of frames (each frame is a numpy array or an image file path).\n",
    "        output_path (str): Path to save the output video file (including file extension, e.g., 'output.mp4').\n",
    "        fps (int, optional): Frames per second for the output video (default is 30).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create video clip from frames\n",
    "    clip = ImageSequenceClip(frames, fps=fps)\n",
    "\n",
    "    # Write video file\n",
    "    clip.write_videofile(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433dc75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dict[124].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c623425",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "843f956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import json_tricks as json_tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7fc5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_json_path = os.path.join(output_directory, 'exp.json')\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open(exp_json_path, 'w') as f:\n",
    "    json.dump(exp_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bdd95057",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json_path = os.path.join(output_directory, 'result.json')\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "with open(result_json_path, 'w') as f:\n",
    "    json_tricks.dump(temp_results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "884655f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_results_dict[74][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd9be0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
