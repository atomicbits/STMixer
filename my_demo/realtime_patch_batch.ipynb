{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6966f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96ff5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import moviepy \n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from alphaction.config import cfg\n",
    "from alphaction.modeling.detector import build_detection_model\n",
    "from alphaction.utils.checkpoint import ActionCheckpointer\n",
    "from alphaction.utils.comm import get_world_size\n",
    "\n",
    "\n",
    "from my_utils.gen_utils import create_experiment_folder\n",
    "from my_utils.video_processing import get_video_info, get_frame_from_video\n",
    "from my_utils.slicing import get_slice_bboxes, generate_sliding_window_gif\n",
    "\n",
    "from my_utils.video_processing import segment_crop_video\n",
    "from my_utils.my_ava_preprocessing import ava_preprocessing_cv2, clip_constructor, prepare_collated_batches, prepare_collated_batches_v2\n",
    "from my_utils.ava_postprocessing import concatenate_results\n",
    "from my_utils.visualization import action_visualizer_frame_index\n",
    "\n",
    "from my_utils.gen_utils import parse_label_file\n",
    "\n",
    "from my_utils.ava_postprocessing import clip_boxes_tensor, map_bbox_from_prep_to_crop, map_bbox_from_crop_to_orig\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3222f3",
   "metadata": {},
   "source": [
    "### 1. CONFIG\n",
    "#### 1.1 Main Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba83991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'VMAEv2',\n",
       " 'model_params': {'person_threshold': 0.3, 'sampling_rate': 4},\n",
       " 'orig_post_processing': {'top_k': 5},\n",
       " 'aggregation': {'method': {}, 'params': {}},\n",
       " 'video_path': '../input_dir/Fighting_14.mp4',\n",
       " 'slicing_params': {'slice_height': 600,\n",
       "  'slice_width': 800,\n",
       "  'overlap_ratio': 0},\n",
       " 'video_params': {'st_frame_index': 900, 'length_input': 300}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'VMAEv2'\n",
    "\n",
    "\n",
    "person_threshold = 0.3 # confidence threshold on actor. 0.6 is the defualt\n",
    "sampling_rate = 4 # sampling rate: 4 is the defualt\n",
    "top_k = 5 # number of actions per person\n",
    "video_path = '../input_dir/Fighting_14.mp4'\n",
    "\n",
    "slice_height = 600\n",
    "slice_width = 800\n",
    "overlap_ratio = 0\n",
    "\n",
    "starting_frame_index = 900\n",
    "length_input = 300\n",
    "\n",
    "exp_dict = {'model_name': model_name,\n",
    "            'model_params': {'person_threshold': person_threshold, \n",
    "                             'sampling_rate': sampling_rate},\n",
    "            'orig_post_processing':{'top_k': top_k},\n",
    "            'aggregation': {'method': {}, \n",
    "                            'params': {}},\n",
    "            'video_path': video_path,\n",
    "            'slicing_params': {'slice_height': slice_height, \n",
    "                               'slice_width': slice_width, \n",
    "                               'overlap_ratio':overlap_ratio},\n",
    "            'video_params': {'st_frame_index': starting_frame_index, \n",
    "                             'length_input':length_input\n",
    "                             }\n",
    "           }\n",
    "\n",
    "exp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656995dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = os.path.basename(video_path).split('.')[0]\n",
    "#output_directory = f'../output_dir/{video_name}/{model_name}/patch_batch/' \n",
    "#output_directory = create_experiment_folder(output_directory, 'exp')\n",
    "#output_directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265cbefc",
   "metadata": {},
   "source": [
    "#### 1.2 Model Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87183304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg_create(model_name, person_threshold, sampling_rate, test_videos_batch=1, num_workers=1):\n",
    "    \n",
    "    if model_name == 'VMAEv2':\n",
    "        config_file = '../config_files/VMAEv2-ViTB-16x4.yaml'\n",
    "        \n",
    "    if model_name == 'VMAE':\n",
    "        config_file = '../config_files/VMAE-ViTB-16x4.yaml'\n",
    "        \n",
    "    cfg.merge_from_file(config_file)\n",
    "    \n",
    "    # change model weight path\n",
    "    if model_name == 'VMAEv2':\n",
    "        cfg.merge_from_list([\"MODEL.WEIGHT\", \"../checkpoints/VMAEv2_ViTB_16x4.pth\"])\n",
    "    if model_name == 'VMAE':\n",
    "        cfg.merge_from_list([\"MODEL.WEIGHT\", \"../checkpoints/VMAE_ViTB_16x4.pth\"])\n",
    "\n",
    "    # change output dir\n",
    "    cfg.merge_from_list([\"OUTPUT_DIR\", \"../output_dir/\"])\n",
    "\n",
    "    # change person threshold\n",
    "    cfg.merge_from_list([\"MODEL.STM.PERSON_THRESHOLD\", person_threshold])\n",
    "\n",
    "    # change sampling rate\n",
    "    cfg.merge_from_list([\"DATA.SAMPLING_RATE\", sampling_rate])\n",
    "\n",
    "    # change path for data_dir\n",
    "    cfg.merge_from_list([\"DATA.PATH_TO_DATA_DIR\", \"/work/ava\"])\n",
    "\n",
    "    # folder name of annotations\n",
    "    cfg.merge_from_list([\"AVA.ANNOTATION_DIR\", \"annotations/\"])\n",
    "\n",
    "    # file name of  frame_lists\n",
    "    cfg.merge_from_list([\"AVA.TRAIN_LISTS\", ['sample.csv']])\n",
    "    cfg.merge_from_list([\"AVA.TEST_LISTS\", ['sample.csv']])\n",
    "\n",
    "    # file name of predicted_bboxes\n",
    "    cfg.merge_from_list([\"AVA.TRAIN_GT_BOX_LISTS\", ['ava_sample_predicted_boxes.csv']])\n",
    "    cfg.merge_from_list([\"AVA.TEST_GT_BOX_LISTS\", ['ava_sample_predicted_boxes.csv']])\n",
    "\n",
    "    # file name of exlusions\n",
    "    cfg.merge_from_list([\"AVA.EXCLUSION_FILE\", 'ava_sample_train_excluded_timestamps_v2.2.csv'])\n",
    "\n",
    "    # number of batches in test scenario\n",
    "    cfg.merge_from_list([\"TEST.VIDEOS_PER_BATCH\", test_videos_batch])\n",
    "\n",
    "    # number of workers\n",
    "    cfg.merge_from_list([\"DATALOADER.NUM_WORKERS\", num_workers])\n",
    "    \n",
    "    \n",
    "    return cfg\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4754c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = cfg_create(model_name, person_threshold, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00476179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_detection_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6187164d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.DATALOADER.SIZE_DIVISIBILITY:  32\n",
      "cfg.DATA.SAMPLING_RATE:  4\n",
      "cfg.DATA.NUM_FRAMES:  16\n",
      "self_seq_len:  64\n",
      "cfg.MODEL.STM.ACTION_CLASSES:  80\n",
      "Augmentation params:  [0.45, 0.45, 0.45] [0.225, 0.225, 0.225] False\n",
      "scale and flip params [256] 1333 False\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    # The shape of model input should be divisible into this. Otherwise, padding 0 to left and bottum. \n",
    "    print(\"cfg.DATALOADER.SIZE_DIVISIBILITY: \", cfg.DATALOADER.SIZE_DIVISIBILITY)\n",
    "    \n",
    "    # Sampling rate in constructing the clips.\n",
    "    self_sample_rate =  cfg.DATA.SAMPLING_RATE\n",
    "    print(\"cfg.DATA.SAMPLING_RATE: \", cfg.DATA.SAMPLING_RATE)\n",
    "    \n",
    "    # Length of clip\n",
    "    self_video_length = cfg.DATA.NUM_FRAMES\n",
    "    print(\"cfg.DATA.NUM_FRAMES: \", cfg.DATA.NUM_FRAMES)\n",
    "    \n",
    "    # Length of sequence frames from which a clip is constructed.\n",
    "    self_seq_len = self_video_length * self_sample_rate\n",
    "    print(\"self_seq_len: \", self_seq_len)\n",
    "    \n",
    "    self_num_classes = cfg.MODEL.STM.ACTION_CLASSES\n",
    "    print(\"cfg.MODEL.STM.ACTION_CLASSES: \", self_num_classes)\n",
    "    \n",
    "    # Augmentation params.\n",
    "    self_data_mean = cfg.DATA.MEAN\n",
    "    self_data_std = cfg.DATA.STD\n",
    "    self_use_bgr = cfg.AVA.BGR\n",
    "    print(\"Augmentation params: \", self_data_mean, self_data_std, self_use_bgr)\n",
    "    \n",
    "    self_jitter_min_scale = cfg.DATA.TEST_MIN_SCALES\n",
    "    self_jitter_max_scale = cfg.DATA.TEST_MAX_SCALE\n",
    "    self_test_force_flip = cfg.AVA.TEST_FORCE_FLIP\n",
    "\n",
    "    print(\"scale and flip params\", self_jitter_min_scale, self_jitter_max_scale, self_test_force_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "770e0c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "seq_len = cfg.DATA.NUM_FRAMES * cfg.DATA.SAMPLING_RATE\n",
    "print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9b339d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STMDetector(\n",
       "  (backbone): ViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0181818176060915)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.036363635212183)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05454545468091965)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.072727270424366)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09090908616781235)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10909091681241989)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12727272510528564)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1454545557498932)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16363637149333954)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1818181872367859)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000000298023224)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose3d(384, 192, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (4): Conv3d(192, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (5): LayerNorm()\n",
       "      (6): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): Conv3d(384, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (1): LayerNorm()\n",
       "      (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (stm_head): STMDecoder(\n",
       "    (init_spatial_queries): Embedding(100, 256)\n",
       "    (init_temporal_queries): Embedding(100, 256)\n",
       "    (decoder_stages): ModuleList(\n",
       "      (0): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (1): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (2): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (3): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (4): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (5): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): SetCriterion(\n",
       "      (matcher): HungarianMatcher()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec664a1",
   "metadata": {},
   "source": [
    "### 5. loading weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c36d27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output_dir/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = cfg.OUTPUT_DIR\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe6cd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ActionCheckpointer(cfg, model, save_dir=output_dir)\n",
    "checkpointer.load(cfg.MODEL.WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3054e5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d68c498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_active = cfg.MODEL.STM.MEM_ACTIVE\n",
    "mem_active  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00cf88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6070b453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_devices = get_world_size()\n",
    "num_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffbb96ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STMDetector(\n",
       "  (backbone): ViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0181818176060915)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.036363635212183)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05454545468091965)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.072727270424366)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09090908616781235)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10909091681241989)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12727272510528564)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1454545557498932)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16363637149333954)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1818181872367859)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000000298023224)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (lateral_convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose3d(384, 192, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (4): Conv3d(192, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (5): LayerNorm()\n",
       "      (6): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose3d(768, 384, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "      (1): Conv3d(384, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (1): LayerNorm()\n",
       "      (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (2): LayerNorm()\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (stm_head): STMDecoder(\n",
       "    (init_spatial_queries): Embedding(100, 256)\n",
       "    (init_temporal_queries): Embedding(100, 256)\n",
       "    (decoder_stages): ModuleList(\n",
       "      (0): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (1): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (2): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (3): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (4): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "      (5): AMStage(\n",
       "        (attention_s): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_s): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_t): MultiheadAttention(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (attention_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn_t): FFN(\n",
       "          (activate): ReLU(inplace=True)\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout_layer): Identity()\n",
       "        )\n",
       "        (ffn_norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (samplingmixing): AdaptiveSTSamplingMixing(\n",
       "          (offset_generator): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          )\n",
       "          (norm_s): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_t): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (adaptive_mixing_s): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32768, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=32768, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (adaptive_mixing_t): AdaptiveMixing(\n",
       "            (parameter_generator): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=17408, bias=True)\n",
       "            )\n",
       "            (out_proj): Linear(in_features=8192, out_features=256, bias=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (human_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (human_fc_cls): Linear(in_features=256, out_features=2, bias=True)\n",
       "        (reg_fcs): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_reg): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (action_cls_fcs): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (fc_action): Linear(in_features=512, out_features=80, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): SetCriterion(\n",
       "      (matcher): HungarianMatcher()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b3628",
   "metadata": {},
   "source": [
    "### 3. VIDEO Info and Slicing Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10875a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = get_video_info(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "344b1e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame_count': 1525,\n",
       " 'frame_rate': 24.353,\n",
       " 'width': 1920,\n",
       " 'height': 1080,\n",
       " 'fps': 24.353}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5d0e529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'VMAEv2',\n",
       " 'model_params': {'person_threshold': 0.3, 'sampling_rate': 4},\n",
       " 'orig_post_processing': {'top_k': 5},\n",
       " 'aggregation': {'method': {}, 'params': {}},\n",
       " 'video_path': '../input_dir/Fighting_14.mp4',\n",
       " 'slicing_params': {'slice_height': 600,\n",
       "  'slice_width': 800,\n",
       "  'overlap_ratio': 0},\n",
       " 'video_params': {'st_frame_index': 900,\n",
       "  'length_input': 300,\n",
       "  'frame_count': 1525,\n",
       "  'frame_rate': 24.353,\n",
       "  'width': 1920,\n",
       "  'height': 1080,\n",
       "  'fps': 24.353}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dict['video_params'].update(video_info)\n",
    "exp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a797bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_height = video_info['height']\n",
    "frame_width = video_info['width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "420b041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_coordinates = get_slice_bboxes(frame_height, frame_width, slice_height, slice_width, False, overlap_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63e6e784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fda0e5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 800, 600],\n",
       " [800, 0, 1600, 600],\n",
       " [1120, 0, 1920, 600],\n",
       " [0, 480, 800, 1080],\n",
       " [800, 480, 1600, 1080],\n",
       " [1120, 480, 1920, 1080]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebc600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame, patches_coordinates):\n",
    "    frame_slices = [frame[y1:y2, x1:x2] for x1, y1, x2, y2 in patches_coordinates]\n",
    "    return frame_slices\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf94c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bda37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51a15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a90a2d",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0665f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n",
      "torch.Size([3, 6, 256, 341])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;66;03m# INFERENCE\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         action_score_list, box_list, objectness_score_list \u001b[38;5;241m=\u001b[39m model(slow_video, fast_video, whwh, boxes, labels)\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mfeatures\u001b[49m))\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Add frame to buffer\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m#buffer.append(frame)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Release video capture\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize buffer\n",
    "buffer = []\n",
    "\n",
    "frames_tensor_list = []\n",
    "\n",
    "\n",
    "# Read frames from video\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_slices = crop_frame(frame, patches_coordinates)\n",
    "    frames_prep = ava_preprocessing_cv2(frame_slices, cfg) # torch.Size([3, n_patches, 256, 455])\n",
    "    \n",
    "    print(frames_prep.shape)\n",
    "    frames_tensor_list.append(frames_prep.permute(1, 0, 2, 3))\n",
    "    \n",
    "    if len(frames_tensor_list) == 48:\n",
    "        video_tensor = torch.stack(frames_tensor_list).permute(1, 2, 0, 3, 4)\n",
    "        clip_tensor = video_tensor[:,:, 0:-1:3,:,:]\n",
    "        cente_frame_id = [24 for _ in range(10)]\n",
    "        list_collated_batches = prepare_collated_batches_v2(clip_tensor, cfg)\n",
    "        \n",
    "        slow_video = torch.stack([torch.squeeze(item[0]) for item in list_collated_batches])\n",
    "        fast_video = None\n",
    "        whwh = torch.stack([torch.squeeze(item[2]) for item in list_collated_batches])\n",
    "        boxes = list_collated_batches[0][3]\n",
    "        labels = list_collated_batches[0][4]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #slow_video, fast_video, whwh, boxes, labels, metadata, idx = list_collated_batches\n",
    "        #clips_height, clips_width = slow_video.shape[-2:]\n",
    "        slow_video = slow_video.to(device)\n",
    "        if fast_video is not None:\n",
    "            fast_video = fast_video.to(device)\n",
    "        whwh = whwh.to(device)\n",
    "    \n",
    "        # INFERENCE\n",
    "        action_score_list, box_list, objectness_score_list = model(slow_video, fast_video, whwh, boxes, labels)\n",
    "        break\n",
    "        \n",
    "\n",
    "    # Add frame to buffer\n",
    "    #buffer.append(frame)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Process frames if buffer size is equal to 48\n",
    "    #process_frames(buffer)\n",
    "\n",
    "# Release video capture\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5355cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 16, 256, 352])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a2cea21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42b6cde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 80])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_score_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0501e7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 80])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_score_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "897384bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_score_list[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b70b36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_score_list[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b1f7395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_list[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(action_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4500d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    " ss = torch.stack([torch.squeeze(item[0]) for item in list_collated_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b46e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b0f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239ebfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
